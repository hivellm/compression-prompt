cuda-convnet toolbox 1 , although our net is less wide, and we used additional image jittering, based on zeroing-out random parts of an image. Our weight layer conguration is: conv64-conv256- conv256-conv256-conv256-full4096-full4096-full1000, where convN denotes a convolutional layer with N lters, fullM  a fully-connected layer with M outputs. On ILSVRC-2013 validation set, the network achieves the top-1/top-5 classication error of 39 : 7% = 17 : 7% , which is slightly better than 40 : 7% / 18 : 2% , reported in [ 8 ] for a single ConvNet. 2  Class Model Visualisation In this section we describe a technique for visualising the class models, learnt by the image clas- sication ConvNets. Given a learnt classication ConvNet and a class of interest, the visualisation method consists in numerically generating an image [ 5 ], which is representative of the class in terms of the ConvNet class scoring model. More formally, let S c ( I ) be the score of the class c , computed by the classication layer of the ConvNet for an image I . We would like to nd an L 2 -regularised image, such that the score S c is high: arg max I S c ( I )   k I k 2 2 ; (1) where  is the regularisation parameter. A locally-optimal I can be found by the back-propagation method. The procedure is related to the ConvNet training procedure, where the back-propagation is used to optimise the layer weights. The difference is that in our case the optimisation is performed with respect to the input image, while the weights are xed to those found during the training stage. We initialised the optimisation with the zero image (in our case, the ConvNet was trained on the zero-centred image data), and then added the training set mean image to the result. The class model visualisations for several classes are shown in Fig.  1 . It should be noted that we used the (unnormalised) class scores S c , rather than the class posteriors, returned by the soft-max layer: P c = exp S c