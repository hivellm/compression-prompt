@ x i 1 preserve norm only relevant directions. practice we show that these so- lutions improve performance both pathological synthetic datasets considered well polyphonic music prediction language modelling. Acknowledgements We would like thank Theano development team well (particularly Frederic Bastien, Pascal Lam- blin James Bergstra) their help. We acknowledge NSERC, FQRNT, CIFAR, RQCHP Compute Canada resources they provided. References Bastien, F., Lamblin, Pascanu, R., Bergstra, J., Goodfellow, I., Bergeron, A., Bouchard, N., Y. Theano: new features speed improvements. Submited Deep Un- supervised Feature NIPS 2012 Workshop. Frasconi, Simard, P. (1993). The problem learning long-term re- current networks. 1183{1195, San Francisco. Press. (invited paper). Simard, Frasconi, P. (1994). Learn- long-term gradient descent is dicult. Transactions 5 157{166. Boulanger-Lewandowski, N., Pascanu, R. Advances optimizing works. Technical Report arXiv:1212.0901, U. Mon- treal. Bergstra, J., Breuleux, O., Bastien, F., Lamblin, Pascanu, R., Desjardins, G., Turian, J., Warde- Farley, D., Y. (2010). Theano: CPU GPU math expression compiler. Proceedings Python Scientic Computing Conference (SciPy) Oral Presentation. Boulanger-Lewandowski, N., Vincent, P. Modeling temporal high- dimensional sequences: Application polyphonic generation transcription. Proceed- ings Twenty-nine International Conference Machine (ICML’12) ACM. Doya, K. (1993). Bifurcations works gradient descent learning. Transac- tions 75{80. Doya, K. Yoshizawa, S. (1991). Adaptive synchro- nization physical oscillators. E. Moody, Hanson, R. Lippmann, editors, NIPS 109{116. Morgan Kaufmann. Duchi, C., Hazan, E., Singer, Y. (2011). Adap- tive subgradient methods online learning stochastic optimization. Journal Machine Learn- Research 12 2121{2159. Elman, (1990). Finding structure time. Cognitive Science 14 179{211. Graves, A., Liwicki, M., Fernandez, S., Bertolami, R., Bunke, H., Schmidhuber, (2009). A Novel Connectionist System Unconstrained Handwrit- Recognition. Transactions Pattern Analysis Machine Intelligence 31 (5), 855{868. Hochreiter, S. Schmidhuber, (1997). Long short-term memory. Computation 9 (8), 1735{1780. H. Long short-term memory echo state networks: Details simulation study. Tech- nical report, Jacobs University Bremen. Jaeger, H., Lukosevicius, M., Popovici, D., Siew- ert, U. (2007). Optimization applications echo state networks leaky- integrator neurons. 20 (3), 335{352. Lukosevicius, M. Jaeger, H. (2009). Reservoir computing approaches recurrent network training. Computer Science Review 3 (3), 127{149. Martens, Sutskever, I. (2011). Learning recur- rent networks Hessian-free optimization. Proc. ICML’2011 ACM. Mikolov, T. Statistical Language Models based Networks Ph.D. thesis, Brno University Technology.