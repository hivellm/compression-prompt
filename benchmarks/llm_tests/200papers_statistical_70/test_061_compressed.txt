We now describe exact architecture used all seven Atari games. input neural network consists an 84 84 image produced by . rst hidden layer convolves 16 8 8 lters stride input image applies rectier nonlinearity [10, 18]. second hidden layer convolves 32 lters stride 2 , again followed by rectier nonlinearity. nal hidden layer fully-connected consists 256 rectier units. output layer fully- connected linear layer single output each valid action. number valid actions varied between 18 considered. We refer convolutional networks trained our approach as Deep Q-Networks (DQN). 5 Experiments So far, have performed experiments seven popular ATARI Beam Rider, Breakout, Enduro, Pong, Q*bert, Seaquest, Space Invaders. We use same network architecture, learning algorithm hyperparameters settings across seven games, showing that our approach robust enough work variety without incorporating game-specic information. While evaluated our agents real unmodied games, made one change reward structure during training only. Since scale scores varies greatly from game game, xed positive be negative be , leaving 0 unchanged. Clipping in this manner limits scale error derivatives makes it easier use same learning rate across multiple games. At same time, it could affect performance since it cannot differentiate between different magnitude. In these experiments, RMSProp algorithm minibatches size 32. behavior policy during training was -greedy annealed linearly from 0 : over rst million frames, xed at 0 : thereafter. We trained total 10 million frames replay memory one million most recent frames. Following previous approaches playing Atari games, also simple frame-skipping tech- nique [3]. More precisely, sees selects actions every th frame instead every frame, its last action repeated skipped frames. Since running emulator forward one step requires much less computation than having agent select an action, this technique allows agent play roughly k times more without signicantly increasing runtime. We use k = all except Space Invaders where noticed that using k = makes lasers invisible because period at which they blink. We used k = 3 make lasers visible this change was only difference in hyperparameter values between any games.