estimate since data center machines are shared with other production tasks, usage can uctuate quite bit. Note that due overhead distributed framework, CPU usage CBOW Skip-gram much closer each other than their single-machine implementations. The result are reported Table 6. 4.5 Microsoft Research Sentence Completion Challenge The Microsoft Sentence Completion Challenge has been recently introduced as task for advancing language modeling other NLP techniques [32]. This task consists 1040 sentences, where one word missing each sentence goal select most coherent rest sentence, given list ve reasonable choices. Performance several techniques has been already reported set, including N-gram models, LSA-based [32], log-bilinear [24] combination recurrent neural networks currently holds state art performance 55.4% accuracy benchmark [19]. We have explored performance Skip-gram architecture task. First, we train 640- dimensional 50M words provided [32]. Then, we compute score each sentence test set by using unknown at input, predict all surrounding words sentence. The nal sentence score then sum these individual predictions. Using sentence scores, we choose most likely sentence. A short summary some previous results together new results presented Table 7. While Skip-gram itself does not perform task better than LSA similarity, scores from complementary scores obtained RNNLMs, weighted combination leads new state art result 58.9% accuracy (59.2% development part set 58.7% test part set). 5 Examples Learned Relationships Table 8 shows words follow various relationships. We follow approach described above: relationship dened by subtracting two word vectors, result added another word. Thus for example, Paris - France + Italy = Rome . As it can be seen, accuracy quite good, although there clearly lot room for further improvements (note that using our accuracy metric that 9