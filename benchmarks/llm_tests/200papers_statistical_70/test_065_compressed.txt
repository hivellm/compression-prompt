[6] George E. Dahl, Dong Yu, Li Deng, Alex Acero. Context-dependent pre-trained deep networks large-vocabulary speech recognition. Audio, Speech, Language Pro- cessing, IEEE Transactions 20(1):30 42, January 2012. [7] Alex Graves, Abdel-rahman Mohamed, Geoffrey E. Hinton. Speech recognition deep recurrent networks. Proc. ICASSP [8] Matthew Hausknecht, Risto Miikkulainen, Peter Stone. A neuro-evolution approach to general atari game playing. [9] Nicolas Heess, David Silver, Yee Whye Teh. Actor-critic reinforcement energy-based policies. European Workshop Reinforcement page 43, [10] Kevin Jarrett, Koray Kavukcuoglu, MarcAurelio Ranzato, Yann LeCun. What is best multi-stage architecture object recognition? Proc. Com- puter Vision Pattern Recognition (CVPR 2009) 21462153. IEEE, 2009. [11] Alex Krizhevsky, Ilya Sutskever, Geoff Imagenet classication con- volutional Advances Information Processing Systems 25 11061114, [12] Sascha Lange Martin Riedmiller. Deep auto-encoder networks reinforcement learning. Networks (IJCNN), The 2010 Joint 18. IEEE, [13] Long-Ji Lin. robots using Technical report, DTIC Document, 1993. [14] Hamid Maei, Csaba Szepesvari, Shalabh Bhatnagar, Doina Precup, David Silver, Rich Sutton. Convergent Temporal-Difference Arbitrary Smooth Function Approxi- mation. Advances Information Processing Systems 22 12041212, 2009. [15] Hamid Maei, Csaba Szepesv Â· ari, Shalabh Bhatnagar, Richard S. Sutton. Toward off-policy control function approximation. Proceedings 27th Con- ference (ICML 2010) 719726, [16] Volodymyr Mnih. Aerial Image Labeling PhD thesis, University Toronto, [17] Andrew Moore Chris Atkeson. Prioritized sweeping: less data less real time. 13:103130, 1993. [18] Vinod Nair Geoffrey E Rectied linear units improve restricted boltzmann ma- chines. Proceedings 27th (ICML 2010) 807814, [19] Jordan B. Pollack Alan D. Blair. Why did td-gammon work. Advances Information Processing Systems 9 1016, 1996. [20] Martin Riedmiller. tted q iterationrst experiences a data efcient re- inforcement method. Learning: ECML 2005 317328. Springer, 2005. [21] Brian Sallans Geoffrey E. factored states actions. Journal Research 5:10631088, 2004. [22] Pierre Sermanet, Koray Kavukcuoglu, Soumith Chintala, Yann LeCun. Pedestrian de- tection unsupervised multi-stage feature learning. Proc. International Conference Computer Vision Pattern Recognition (CVPR 2013) IEEE, [23] Richard Sutton Andrew Barto. Reinforcement Learning: An Introduction MIT Press, 1998. [24] Gerald Tesauro. Temporal difference td-gammon. Communications ACM 38(3):5868, 1995. [25] John N Tsitsiklis Benjamin Van Roy. An analysis temporal-difference function approximation. Automatic Control, IEEE Transactions 42(5):674690, 1997. [26] Christopher JCH Watkins Peter Dayan. Q-learning. 8(3-4):279292, 1992. 9