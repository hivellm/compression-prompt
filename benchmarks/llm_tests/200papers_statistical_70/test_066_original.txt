Karen Simonyan Andrea Vedaldi Andrew Zisserman Visual Geometry Group, University of Oxford {karen,vedaldi,az}@robots.ox.ac.uk Abstract This paper addresses the visualisation of image classication models, learnt us- ing deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The rst one generates an image, which maximises the class score [ 5 ], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specic to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classication ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [ 13 ]. 1  Introduction With the deep Convolutional Networks (ConvNets) [ 10 ] now being the architecture of choice for large-scale image recognition [ 4 ,  8 ], the problem of understanding the aspects of visual appearance, captured inside a deep model, has become particularly relevant and is the subject of this paper. In previous work, Erhan et al. [ 5 ] visualised deep models by nding an input image which max- imises the neuron activity of interest by carrying out an optimisation using gradient ascent in the image space. The method was used to visualise the hidden feature layers of unsupervised deep ar- chitectures, such as the Deep Belief Network (DBN) [ 7 ], and it was later employed by Le et al. [ 9 ] to visualise the class models, captured by a deep unsupervised auto-encoder. Recently, the problem of ConvNet visualisation was addressed by Zeiler et al. [ 13 ]. For convolutional layer visualisation, they proposed the Deconvolutional Network (DeconvNet) architecture, which aims to approximately reconstruct the input of each layer from its output. In this paper, we address the visualisation of deep image classication ConvNets, trained on the large-scale ImageNet challenge dataset [ 2 ]. To this end, we make the following three contributions. First, we demonstrate that understandable visualisations of ConvNet classication models can be ob- tained using the numerical optimisation of the input image [ 5 ] (Sect.  2 ). Note, in our case, unlike [ 5 ], the net is trained in a supervised manner, so we know which neuron in the nal fully-connected clas- sication layer should be maximised to visualise the class of interest (in the unsupervised case, [ 9 ] had to use a separate annotated image set to nd out the neuron responsible for a particular class). To the best of our knowledge, we are the rst to apply the method of [ 5 ] to the visualisation of ImageNet classication ConvNets [ 8 ]. Second, we propose a method for computing the spatial support of a given class in a given image (image-specic class saliency map) using a single back-propagation pass through a classication ConvNet (Sect.  3 ). As discussed in Sect.  3.2 , such saliency maps can be used for weakly supervised object localisation. Finally, we show in Sect.  4  that the gradient-based visualisation methods generalise the deconvolutional network reconstruction procedure [ 13 ]. ConvNet implementation details. Our visualisation experiments were carried out using a single deep ConvNet, trained on the ILSVRC-2013 dataset [ 2 ], which includes 1.2M training images, labelled into 1000 classes. Our ConvNet is similar to that of [ 8 ] and is implemented using their 1