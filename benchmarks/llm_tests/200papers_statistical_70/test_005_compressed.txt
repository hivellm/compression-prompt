two entropy quantities. The rst term in Eqn. (2) , H[ y j D ] can be handled analytically for the probit case: H[ y j D ] 1 h Z ( ) N ( j D ) df = h 0 @ 0 @ + 1 1 A 1 A (3) The second term, E p ( jD ) [H[ y j ]] can be computed approximately as follows: E p ( jD ) [H[ y j ]] Z h(( )) N j ) df (4) Z exp ln N j ) df = C + C exp 0 @ + C A where C = q . The rst approximation, , reects Gaussian ap- proximation to posterior. The integral in left hand side Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( )) (see supplementary material) we can see that it can be approximated up to O ( 4 ) by a squared exponential curve, exp ( = ln 2). We will refer to this approximation as . Now we can apply standard convolution formula for Gaussians to nally get a closed form expression for both terms Eqn. (2). Fig. depicts striking accuracy this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( j ) is centred at = : 05 with tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in integral in Eqn. (4) . The authors are unaware previous use this simple and useful approximation in this context. In Section 5 we investigate experimentally information lost from approximations and as compared to golden standard extensive Monte Carlo simulation. To summarise, BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain posterior predictive mean and for each point of interest . Then, it selects a query that maximises the following objective function: h 0 @ 0 @ D D + 1 1 A 1 A C exp D ( D + C ) D + C (5) 5