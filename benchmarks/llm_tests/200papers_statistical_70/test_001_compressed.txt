Bayesian Active Learning Classication Preference Learning Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational Biological Learning Laboratory University Cambridge November 27, 2024 Abstract Information theoretic has been widely studied prob- abilistic models. For simple regression an optimal myopic policy easily tractable. However, other tasks more complex models, such as classication nonparametric models, solution harder compute. Current make approximations achieve tractabil- ity. We propose approach that expresses gain terms predictive entropies, apply method Gaussian Process Classier (GPC). Our approach makes minimal approximations full objective. Our experimental performance compares favourably many popular algorithms, has equal or lower computational complexity. We compare well decision also, which privy require much computational time. Secondly, by developing further reformulation binary preference classication problem, we extend our algorithm Gaussian Process preference learning. 1 Introduction In machine systems, learner passively collects which it makes inferences about its environment. In learning, however, learner seeks useful measurements trained upon. The goal produce best model least possible data; closely related statistical eld experimental design. With advent internet expansion storage facilities, vast quantities unlabelled data have become available, but it can be costly obtain labels. Finding most useful in vast space calls ecient algorithms. Two approaches are use decision information the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. The former minimizes expected 1