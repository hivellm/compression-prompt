In practice, adversarial nets represent limited family p distributions via function G ( z ; ) , we optimize rather than itself. Using multilayer perceptron dene G introduces multiple critical points parameter space. However, excellent performance multilayer per- ceptrons practice suggests that they are reasonable model use despite their lack theoretical guarantees. 5 Experiments We trained adversarial an range datasets including MNIST[23], Toronto Face Database (TFD) [28], CIFAR-10 [21]. generator mixture rectier linear activations [19, 9] sigmoid activations, while discriminator net maxout [10] activations. Dropout [17] was applied training discriminator net. While our theoretical framework permits dropout other at intermediate layers generator, as input only bottommost layer generator network. We estimate probability test set data under by tting Gaussian Parzen window samples generated with G reporting log-likelihood under this distribution. The parameter 5