@ x k +1 , not any direction (i.e. we do not enforce all eigenvalues close 1). The second observation we using a soft con- straint, therefore we not ensured norm error signal preserved. If it happens these Jaco- bian matrices such norm explodes (as t k increases), then this could lead exploding gradi- ents problem need deal with it example described section 3.2. This can be seen from dynamical systems perspective well: preventing vanishing implies pushing model such further away from attrac- tor (such does not converge it, case which vanish) closer boundaries between basins attractions, making more probable explode. 4. Experiments Results 4.1. Pathological synthetic problems As done Martens Sutskever (2011), address pathological problems proposed by Hochreiter Schmidhuber (1997) require learning long term correlations. We refer reader this original pa- per detailed description tasks supplementary materials complete description experimental setup. 4.1.1. Temporal Order problem We consider temporal order problem pro- totypical pathological problem, extending our results other proposed tasks afterwards. input long stream discrete symbols. At two points time (in beginning middle sequence) symbol within f A; B g emitted. task consists classifying order (either AA; AB; BA; BB ) at end sequence. Fig. 7 shows success rate standard SGD, SGD-C (SGD enhanced out clipping strategy) SGD- CR (SGD clipping strategy regular- ization term). Note sequences longer than 20, vanishing problem ensures neither SGD nor SGD-C algorithms can solve task. x -axis on log scale. This task provides empirical evidence exploding gradients linked tasks require long mem- ory traces. We know initially model oper- ates one-attractor regime (i.e. 1 < 1), which amount memory controlled by 1 . More memory means larger spectral radius, and, when this value crosses certain threshold model enters rich regimes where gradients likely explode. We see Fig. 7 long vanishing gradient prob-