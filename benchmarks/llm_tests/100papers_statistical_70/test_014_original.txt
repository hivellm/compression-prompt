incapable of incorporating hyperparameter learning. This may mean that given little data the GP model overts, leading to BALD selecting abnormal query locations. Maintaining a distribution over hyperparameters can be done using MCMC, although this signicantly increases computational time. Designing a general method to do this eciently is a subject of further work. In practice, a simple heuristic such as picking the rst few points randomly, and optimising hyperparameters will usually suce. 6 Conclusions We have demonstrated a method that applies the full information theoretic active learning criterion to GP classication that makes, as far as the authors are aware, the smallest number of approximations to date, and has as good computational complexity. We extend the GPC model to develop a new preference learning kernel, which enables us to apply our active learning algorithm directly to this domain also. The method can handle naturally active learning of kernel hyperparameters, which is a hard, mostly unsolved problem, for example in SVM active learning. One notable feature of our approach is that it is agnostic to the approximate inference methods used. This allows us to choose from a whole range of approximate inference methods, including EP, the Laplace approximation, ADF or even sparse online learning, and thereby make the trade o between computational complexity and accuracy. Our experimental performance compares favourably to many other active learning methods for classication, and even decision theoretic methods that have access to the test data and require much greater computational time. References [Bernardo, 1979] Bernardo, J. (1979). Expected information as expected utility. The Annals of Statistics , 7(3):686{690. [Chu and Ghahramani, 2005] Chu, W. and Ghahramani, Z. (2005). Preference learning with Gaussian processes. In ICML , pages 137{144. ACM. [Cover et al., 1991] Cover, T., Thomas, J., and Wiley, J. (1991). Elements of information theory , volume 6. Wiley Online Library. [Dasgupta, 2005] Dasgupta, S. (2005). Analysis of a greedy active learning strategy. In NIPS . [Ertin et al., ] Ertin, E., Fisher, J., and Potter, L. Maximum mutual information principle for dynamic sensor query problems. In Information Processing in Sensor Networks , Lecture Notes in Computer Science. [Fuhrmann, 2003] Fuhrmann, D. (2003). Active Testing Surveillance Systems, or, Playing Twenty Questions with a Radar . Defense Technical Information Center. 14