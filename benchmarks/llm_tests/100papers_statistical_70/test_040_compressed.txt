2 ]. These positions i; j are marked in dif- ferent input channel that 0 everywhere except for two sampled positions when it 1. model needs predict sum random numbers found at sampled positions i; j divided by 2. To address this problem we use 50 hidden units model, tanh activation function. learn- ing rate set .01 factor front regularization term 0.5. We use clipping cut- o threshold 6 norm gradients. weights initialized normal distribution mean 0 standard derivation : 1. trained varying length T between 50 200. We manage get success rate 100% solving this task, which outperforms results presented Martens Sutskever (2011) (using Hessian Free), where we see decline success rate length sequence gets closer 200 steps. Hochreiter Schmidhuber (1997) only con- siders up 100 steps. Jaeger (2012) also addresses this task 100% success rate, though solution does not seem generalize well it relies very large output weights, which ESNs usually sign instability. We use single deal all lengths (50, 100, 150 200), trained generalizes new that can be up 400 steps (while error still under 1%). Multiplication This task similar above, just that predicted value product random num- bers instead sum. We used same hyper- parameters previous case, obtained very similar results. Temporal order problem For temporal order length sequence xed T , We have xed set two symbols f A; B g 4 distractor symbols f c; d; e; f g . sequence en- tries uniformly sampled from distractor sym- bols everywhere except at two random positions, rst position sampled from [ T