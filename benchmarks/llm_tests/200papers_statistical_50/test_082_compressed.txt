Any differentiable function theoretically permitted Table 2: Challenges modeling: summary difculties encountered different approaches deep modeling each major operations involving model. 6 Advantages disadvantages new framework comes relative previous frame- works. primarily there no explicit representation g ( ) , D synchronized well (in particular, without updating avoid Helvetica scenario which collapses values same value have enough diversity ), negative Boltzmann machine kept up date between learning steps. Markov never needed, backprop used obtain gradients, needed learning, wide variety functions incorporated Table 2 summarizes comparison nets other approaches. aforementioned primarily computational. Adversarial models also gain some statistical from network being updated directly exam- ples, gradients owing through discriminator. means components copied generatorâ€™s parameters. Another adversarial net- works they represent very sharp, even degenerate distributions, while methods based on Markov require distribution somewhat blurry able mix modes. Conclusions future work admits straightforward extensions: 1. A conditional ( j c ) obtained adding c input both D . 2. Learned approximate performed training an auxiliary network predict z given . This similar trained wake-sleep algorithm [15] but advantage may trained xed generator after has nished training. 7