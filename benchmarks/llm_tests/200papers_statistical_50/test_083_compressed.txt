3. One approximately model all conditionals p ( j 6 ) where subset indices training family conditional models share parameters. Essentially, one use adversarial nets implement extension deterministic MP-DBM [11]. 4. Semi-supervised learning : features discriminator inference net improve perfor- mance classiers when limited labeled data available. 5. Efciency improvements: be accelerated greatly divising methods coordinating G D determining distributions sample z during training. This paper has demonstrated viability framework, suggesting these directions prove useful. Acknowledgments acknowledge Patrice Marcotte, Olivier Delalleau, Kyunghyun Cho, Guillaume Alain Jason Yosinski helpful discussions. Yann Dauphin shared his Parzen window eval- uation code us. developers Pylearn2 [7, 1], particularly Fr ed eric Bastien who rushed feature specically benet this project. Ar- naud Bergeron provided much-needed support L T E X typesetting. also CIFAR, Canada Research Chairs funding, Compute Canada, Calcul Qu ebec providing computational resources. Ian Goodfellow supported 2013 Google Fellowship Learning. Finally, we Les Trois Brasseurs stimulating our creativity. References [1] Bergeron, Bouchard, (2012). speed improvements. Unsupervised Feature NIPS 2012 Workshop. [2] (2009). architectures AI Now Publishers. [3] Mesnil, Dauphin, Rifai, S. Better mixing via representations. ICML’13 [4] Yao, Generalized denoising auto-encoders NIPS26 Nips Foundation. [5] (2014a). ICML’14 [6] (2014b). net- works 30th International Machine (ICML’14) [7] Desjardins, Turian, CPU GPU math expression compiler. Python Scientic Computing (SciPy) Oral Presentation. [8] Quickly generating representative samples RBM-derived process. Neural Computation 23 (8), 20532073. [9] Glorot, X., Bordes, sparse rectier AISTATS’2011 [10] Maxout ICML’2013 [11] Multi-prediction Boltzmann machines. NIPS’2013 Dumoulin, V., (2013c). Pylearn2: machine library. arXiv preprint arXiv:1308.4214 [13] Gutmann, M. Hyvarinen, A. Noise-contrastive estimation: estimation principle unnormalized statistical AISTATS’2010 [14] Hinton, Deng, L., Dahl, G. Mohamed, Jaitly, N., Senior, Vanhoucke, V., Nguyen, Sainath, T., Kingsbury, B. (2012a). networks acoustic modeling speech recognition. IEEE Signal Processing Magazine 29 (6), 8297. [15] Hinton, G. Dayan, Frey, B. Neal, R. M. (1995). The wake-sleep algorithm unsupervised Science 268 15581161. 8