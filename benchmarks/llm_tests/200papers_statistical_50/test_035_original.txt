dominated by long term contributions. 5. Summary and Conclusions We provided dierent perspectives through which one can gain more insight into the exploding and vanishing gradients issue. To deal with the exploding gradients problem, we propose a solution that involves clipping the norm of the exploded gradients when it is too large. The algorithm is motivated by the assumption that when gradients explode, the curvature and higher or- der derivatives explode as well, and we are faced with a specic pattern in the error surface, namely a val- ley with a single steep wall. In order to deal with the vanishing gradient problem we use a regulariza- tion term that forces the error signal not to vanish as it travels back in time. This regularization term forces the Jacobian matrices @ x i