7 Follow-Up Work After initial version was written, we single-machine multi-threaded C++ code computing vectors, using both continuous bag-of-words skip-gram archi- tectures 4 . The training speed signicantly higher reported earlier paper, i.e. it order billions words per hour typical hyperparameter choices. We also 1.4 million that represent named entities, trained 100 billion words. Some our follow-up work will be an upcoming NIPS 2013 [21]. References [1] Bengio, Ducharme, Vincent. probabilistic model. chine 3:1137-1155, LeCun. Scaling algorithms towards AI. Large-Scale Kernel chines, MIT [3] Brants, Popat, Xu, F. Och, Dean. machine translation. Joint Methods Collobert Weston. Unied Architecture Processing: Networks Multitask Learning. ICML, 2008. [5] Collobert, Weston, Bottou, Karlen, Kavukcuoglu Kuksa. Lan- (Almost) Scratch. 12:2493- 2537, [6] Dean, G.S. Corrado, Monga, Chen, Devin, Q.V. Le, M.Z. Mao, M.A. Ranzato, Senior, Tucker, Yang, Ng., Scale Networks, NIPS, [7] J.C. Duchi, E. Hazan, Singer. Adaptive subgradient methods online stochastic optimization. [8] Elman. Finding Structure Time. Cognitive Science, 14, 179-211, 1990. [9] Eric H. Socher, Manning Andrew Ng. Improving Representations via Global Context Multiple Prototypes. Association Linguistics, [10] G.E. Hinton, J.L. McClelland, D.E. Rumelhart. representations. Parallel dis- tributed processing: Explorations microstructure cognition. Volume 1: Foundations, MIT 1986. D.A. Jurgens, S.M. Mohammad, P.D. Turney, K.J. Holyoak. Semeval-2012 Measuring degrees relational similarity. Workshop Semantic (SemEval A.L. Maas, R.E. Daly, P.T. Pham, A.Y. Ng, Potts. sentiment analysis. ACL, Mikolov. Speech Recognition Czech, Masters thesis, Brno Uni- versity Technology, Kopeck O. Glembek Neural lan- higly inective languages, Proc. ICASSP 2009. [15] Kara at, Khudanpur. Recurrent Interspeech, 2010. [16] Kombrink, Khudanpur. Extensions recurrent ICASSP [17] Deoras, Kombrink, Empirical Evaluation Com- bination Advanced Modeling Techniques, Interspeech,