losses encountered after making decisions based on the data collected i.e. min- imize the Bayes posterior risk [ Roy and McCallum, 2001 ]. Maximising perfor- mance under test is the ultimate objective of most learners, however, evaluat- ing this objective can be very hard. For example, the methods proposed in [ Kapoor et al., 2007 , Zhu et al., 2003 ] for classication are in general expensive to compute. Furthermore, one may not know the loss function or test distribution in advance, or may want the model to perform well on a variety of loss functions. In extreme scenarios, such as exploratory data analysis, or visualisation, losses may be very hard to quantify. This motivates information theoretic approaches to active learning, which are agnostic to the decision task at hand and particular test data, this is known an inductive approach. They seek to reduce the number of feasible models as quickly as possible, using either heuristics (e.g. margin sampling [ Tong and Koller, 2001 ]) or by formalising uncertainty using well studied quantities, such as Shannons entropy and the KL-divergence [ Cover et al., 1991 ]. Although the latter approach was proposed several decades ago [ Lindley, 1956 , Bernardo, 1979 ], it is not always straightforward to apply the criteria to complicated models such as nonparametric processes with innite parameter spaces. As a result many algorithms exist which compute approximate posterior entropies, perform sampling, or work with related quantities in non-probabilistic models. We return to this problem, presenting the full information criterion and demonstrate how to apply it to Gaussian Processes Classication (GPC), yielding a novel active learning algorithm that makes minimal approximations. GPC is a powerful, non-parametric kernel-based model, and poses an interesting problem for information-theoretic active learning because the parameter space is innite dimensional and the posterior distribution is analytically intractable. We present the information theoretic approach to active learning in Section 2. In Section 3 we apply it to GPC, and show how to extended our method to preference learning. In Section 4 we review other approaches and how they compare to our algorithm. We take particular care to contrast our approach to the Informative Vector Machine, that addresses data point selection for GPs directly. We present results on a wide variety of datasets in Section 5 and conclude in Section 6. 2 Bayesian Information Theoretic Active Learn- ing We consider a fully discriminative model where the goal of active learning is to discover the dependence of some variable y 2 Y on an input variable x 2 X . The key idea in active learning is that the learner chooses the input queries x i 2 X and observes the systemâ€™s response y i , rather than passively receiving ( x i y i ) pairs. Within a Bayesian framework we assume existence of some latent param- eters, , that control the dependence between inputs and outputs, p ( y j x ; ). Having observed data D = f ( x i ; y i ) g n i =1 , a posterior distribution over the pa- 2