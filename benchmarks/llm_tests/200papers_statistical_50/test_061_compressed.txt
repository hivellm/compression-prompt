now describe exact architecture Atari input neural network consists an 84 84 image produced by . rst convolves 16 8 8 lters stride input image applies rectier nonlinearity [10, 18]. second convolves 32 lters stride 2 , again followed nonlinearity. nal fully-connected consists 256 units. output fully- connected linear single output each action. number actions varied 18 considered. refer convolutional networks trained approach as Deep Q-Networks (DQN). 5 Experiments So far, have performed experiments popular ATARI Beam Rider, Breakout, Enduro, Pong, Q*bert, Seaquest, Space Invaders. network architecture, learning algorithm hyperparameters settings showing approach robust enough work variety without incorporating game-specic information. While evaluated agents real unmodied made reward structure only. Since scores varies greatly game game, positive negative leaving unchanged. Clipping manner limits error derivatives easier learning rate multiple At time, could affect performance since cannot differentiate different magnitude. In these experiments, RMSProp algorithm minibatches size 32. behavior policy training -greedy annealed linearly over frames, thereafter. total 10 frames replay memory most recent Following previous approaches playing Atari also simple frame-skipping tech- nique [3]. More precisely, sees selects th frame instead frame, its last action repeated skipped frames. Since running emulator forward step requires much less computation than having select action, technique allows play roughly times more without signicantly increasing runtime. except Space Invaders where noticed that using makes lasers invisible because period at which they blink. 3 make lasers visible change was only difference in hyperparameter values between any