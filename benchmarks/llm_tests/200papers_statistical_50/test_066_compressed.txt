Karen Simonyan Andrea Vedaldi Andrew Zisserman Visual Geometry Group, University Oxford {karen,vedaldi,az}@robots.ox.ac.uk Abstract This paper addresses models, learnt us- ing Convolutional Networks (ConvNets). We consider two techniques, based computing gradient score with respect image. The rst one generates image, maximises score thus visualising notion class, captured ConvNet. second technique computes saliency map, specic class. We show maps employed weakly supervised object segmentation ConvNets. Finally, establish connection between gradient-based methods deconvolutional networks 1 Introduction With Convolutional Networks (ConvNets) 10 now being architecture choice large-scale recognition 4 , problem understanding aspects visual appearance, inside model, has become particularly relevant subject paper. In previous work, Erhan visualised models nding max- imises activity interest carrying optimisation gradient ascent space. used hidden feature layers ar- chitectures, as Deep Belief Network (DBN) 7 it later employed Le 9 models, auto-encoder. Recently, problem addressed Zeiler For convolutional visualisation, they proposed Deconvolutional Network (DeconvNet) architecture, aims approximately reconstruct each from its output. In paper, address ConvNets, large-scale ImageNet challenge dataset To end, make following three contributions. First, demonstrate understandable visualisations models ob- tained numerical optimisation (Sect. ). Note, our case, unlike net manner, so know nal fully-connected clas- sication should maximised interest (in case, 9 had use separate annotated set nd responsible particular class). To best our knowledge, are rst apply ImageNet ConvNets Second, propose computing spatial support (image-specic saliency map) single back-propagation pass through (Sect. 3 ). As discussed Sect. 3.2 , saliency maps used weakly supervised object localisation. Finally, show Sect. 4 gradient-based methods generalise deconvolutional network reconstruction procedure 13 ConvNet implementation details. Our experiments were carried out single ConvNet, trained ILSVRC-2013 dataset 2 includes 1.2M training images, labelled into 1000 classes. Our similar 8 implemented their 1