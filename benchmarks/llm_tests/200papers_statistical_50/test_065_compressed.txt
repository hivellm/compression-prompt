[6] George Dahl, Dong Yu, Li Deng, Acero. Context-dependent pre-trained large-vocabulary speech recognition. Audio, Speech, Language Pro- cessing, IEEE Transactions 20(1):30 42, January [7] Graves, Abdel-rahman Mohamed, Speech recognition recurrent ICASSP [8] Matthew Hausknecht, Risto Miikkulainen, Peter Stone. A neuro-evolution approach to general atari game playing. [9] Nicolas Heess, David Silver, Yee Whye Teh. Actor-critic energy-based policies. European Workshop page 43, [10] Kevin Jarrett, Koray Kavukcuoglu, MarcAurelio Ranzato, What best architecture object recognition? Com- puter 2009) 21462153. [11] Krizhevsky, Ilya Sutskever, Geoff Imagenet classication con- volutional 25 11061114, [12] Sascha Lange Deep auto-encoder Networks (IJCNN), 2010 Joint 18. [13] Long-Ji Lin. robots using Technical report, DTIC Document, [14] Szepesvari, Doina Precup, Rich Convergent Temporal-Difference Arbitrary Smooth Function Approxi- mation. 22 12041212, [15] Szepesv Â· ari, S. Toward off-policy control Con- ference 719726, [16] Volodymyr Mnih. Aerial Image Labeling PhD thesis, University Toronto, [17] Moore Chris Atkeson. Prioritized sweeping: 13:103130, [18] Vinod Nair E Rectied linear units improve restricted boltzmann ma- chines. 807814, [19] Jordan B. Pollack Alan D. Blair. Why did td-gammon work. 1016, 1996. [20] tted q iterationrst experiences efcient re- inforcement method. ECML 2005 317328. Springer, Brian Sallans factored actions. Journal Research 5:10631088, 2004. [22] Pierre Sermanet, Koray Kavukcuoglu, Soumith Chintala, Yann LeCun. Pedestrian de- tection unsupervised feature Computer Vision Pattern Recognition 2013) [23] Richard Sutton Andrew Barto. Learning: Introduction MIT Press, 1998. [24] Gerald Tesauro. Temporal difference td-gammon. Communications ACM 38(3):5868, 1995. [25] John N Tsitsiklis Benjamin Van Roy. analysis temporal-difference Automatic Control, IEEE Transactions 42(5):674690, 1997. [26] Christopher JCH Watkins Peter Dayan. Q-learning. 8(3-4):279292, 1992.