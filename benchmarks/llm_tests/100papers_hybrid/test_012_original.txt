QBC100 Kapoor Zhu et al. Empirical Figure 5: Summary of results for all classication experiments. y -axis denotes the number of additional data points, relative to BALD, required to achieve at least 97 : 5% of the predictive performance of the entire pool. The ‘box’ denotes 25th to 75th percentile, the red line denotes the median over datasets, and the ‘whiskers’ depict the range. The crosses denote outliers ( > 2 : 7 from the mean). Positive values mean that the algorithm required more data points than BALD to achieve the same performance. expected empirical error (the last is not a widely used method, but is included for analysis of [Kapoor et al., 2007]). We consider three articial, but challenging, datasets. The rst of which, block in the middle , has a block of noisy points on the decision boundary, the second block in the corner , has a block of uninformative points far from the decision boundary: a strong active learning algorithm should avoid these uninformative regions. The third is similar to the checkerboard dataset in [ Zhu et al., 2003 ], and is designed to test the algorithm’s capabilities to nd multiple disjoint islands of points from one class. The three datasets and results using each algorithm are depicted in Fig. 3. Results are also presented on eight UCI classication datasets australia, crabs, vehicle, isolet, cancer, wine, wdbc and letter . Letter is a multiclass dataset for which we select hard-to-distinguish letters E vs. F and D vs. P. For preference learning we use the cpu, cart and kinematics regression datasets 1 processed to yield a preference task as described in [ Chu and Ghahramani, 2005 ]. Results are plotted in Fig. 4, and Fig. 5 depicts an aggregation of the results. Discussion: Figs. 3 and 4 show that by using BALDwe make signicant gains over naive random sampling in both the classication and preference learning domains. Relative to other active learning algorithms BALDis consistently the 1 http://www.liacc.up.pt/ ltorgo/Regression/DataSets.html 12