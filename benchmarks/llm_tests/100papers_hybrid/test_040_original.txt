2 ]. These positions i; j are marked in a dif- ferent input channel that is 0 everywhere except for the two sampled positions when it is 1. The model needs to predict the sum of the random numbers found at the sampled positions i; j divided by 2. To address this problem we use a 50 hidden units model, with a tanh activation function. The learn- ing rate is set to .01 and the factor  in front of the regularization term is 0.5. We use clipping with a cut- o threshold of 6 on the norm of the gradients. The weights are initialized from a normal distribution with mean 0 and standard derivation : 1. The model is trained on sequences of varying length T between 50 and 200. We manage to get a success rate of 100% at solving this task, which outperforms the results presented in Martens and Sutskever (2011) (using Hessian Free), where we see a decline in success rate as the length of the sequence gets closer to 200 steps. Hochreiter and Schmidhuber (1997) only con- siders sequences up to 100 steps. Jaeger (2012) also addresses this task with 100% success rate, though the solution does not seem to generalize well as it relies on very large output weights, which for ESNs are usually a sign of instability. We use a single model to deal with all lengths of sequences (50, 100, 150 200), and the trained model generalizes to new sequences that can be up 400 steps (while the error is still under 1%). Multiplication problem This task is similar to the problem above, just that the predicted value is the product of the random num- bers instead of the sum. We used the same hyper- parameters as for the previous case, and obtained very similar results. Temporal order problem For the temporal order the length of the sequence is xed to T , We have a xed set of two symbols f A; B g and 4 distractor symbols f c; d; e; f g . The sequence en- tries are uniformly sampled from the distractor sym- bols everywhere except at two random positions, the rst position sampled from [ T