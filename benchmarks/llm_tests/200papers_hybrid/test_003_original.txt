rameters is inferred, p ( jD ). The central goal of information theoretic ac- tive learning is to reduce the number possible hypotheses maximally fast, i.e. to minimize the uncertainty about the parameters using Shannonâ€™s entropy [ Cover et al., 1991 ]. Data points D 0 are selected that satisfy arg min D 0 H[ jD 0 ] = R p ( jD 0 ) log p ( jD 0 )d . Solving this problem in general is NP-hard; however, as is common in sequential decision making tasks a myopic (greedy) approxi- mation is made [ Heckerman et al., 1995 ]. It has been shown that the myopic policy can perform near-optimally [ Golovin and Krause, 2010 , Dasgupta, 2005 ]. Therefore, the objective is to seek the data point x that maximises the decrease in expected posterior entropy: arg max x H[ jD ] E y p ( y j x D ) [H[ j y; x ; D ]] (1) Note that expectation over the unseen output y is required. Many works e.g. [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ] propose using this objective directly. However, parameter posteriors are often high dimen- sional and computing their entropies is usually intractable. Furthermore, for nonparametric processes the parameter space is innite dimensional so Eqn. (1) becomes poorly dened. To avoid gridding parameter space (exponentially hard with dimensionality), or sampling (from which it is notoriously hard to estimate entropies without introducing bias [ Panzeri and Petersen, 2007 ]), these papers make Gaussian or low dimensional approximations and calculate the entropy of the approximate posterior. A second computational diculty arises; if N x data points are under consideration, and N y responses may be seen, then O ( N x N y ), potentially expensive, posterior updates are required to calculate Eqn. (1). An important insight arises if we note that the objective in Eqn. (1) is equivalent to the conditional mutual information between the unknown output and the parameters, I[ ; y j x ; D ]. Using this insight it is simple to show that the objective can be rearranged to compute entropies in y space: arg max x H[ y j x ; D ] E p ( jD ) [H[ y j x ; ]] (2) Eqn. (2) overcomes the challenges we described for Eqn. (1) . Entropies are now calculated in, usually low dimensional, output space. For binary classication, these are just entropies of Bernoulli variables. Also is now conditioned only on D , so only O (1) posterior updates are required. Eqn. (2) also provides us with an interesting intuition about the objective; we seek the x for which the model is marginally most uncertain about y (high H[ y j x ; D ]), but for which individual settings of the parameters are condent (low E p ( jD ) [H[ y j x ; ]] ). This can be interpreted as seeking the x for which the parameters under the posterior disagree about the outcome the most, so we refer to this objective as Bayesian Active Learning by Disagreement (BALD). We present a method to apply Eqn. (2) directly to GPC and preference learning. We no longer need to build our entropy calculation around the type of posterior approximation (as 3