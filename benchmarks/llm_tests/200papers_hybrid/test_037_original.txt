Mikolov, T., Deoras, A., Kombrink, S., Burget, L., and Cernocky, J. (2011). Empirical evaluation and combination of advanced language modeling tech- niques. In Proc. 12th annual conference of the in- ternational speech communication association (IN- TERSPEECH 2011) . Mikolov, T., Sutskever, I., Deoras, A., Le, H.-S., Kombrink, S., and Cernocky, J. (2012). Subword language modeling with neural networks. preprint (http://www.t.vutbr.cz/ imikolov/rnnlm/char.pdf). Moreira, M. and Fiesler, E. (1995). Neural net- works with adaptive learning rate and momentum terms. Idiap-RR Idiap-RR-04-1995, IDIAP, Mar- tigny, Switzerland. Pascanu, R. and Jaeger, H. (2011). A neurodynamical model for working memory. Neural Netw. , 24 , 199{ 207. Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by back- propagating errors. Nature , 323 (6088), 533{536. Strogatz, S. (1994). Nonlinear Dynamics And Chaos: With Applications To Physics, Biology, Chemistry, And Engineering (Studies in Nonlinearity) . Studies in nonlinearity. Perseus Books Group, 1 edition. Sutskever, I., Martens, J., and Hinton, G. (2011). Generating text with recurrent neural networks. In L. Getoor and T. Scheer, editors, Proceedings of the 28th International Conference on Machine Learning (ICML-11) , ICML â€™11, pages 1017{1024, New York, NY, USA. ACM. Werbos, P. J. (1988). Generalization of backpropa- gation with application to a recurrent gas market model. Neural Networks , 1 (4), 339{356. Analytical analysis of the exploding and vanishing gradients problem x t = W rec  ( x t  1 ) + W in u t + b (11) Let us consider the term g T k = @ E t