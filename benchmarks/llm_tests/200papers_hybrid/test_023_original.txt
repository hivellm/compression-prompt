Figure 3. Bifurcation diagram of a single hidden unit RNN (with xed recurrent weight of 5.0 and adjustable bias b ; example introduced in Doya (1993)). See text. We show that there are two types of events that could lead to a large change in x t , with t ! 1 . One is cross- ing a boundary between basins of attraction (depicted with a unlled circles), while the other is crossing a bi- furcation boundary (lled circles). For large t , the  x t resulting from a change in b will be large even for very small changes in b (as the system is attracted towards dierent attractors) which leads to a large gradient. It is however neither necessary nor sucient to cross a bifurcation for the gradients to explode, as bifurca- tions are global events that could have no eect lo- cally. Learning traces out a path in the parameter- state space. If we are at a bifurcation boundary, but the state of the model is such that it is in the basin of attraction of one attractor (from many possible attrac- tors) that does not change shape or disappear when the bifurcation is crossed, then this bifurcation will not aect learning.