affect score most. One can expect such correspond location image. We note similar technique has been previously applied 1 ] context Bayesian classication. 3.1 Class Saliency Extraction Given an I 0 (with m rows n columns) c M 2 R m n computed follows. First, derivative 4 found back-propagation. After that, obtained rearranging elements vector case grey-scale image, number elements equal number I 0 so can M ij = i;j where index element corresponding i -th row -th column. case multi-channel e.g. RGB) image, let us assume channel I corresponds element index j; To derive single value each took maximum magnitude across all channels: M ij = max i;j;c It important note are extracted classication ConvNet trained labels, so no additional annotation required (such bounding boxes or masks). computation image-specic single extremely quick, since it only requires single back-propagation pass. We visualise highest-scoring (top-1 prediction) randomly se- lected ILSVRC-2013 test images Fig. 2 Similarly ConvNet classication procedure 8 ], where predictions are 10 cropped reected sub-images, 10 10 sub-images, then averaged them. 3.2 Weakly Supervised Object Localisation weakly supervised (Sect. 3.1 encode location given given image, thus can used (in spite being trained labels only). Here briey describe simple procedure, which used task ILSVRC-2013 12 Given corresponding map, compute mask GraphCut use motivated fact might capture only most discriminative part object, so thresholding might not able highlight whole object. Therefore, it important able propagate thresholded other parts object, which aim achieve here continuity cues. Foreground background models were Gaussian Mixture Models. foreground model estimated from higher than threshold, 95% quantile distribution image; background model estimated from smaller than 30% quantile (Fig. right-middle). GraphCut ] then performed publicly available implementation Once labelling into foreground background computed, mask largest connected component foreground (Fig. right). We entered our ILSVRC-2013 challenge. Consid- ering requires bounding boxes reported, them bounding boxes masks. procedure repeated each top-5 predicted classes. method achieved 46 : 4% top-5 error test ILSVRC-2013. It should noted method weakly supervised (unlike challenge winner 29 : 9% error), task not taken into account during training. spite its simplicity, method still outperformed our submission ILSVRC-2012 challenge (which used same dataset), which achieved 50 : 0% error fully-supervised algorithm based part-based models 6 ] Fisher vector feature encoding 11 ]. 4 Relation Deconvolutional Networks In this section establish connection between gradient-based visualisation DeconvNet architecture 13 ]. As show below, DeconvNet-based reconstruction n -th layer input X n either equivalent or similar computing gradient visualised neuron ac-