This similar one Tomas Mikolov only diverged from original proposal attempt provide better theoretical foundation (ensuring always move de- scent direction respect current mini-batch), though practice both variants behave similarly. clipping simple implement computationally ecient, it does however in- troduce additional hyper-parameter, namely threshold. One good heuristic setting thresh- old look average over suciently large number updates. our ex- periments have noticed given task training sensitive parameter behaves thresholds. thought adapting based gradient. Compared other adaptation strate- gies, which focus improving convergence col- lecting gradient (as example