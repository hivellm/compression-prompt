4.2. Natural problems We address the task of polyphonic music prediction, using the datasets Piano-midi.de, Nottingham and MuseData described in Boulanger-Lewandowski et al. (2012) and language modelling at the character level on the Penn Treebank dataset (Mikolov et al. , 2012). We also explore a modied version of the task, where we ask the model to predict the 5th character in the future (instead of the next). Our assumption is that to solve this modied task long term correlations are more important than short term ones, and hence our regularization term should be more helpful. The training and test scores reported in Table 1 are average negative log likelihood per time step. We xed hyper-parameters across the three runs, except for the regularization factor and clipping cuto threshold. SGD-CR provides a statistically signicant im- provement on the state-of-the-art for RNNs on all the polyphonic music prediction tasks except for MuseData on which we get exactly the same per- formance as the state-of-the-art (Bengio et al. , 2012), which uses a dierent architecture. Table 2 contains the results on language modelling (in bits per letter). These results suggest that clipping the gradients solves an optimization issue and does not act as a regular- izer, as both the training and test error improve in general. Results on Penn Treebank reach the state of the art achieved by Mikolov et al. (2012), who used a dierent clipping algorithm similar to ours, thus pro- viding evidence that both behave similarly. The reg- ularized model performs as well as the Hessian-Free trained model. By employing the proposed regularization term we are able to improve test error even on tasks that are not