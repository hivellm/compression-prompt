The decoder often trained to predict next word 0 given context vector all previously predicted words f 0 . In other words, decoder denes over translation by decomposing joint into ordered conditionals: T Y =1 j (2) where T . With RNN, each conditional modeled j (3) where nonlinear, potentially multi-layered, function outputs , s hidden state RNN. It should noted other architectures such hybrid RNN de-convolutional neural network can used (Kalchbrenner Blunsom, 2013). 3 L EARNING TO A LIGN AND T RANSLATE this section, we propose novel architecture for neural machine translation. The new architecture consists bidirectional RNN encoder (Sec. 3.2) decoder that emulates searching through source sentence during decoding translation (Sec. 3.1). 3.1 D ECODER : G ENERAL D ESCRIPTION