domly picked from [3 ; 100]. The task is to do next symbol prediction, though the only predictable sym- bol is the last one. We use a 100 hidden units with a learning rate of .001 and  , the regularization coecient, set to 1. The cuto threshold is left to 6. This task turns out to be more dicult to learn, and only 1 out of 8 experiments succeeded. As before we use a single model to deal with multiple values for T (from 50 to 200 units). Noiseless memorization problem For the noiseless memorization we are presented with a binary pattern of length 5, followed by T steps of constant value. After these T steps the model needs to generate the pattern seen initially. We also con- sider the extension of this problem from Martens and Sutskever (2011), where the pattern has length 10, and the symbol set has cardinality 5 instead of 2. We manage a 100% success rate on these tasks, though we train a dierent model for the 5 sequence lengths considered (50, 100, 150, 200). Natural Tasks Polyphonic music prediction We train our model, a sigmoid units RNN, on se- quences of 200 steps. The cut-o coecient thresh- old is the same in all cases, namely 8 (note that one has to take the mean over the sequence length when computing the gradients). In case of the Piano-midi.de dataset we use 300 hid- den units and an initial learning rate of 1.0 (whir the learning rate halved every time the error over an epoch increased instead of decreasing). For the regularized model we used a initial value for regularization coef- cient  of 0.5, where  follows a 1 =t schedule, i.e.  t = 1