incapable incorporating hyperparameter This may mean given little GP overts, leading BALD selecting abnormal locations. Maintaining distribution over be done using MCMC, although signicantly increases Designing general do eciently subject further work. practice, simple heuristic such picking rst few points randomly, optimising will usually suce. 6 Conclusions We demonstrated applies full criterion GP classication authors smallest number approximations date, has good complexity. extend GPC develop new preference kernel, enables apply algorithm directly domain also. handle naturally kernel hyperparameters, hard, mostly unsolved problem, example SVM One notable feature approach agnostic methods, including EP, Laplace approximation, ADF learning, thereby between complexity accuracy. Our experimental performance compares favourably classication, decision require greater References [Bernardo, Bernardo, (1979). Expected expected utility. Annals Statistics 7(3):686{690. Chu, W. Z. Preference Gaussian processes. ICML 137{144. ACM. Cover, T., Thomas, Wiley, (1991). Elements volume 6. Wiley Online Library. [Dasgupta, Dasgupta, S. Analysis greedy strategy. NIPS [Ertin ] Ertin, E., Fisher, J., Potter, L. Maximum mutual principle dynamic sensor problems. Information Processing Sensor Networks Lecture Notes Computer Science. [Fuhrmann, 2003] Fuhrmann, D. (2003). Active Testing Surveillance Systems, or, Playing Twenty Questions Radar Defense Technical Information Center. 14