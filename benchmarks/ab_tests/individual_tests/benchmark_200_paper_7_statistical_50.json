{
  "test_id": "benchmark_200_paper_7_statistical_50",
  "technique": "statistical_50%",
  "original_prompt": "2 noise = 1. The likelihood only depends on the dierence between f ( u ) and f ( v ). We therefore dene g ( u ; v ) = f ( u ) f ( v ), and do inference entirely in terms of g , for which the likelihood becomes the same as for probit classication: y j u ; v ; f Bernoulli (( g ( u ; v ))). We observe that a GP prior is induced on g because it is formed by performing a linear operation on f , for which we have a GP prior already f GP (0 ; k ). We can derive the induced covariance function of g as (derivation in the Supplementary material) as: k pref (( u i ; v i ) ; ( u j ; v j )) = k ( u i ; u j ) + k ( v i ; v j ) k ( u i ; v j ) k ( v i ; u j ). Note that this kernel k pref respects the anti-symmetry properties desired for a preference learning scenario, i.e. the value g ( u; v ) is perfectly anti-correlated with g ( v; u ), ensuring P [ u v ] = 1 P [ v u ] holds. Thus, we can conclude that the GP preference learning framework of [ Chu and Ghahramani, 2005 ], is equivalent to GPC with a particular class of kernels, that we may call the preference judgement kernels . Therefore, our active learning algorithm presented in Section 3 for GPC can readily be applied to pairwise preference learning also. 4 Related Methodologies There are a number of closely related algorithms for active classication which we now review. The Informative Vector Machine (IVM): Perhaps the most closely re- lated approach is the IVM [ Lawrence et al., 2003 ]. This popular,and successful approach to active learning was designed specically for GPs; it uses an infor- mation theoretic approach and so appears very similar to BALD. The IVM algorithm was designed for subsampling a dataset for training a GP, so it is privy to the y values before including a measurement; it cannot therefore work explic- itly in output space i.e. with Eqn. (2) . The IVM uses Eqn. (1) , but parameter entropies are calculated approximately in the marginal subspace corresponding to the observed data points. The entropy decrease after inclusion of a new data point can then be calculated eciently using the GP covariance matrix. Although the IVM and BALD are motivated by the same objective, they work fundamentally dierently when approximate inference is carried out. At any time 7",
  "compressed_prompt": "2 noise 1. likelihood only depends dierence between ). We therefore dene ), do inference entirely terms , likelihood becomes same as probit classication: y Bernoulli (( ))). We observe GP prior induced because formed by performing linear operation have prior already (0 We derive induced covariance function (derivation Supplementary material) as: pref (( )) + Note this kernel pref respects anti-symmetry properties desired scenario, i.e. value u; perfectly anti-correlated v; ), ensuring P ] 1 P ] holds. Thus, conclude GP framework Chu Ghahramani, 2005 ], equivalent GPC particular class kernels, may call judgement kernels . Therefore, our algorithm presented Section 3 GPC readily applied pairwise also. 4 Related Methodologies There number closely related algorithms classication now review. Informative Vector Machine (IVM): Perhaps most closely re- lated IVM Lawrence et al., 2003 ]. This popular,and successful designed specically GPs; uses an infor- mation theoretic so appears very similar BALD. IVM algorithm designed subsampling dataset training GP, so privy y values before including measurement; cannot therefore work explic- itly output space i.e. Eqn. (2) . IVM uses Eqn. (1) but parameter entropies calculated approximately marginal subspace corresponding observed data points. entropy decrease after inclusion new data point then be calculated eciently using GP covariance matrix. Although IVM BALD motivated by same objective, they work fundamentally dierently when approximate inference carried out. At any time 7",
  "original_tokens": 451,
  "compressed_tokens": 225,
  "compression_ratio": 0.49889135254988914,
  "metadata": {
    "paper_id": "benchmark_200_paper_7",
    "dictionary_entries": null,
    "substitutions": null,
    "processing_time_ms": 0.16349999999999998
  }
}