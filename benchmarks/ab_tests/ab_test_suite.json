{
  "version": "1.0.0",
  "created_at": "2025-10-21T23:01:52.251586600+00:00",
  "tests": [
    {
      "test_id": "benchmark_100_paper_1_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "Bayesian Active Learning for Classication and Preference Learning Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational and Biological Learning Laboratory University of Cambridge November 27, 2024 Abstract Information theoretic active learning has been widely studied for prob- abilistic models. For simple regression an optimal myopic policy is easily tractable. However, for other tasks and with more complex models, such as classication with nonparametric models, the optimal solution is harder to compute. Current approaches make approximations to achieve tractabil- ity. We propose an approach that expresses information gain in terms of predictive entropies, and apply this method to the Gaussian Process Classier (GPC). Our approach makes minimal approximations to the full information theoretic objective. Our experimental performance compares favourably to many popular active learning algorithms, and has equal or lower computational complexity. We compare well to decision theoretic approaches also, which are privy to more information and require much more computational time. Secondly, by developing further a reformulation of binary preference learning to a classication problem, we extend our algorithm to Gaussian Process preference learning. 1 Introduction In most machine learning systems, the learner passively collects data with which it makes inferences about its environment. In active learning, however, the learner seeks the most useful measurements to be trained upon. The goal of active learning is to produce the best model with the least possible data; this is closely related to the statistical eld of optimal experimental design. With the advent of the internet and expansion of storage facilities, vast quantities of unlabelled data have become available, but it can be costly to obtain labels. Finding the most useful data in this vast space calls for ecient active learning algorithms. Two approaches to active learning are to use decision and information the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. The former minimizes the expected 1",
      "compressed_prompt": "Bayesian Active Classication Preference Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational Biological Laboratory University Cambridge November 27, 2024 Abstract Information been widely studied prob- abilistic models. For simple regression myopic policy easily tractable. However, other tasks complex such as nonparametric solution harder compute. Current make achieve tractabil- ity. propose that expresses gain terms predictive entropies, apply method Classier (GPC). minimal full objective. performance compares favourably many popular algorithms, equal lower complexity. compare well also, privy require much time. Secondly, developing further reformulation binary problem, we extend our algorithm learning. Introduction machine systems, passively collects inferences about its environment. learning, however, seeks measurements trained upon. goal produce best model least possible data; closely related statistical eld design. advent internet expansion storage facilities, quantities unlabelled have become available, but can costly obtain labels. Finding space calls ecient algorithms. Two use the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. former minimizes expected",
      "original_tokens": 308,
      "compressed_tokens": 154,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_100_paper_1",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1931
      }
    },
    {
      "test_id": "benchmark_100_paper_1_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "Bayesian Active Learning for Classication and Preference Learning Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational and Biological Learning Laboratory University of Cambridge November 27, 2024 Abstract Information theoretic active learning has been widely studied for prob- abilistic models. For simple regression an optimal myopic policy is easily tractable. However, for other tasks and with more complex models, such as classication with nonparametric models, the optimal solution is harder to compute. Current approaches make approximations to achieve tractabil- ity. We propose an approach that expresses information gain in terms of predictive entropies, and apply this method to the Gaussian Process Classier (GPC). Our approach makes minimal approximations to the full information theoretic objective. Our experimental performance compares favourably to many popular active learning algorithms, and has equal or lower computational complexity. We compare well to decision theoretic approaches also, which are privy to more information and require much more computational time. Secondly, by developing further a reformulation of binary preference learning to a classication problem, we extend our algorithm to Gaussian Process preference learning. 1 Introduction In most machine learning systems, the learner passively collects data with which it makes inferences about its environment. In active learning, however, the learner seeks the most useful measurements to be trained upon. The goal of active learning is to produce the best model with the least possible data; this is closely related to the statistical eld of optimal experimental design. With the advent of the internet and expansion of storage facilities, vast quantities of unlabelled data have become available, but it can be costly to obtain labels. Finding the most useful data in this vast space calls for ecient active learning algorithms. Two approaches to active learning are to use decision and information the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. The former minimizes the expected 1",
      "compressed_prompt": "Bayesian Active Learning Classication Preference Learning Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational Biological Learning Laboratory University Cambridge November 27, 2024 Abstract Information theoretic has been widely studied prob- abilistic models. For simple regression an optimal myopic policy easily tractable. However, other tasks more complex models, such as classication nonparametric models, solution harder compute. Current make approximations achieve tractabil- ity. We propose approach that expresses gain terms predictive entropies, apply method Gaussian Process Classier (GPC). Our approach makes minimal approximations full objective. Our experimental performance compares favourably many popular algorithms, has equal or lower computational complexity. We compare well decision also, which privy require much computational time. Secondly, by developing further reformulation binary preference classication problem, we extend our algorithm Gaussian Process preference learning. 1 Introduction In machine systems, learner passively collects which it makes inferences about its environment. In learning, however, learner seeks useful measurements trained upon. The goal produce best model least possible data; closely related statistical eld experimental design. With advent internet expansion storage facilities, vast quantities unlabelled data have become available, but it can be costly obtain labels. Finding most useful in vast space calls ecient algorithms. Two approaches are use decision information the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. The former minimizes expected 1",
      "original_tokens": 308,
      "compressed_tokens": 215,
      "compression_ratio": 0.698051948051948,
      "metadata": {
        "paper_id": "benchmark_100_paper_1",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1128
      }
    },
    {
      "test_id": "benchmark_100_paper_2_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "losses encountered after making decisions based on the data collected i.e. min- imize the Bayes posterior risk [ Roy and McCallum, 2001 ]. Maximising perfor- mance under test is the ultimate objective of most learners, however, evaluat- ing this objective can be very hard. For example, the methods proposed in [ Kapoor et al., 2007 , Zhu et al., 2003 ] for classication are in general expensive to compute. Furthermore, one may not know the loss function or test distribution in advance, or may want the model to perform well on a variety of loss functions. In extreme scenarios, such as exploratory data analysis, or visualisation, losses may be very hard to quantify. This motivates information theoretic approaches to active learning, which are agnostic to the decision task at hand and particular test data, this is known an inductive approach. They seek to reduce the number of feasible models as quickly as possible, using either heuristics (e.g. margin sampling [ Tong and Koller, 2001 ]) or by formalising uncertainty using well studied quantities, such as Shannons entropy and the KL-divergence [ Cover et al., 1991 ]. Although the latter approach was proposed several decades ago [ Lindley, 1956 , Bernardo, 1979 ], it is not always straightforward to apply the criteria to complicated models such as nonparametric processes with innite parameter spaces. As a result many algorithms exist which compute approximate posterior entropies, perform sampling, or work with related quantities in non-probabilistic models. We return to this problem, presenting the full information criterion and demonstrate how to apply it to Gaussian Processes Classication (GPC), yielding a novel active learning algorithm that makes minimal approximations. GPC is a powerful, non-parametric kernel-based model, and poses an interesting problem for information-theoretic active learning because the parameter space is innite dimensional and the posterior distribution is analytically intractable. We present the information theoretic approach to active learning in Section 2. In Section 3 we apply it to GPC, and show how to extended our method to preference learning. In Section 4 we review other approaches and how they compare to our algorithm. We take particular care to contrast our approach to the Informative Vector Machine, that addresses data point selection for GPs directly. We present results on a wide variety of datasets in Section 5 and conclude in Section 6. 2 Bayesian Information Theoretic Active Learn- ing We consider a fully discriminative model where the goal of active learning is to discover the dependence of some variable y 2 Y on an input variable x 2 X . The key idea in active learning is that the learner chooses the input queries x i 2 X and observes the system’s response y i , rather than passively receiving ( x i y i ) pairs. Within a Bayesian framework we assume existence of some latent param- eters, , that control the dependence between inputs and outputs, p ( y j x ; ). Having observed data D = f ( x i ; y i ) g n i =1 , a posterior distribution over the pa- 2",
      "compressed_prompt": "losses encountered after making decisions based collected i.e. min- imize Bayes risk Roy McCallum, 2001 ]. Maximising perfor- mance under ultimate objective most learners, however, evaluat- ing objective can very hard. For example, methods proposed Kapoor 2007 Zhu 2003 ] classication general expensive compute. Furthermore, one not know loss function advance, want model perform well variety loss functions. extreme scenarios, exploratory analysis, visualisation, hard quantify. This motivates learning, agnostic decision task at hand data, known inductive approach. They seek reduce number feasible quickly possible, either heuristics (e.g. margin sampling Tong Koller, ]) by formalising uncertainty studied quantities, Shannons entropy KL-divergence Cover 1991 Although latter was several decades ago Lindley, 1956 Bernardo, 1979 ], always straightforward criteria complicated nonparametric processes spaces. As result many algorithms exist compute approximate entropies, sampling, work related quantities non-probabilistic models. return problem, presenting full criterion demonstrate Gaussian Processes Classication (GPC), yielding novel algorithm makes minimal approximations. GPC powerful, non-parametric kernel-based model, poses interesting problem information-theoretic because space dimensional analytically intractable. 2. 3 GPC, show extended method preference learning. 4 review other they compare algorithm. take care contrast Informative Vector Machine, addresses point selection GPs directly. results wide datasets 5 conclude 6. Bayesian Information Theoretic Active Learn- consider fully discriminative where goal discover variable Y input variable X . The key idea learner chooses queries X observes system’s response rather than passively receiving pairs. Within Bayesian framework assume existence some latent param- eters, control dependence between inputs outputs, p j ; ). Having observed D = f ; ) g n =1 over pa-",
      "original_tokens": 514,
      "compressed_tokens": 257,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_100_paper_2",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.29619999999999996
      }
    },
    {
      "test_id": "benchmark_100_paper_2_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "losses encountered after making decisions based on the data collected i.e. min- imize the Bayes posterior risk [ Roy and McCallum, 2001 ]. Maximising perfor- mance under test is the ultimate objective of most learners, however, evaluat- ing this objective can be very hard. For example, the methods proposed in [ Kapoor et al., 2007 , Zhu et al., 2003 ] for classication are in general expensive to compute. Furthermore, one may not know the loss function or test distribution in advance, or may want the model to perform well on a variety of loss functions. In extreme scenarios, such as exploratory data analysis, or visualisation, losses may be very hard to quantify. This motivates information theoretic approaches to active learning, which are agnostic to the decision task at hand and particular test data, this is known an inductive approach. They seek to reduce the number of feasible models as quickly as possible, using either heuristics (e.g. margin sampling [ Tong and Koller, 2001 ]) or by formalising uncertainty using well studied quantities, such as Shannons entropy and the KL-divergence [ Cover et al., 1991 ]. Although the latter approach was proposed several decades ago [ Lindley, 1956 , Bernardo, 1979 ], it is not always straightforward to apply the criteria to complicated models such as nonparametric processes with innite parameter spaces. As a result many algorithms exist which compute approximate posterior entropies, perform sampling, or work with related quantities in non-probabilistic models. We return to this problem, presenting the full information criterion and demonstrate how to apply it to Gaussian Processes Classication (GPC), yielding a novel active learning algorithm that makes minimal approximations. GPC is a powerful, non-parametric kernel-based model, and poses an interesting problem for information-theoretic active learning because the parameter space is innite dimensional and the posterior distribution is analytically intractable. We present the information theoretic approach to active learning in Section 2. In Section 3 we apply it to GPC, and show how to extended our method to preference learning. In Section 4 we review other approaches and how they compare to our algorithm. We take particular care to contrast our approach to the Informative Vector Machine, that addresses data point selection for GPs directly. We present results on a wide variety of datasets in Section 5 and conclude in Section 6. 2 Bayesian Information Theoretic Active Learn- ing We consider a fully discriminative model where the goal of active learning is to discover the dependence of some variable y 2 Y on an input variable x 2 X . The key idea in active learning is that the learner chooses the input queries x i 2 X and observes the system’s response y i , rather than passively receiving ( x i y i ) pairs. Within a Bayesian framework we assume existence of some latent param- eters, , that control the dependence between inputs and outputs, p ( y j x ; ). Having observed data D = f ( x i ; y i ) g n i =1 , a posterior distribution over the pa- 2",
      "compressed_prompt": "losses encountered after making decisions based data collected i.e. min- imize Bayes posterior risk Roy McCallum, 2001 ]. Maximising perfor- mance under test ultimate objective most learners, however, evaluat- ing this objective can be very hard. For example, methods proposed Kapoor et al., 2007 Zhu et al., 2003 ] for classication are general expensive compute. Furthermore, one may not know loss function test distribution advance, may want model perform well variety loss functions. In extreme scenarios, such exploratory data analysis, visualisation, losses may be very hard quantify. This motivates information theoretic approaches learning, which are agnostic decision task at hand particular test data, this known inductive approach. They seek reduce number feasible models quickly possible, using either heuristics (e.g. margin sampling Tong Koller, 2001 ]) by formalising uncertainty using well studied quantities, such Shannons entropy KL-divergence Cover et al., 1991 ]. Although latter approach was proposed several decades ago Lindley, 1956 Bernardo, 1979 ], it not always straightforward apply criteria complicated models such nonparametric processes with innite parameter spaces. As result many algorithms exist which compute approximate entropies, perform sampling, work with related quantities non-probabilistic models. We return this problem, presenting full information criterion demonstrate how apply it Gaussian Processes Classication (GPC), yielding novel algorithm makes minimal approximations. GPC powerful, non-parametric kernel-based model, poses interesting problem information-theoretic because parameter space innite dimensional distribution analytically intractable. We present information theoretic approach Section 2. Section 3 we apply it GPC, show how extended our method preference learning. Section 4 we review other approaches how they compare our algorithm. We take particular care contrast our approach Informative Vector Machine, addresses point selection GPs directly. We present results wide variety datasets Section 5 conclude Section 6. Bayesian Information Theoretic Active Learn- ing We consider fully discriminative model where goal discover dependence some variable Y input variable X . The key idea learner chooses input queries X observes system’s response rather than passively receiving ( ) pairs. Within Bayesian framework we assume existence some latent param- eters, that control dependence between inputs outputs, p ( j ; ). Having observed data D = f ( ; ) g n =1 posterior distribution over pa-",
      "original_tokens": 514,
      "compressed_tokens": 359,
      "compression_ratio": 0.6984435797665369,
      "metadata": {
        "paper_id": "benchmark_100_paper_2",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.19
      }
    },
    {
      "test_id": "benchmark_100_paper_3_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "rameters is inferred, p ( jD ). The central goal of information theoretic ac- tive learning is to reduce the number possible hypotheses maximally fast, i.e. to minimize the uncertainty about the parameters using Shannon’s entropy [ Cover et al., 1991 ]. Data points D 0 are selected that satisfy arg min D 0 H[ jD 0 ] = R p ( jD 0 ) log p ( jD 0 )d . Solving this problem in general is NP-hard; however, as is common in sequential decision making tasks a myopic (greedy) approxi- mation is made [ Heckerman et al., 1995 ]. It has been shown that the myopic policy can perform near-optimally [ Golovin and Krause, 2010 , Dasgupta, 2005 ]. Therefore, the objective is to seek the data point x that maximises the decrease in expected posterior entropy: arg max x H[ jD ] E y p ( y j x D ) [H[ j y; x ; D ]] (1) Note that expectation over the unseen output y is required. Many works e.g. [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ] propose using this objective directly. However, parameter posteriors are often high dimen- sional and computing their entropies is usually intractable. Furthermore, for nonparametric processes the parameter space is innite dimensional so Eqn. (1) becomes poorly dened. To avoid gridding parameter space (exponentially hard with dimensionality), or sampling (from which it is notoriously hard to estimate entropies without introducing bias [ Panzeri and Petersen, 2007 ]), these papers make Gaussian or low dimensional approximations and calculate the entropy of the approximate posterior. A second computational diculty arises; if N x data points are under consideration, and N y responses may be seen, then O ( N x N y ), potentially expensive, posterior updates are required to calculate Eqn. (1). An important insight arises if we note that the objective in Eqn. (1) is equivalent to the conditional mutual information between the unknown output and the parameters, I[ ; y j x ; D ]. Using this insight it is simple to show that the objective can be rearranged to compute entropies in y space: arg max x H[ y j x ; D ] E p ( jD ) [H[ y j x ; ]] (2) Eqn. (2) overcomes the challenges we described for Eqn. (1) . Entropies are now calculated in, usually low dimensional, output space. For binary classication, these are just entropies of Bernoulli variables. Also is now conditioned only on D , so only O (1) posterior updates are required. Eqn. (2) also provides us with an interesting intuition about the objective; we seek the x for which the model is marginally most uncertain about y (high H[ y j x ; D ]), but for which individual settings of the parameters are condent (low E p ( jD ) [H[ y j x ; ]] ). This can be interpreted as seeking the x for which the parameters under the posterior disagree about the outcome the most, so we refer to this objective as Bayesian Active Learning by Disagreement (BALD). We present a method to apply Eqn. (2) directly to GPC and preference learning. We no longer need to build our entropy calculation around the type of posterior approximation (as 3",
      "compressed_prompt": "rameters inferred, ). The central goal information theoretic ac- tive learning reduce number possible hypotheses maximally fast, i.e. minimize uncertainty parameters using Shannon’s entropy Cover 1991 Data points selected satisfy arg min H[ = R log )d . Solving problem general NP-hard; however, common sequential decision making tasks a myopic (greedy) approxi- mation made Heckerman 1995 It has been shown myopic policy perform near-optimally Golovin Krause, 2010 Dasgupta, 2005 Therefore, data point maximises decrease expected entropy: max E y; Note expectation over unseen required. Many works e.g. MacKay, 1992 Krishnapuram Lawrence 2003 propose using directly. However, posteriors often high dimen- sional computing their usually intractable. Furthermore, nonparametric processes space innite dimensional becomes poorly dened. To avoid gridding space (exponentially hard dimensionality), sampling (from it notoriously hard estimate without introducing bias Panzeri Petersen, 2007 ]), these papers make Gaussian low dimensional approximations calculate approximate posterior. A second computational diculty arises; if data points consideration, responses may seen, then O ), potentially expensive, updates required calculate (1). An important insight arises if note equivalent conditional mutual information between unknown parameters, I[ Using insight it simple show rearranged compute space: E overcomes challenges described . Entropies now calculated in, usually low dimensional, space. For binary classication, these just Bernoulli variables. Also now conditioned only on O updates required. also provides us an interesting intuition objective; seek model marginally most uncertain (high H[ ]), but individual settings parameters condent (low E ). This interpreted seeking parameters under disagree outcome most, so refer Bayesian Active Learning by Disagreement (BALD). We present a method apply directly GPC preference learning. We no longer need build our entropy calculation around type approximation (as 3",
      "original_tokens": 553,
      "compressed_tokens": 276,
      "compression_ratio": 0.49909584086799275,
      "metadata": {
        "paper_id": "benchmark_100_paper_3",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.2041
      }
    },
    {
      "test_id": "benchmark_100_paper_3_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "rameters is inferred, p ( jD ). The central goal of information theoretic ac- tive learning is to reduce the number possible hypotheses maximally fast, i.e. to minimize the uncertainty about the parameters using Shannon’s entropy [ Cover et al., 1991 ]. Data points D 0 are selected that satisfy arg min D 0 H[ jD 0 ] = R p ( jD 0 ) log p ( jD 0 )d . Solving this problem in general is NP-hard; however, as is common in sequential decision making tasks a myopic (greedy) approxi- mation is made [ Heckerman et al., 1995 ]. It has been shown that the myopic policy can perform near-optimally [ Golovin and Krause, 2010 , Dasgupta, 2005 ]. Therefore, the objective is to seek the data point x that maximises the decrease in expected posterior entropy: arg max x H[ jD ] E y p ( y j x D ) [H[ j y; x ; D ]] (1) Note that expectation over the unseen output y is required. Many works e.g. [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ] propose using this objective directly. However, parameter posteriors are often high dimen- sional and computing their entropies is usually intractable. Furthermore, for nonparametric processes the parameter space is innite dimensional so Eqn. (1) becomes poorly dened. To avoid gridding parameter space (exponentially hard with dimensionality), or sampling (from which it is notoriously hard to estimate entropies without introducing bias [ Panzeri and Petersen, 2007 ]), these papers make Gaussian or low dimensional approximations and calculate the entropy of the approximate posterior. A second computational diculty arises; if N x data points are under consideration, and N y responses may be seen, then O ( N x N y ), potentially expensive, posterior updates are required to calculate Eqn. (1). An important insight arises if we note that the objective in Eqn. (1) is equivalent to the conditional mutual information between the unknown output and the parameters, I[ ; y j x ; D ]. Using this insight it is simple to show that the objective can be rearranged to compute entropies in y space: arg max x H[ y j x ; D ] E p ( jD ) [H[ y j x ; ]] (2) Eqn. (2) overcomes the challenges we described for Eqn. (1) . Entropies are now calculated in, usually low dimensional, output space. For binary classication, these are just entropies of Bernoulli variables. Also is now conditioned only on D , so only O (1) posterior updates are required. Eqn. (2) also provides us with an interesting intuition about the objective; we seek the x for which the model is marginally most uncertain about y (high H[ y j x ; D ]), but for which individual settings of the parameters are condent (low E p ( jD ) [H[ y j x ; ]] ). This can be interpreted as seeking the x for which the parameters under the posterior disagree about the outcome the most, so we refer to this objective as Bayesian Active Learning by Disagreement (BALD). We present a method to apply Eqn. (2) directly to GPC and preference learning. We no longer need to build our entropy calculation around the type of posterior approximation (as 3",
      "compressed_prompt": "rameters inferred, p ). The central goal of information theoretic ac- tive learning reduce number possible hypotheses maximally fast, i.e. minimize uncertainty about parameters using Shannon’s entropy [ Cover et al., 1991 ]. Data points D 0 selected that satisfy arg min D 0 H[ 0 ] = R 0 ) log 0 )d . Solving this problem general NP-hard; however, as common sequential decision making tasks a myopic (greedy) approxi- mation made [ Heckerman et al., 1995 ]. It has been shown myopic policy can perform near-optimally Golovin Krause, 2010 , Dasgupta, 2005 ]. Therefore, seek data point maximises decrease expected posterior entropy: arg max H[ ] E ) [H[ y; ]] Note expectation over unseen output required. Many works e.g. MacKay, 1992 , Krishnapuram et Lawrence et al., 2003 ] propose using this directly. However, parameter posteriors often high dimen- sional computing their entropies usually intractable. Furthermore, nonparametric processes parameter space innite dimensional so Eqn. becomes poorly dened. To avoid gridding parameter space (exponentially hard with dimensionality), or sampling (from which it notoriously hard estimate entropies without introducing bias Panzeri Petersen, 2007 ]), these papers make Gaussian or low dimensional approximations calculate entropy approximate posterior. A second computational diculty arises; if N data points under consideration, N responses may be seen, then O N N ), potentially expensive, updates required calculate Eqn. (1). An important insight arises if we note Eqn. equivalent conditional mutual information between unknown output parameters, I[ ]. Using this insight it simple show can be rearranged compute entropies space: arg max H[ ] E ) [H[ ]] (2) Eqn. (2) overcomes challenges we described Eqn. . Entropies now calculated in, usually low dimensional, output space. For binary classication, these just entropies Bernoulli variables. Also now conditioned only on , so only O updates required. Eqn. (2) also provides us with an interesting intuition about objective; we seek which model marginally most uncertain about (high H[ D ]), but which individual settings parameters condent (low E ) [H[ ]] ). This can be interpreted as seeking which parameters under posterior disagree about outcome most, so we refer this objective as Bayesian Active Learning by Disagreement (BALD). We present a method apply Eqn. (2) directly GPC preference learning. We no longer need build our entropy calculation around type of posterior approximation (as 3",
      "original_tokens": 553,
      "compressed_tokens": 387,
      "compression_ratio": 0.6998191681735986,
      "metadata": {
        "paper_id": "benchmark_100_paper_3",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1946
      }
    },
    {
      "test_id": "benchmark_100_paper_4_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "in [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ]) but are free to choose from many of the available algorithms. Minimal additional approximations are introduced, and so, to our knowledge our algorithm represents the most exact and fastest way to perform full information-theoretic active learning in non-parametric discriminative models. 3 Gaussian Processes for Classication and Pref- erence Learning In this section we derive the BALD algorithm for Gaussian Process classication (GPC). GPs are a powerful and popular non-parametric tool for regression and classication. GPC appears to be an especially challenging problem for information-theoretic active learning because the parameter space is innite, however, by using (2) we are able to calculate fully the relevant information quantities without having to work out entropies of innite dimensional objects. The probabilistic model underlying GPC is as follows: f GP( ( ) ; k ( ; )) y j x ; f Bernoulli(( f ( x ))) The latent parameter, now called f is a function X ! R , and is assigned a Gaussian process prior with mean ( ) and covariance function or kernel k ( ; ). We consider the probit case where given the value of f , y takes a Bernoulli distribution with probability ( f ( x )), and is the Gaussian CDF. For further details on GPs see [Rasmussen and Williams, 2005]. Inference in the GPC model is intractable; given some observations D , the posterior over f becomes non-Gaussian and complicated. The most commonly used approximate inference methods { EP, Laplace approximation, Assumed Density Filtering and sparse methods { all approximate the posterior by a Gaussian [ Rasmussen and Williams, 2005 ]. Throughout this section we will assume that we are provided with such a Gaussian approximation from one of these methods, though the active learning algorithm does not care which one. In our derivation we will use 1 to indicate where such an approximation is exploited. The informativeness of a query x is computed using Eqn. (2) . The entropy of the binary output variable y given a xed f can be expressed in terms of the binary entropy function h: H[ y j x ; f ] = h (( f ( x )) h( p ) = p log p (1 p ) log(1 p ) Expectations over the posterior need to be computed. Using a Gaussian approxi- mation to the posterior, for each x , f x = f ( x ) will follow a Gaussian distribution with mean x ; D and variance 2 x ; D . To compute Eqn. (2) we have to compute 4",
      "compressed_prompt": "[ MacKay, 1992 Krishnapuram et al., Lawrence et al., 2003 ]) but free choose from many available algorithms. Minimal additional approximations introduced, so, knowledge algorithm represents most exact fastest way perform full information-theoretic non-parametric discriminative models. 3 Processes Classication Pref- erence Learning In this section derive BALD Process classication (GPC). GPs powerful popular non-parametric tool regression classication. GPC appears especially challenging problem information-theoretic because parameter space innite, however, able calculate fully relevant information quantities without having work out entropies innite dimensional objects. probabilistic underlying GPC as follows: GP( Bernoulli(( ))) latent parameter, now called X ! R assigned process prior covariance or kernel ). We consider probit case value takes Bernoulli distribution probability )), CDF. For further details on GPs see [Rasmussen Williams, 2005]. Inference GPC intractable; some observations D becomes non-Gaussian complicated. commonly used approximate inference methods EP, Laplace approximation, Assumed Density Filtering sparse methods all approximate Rasmussen Williams, 2005 ]. Throughout section assume that provided approximation one these methods, though does not care which one. derivation use 1 indicate approximation exploited. informativeness query computed Eqn. entropy output variable xed can expressed terms binary entropy h: H[ j ] h (( )) h( log (1 log(1 Expectations over need computed. Using approxi- mation posterior, each follow distribution mean D variance 2 D . To compute Eqn. have compute 4",
      "original_tokens": 440,
      "compressed_tokens": 220,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_100_paper_4",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1659
      }
    },
    {
      "test_id": "benchmark_100_paper_4_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "in [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ]) but are free to choose from many of the available algorithms. Minimal additional approximations are introduced, and so, to our knowledge our algorithm represents the most exact and fastest way to perform full information-theoretic active learning in non-parametric discriminative models. 3 Gaussian Processes for Classication and Pref- erence Learning In this section we derive the BALD algorithm for Gaussian Process classication (GPC). GPs are a powerful and popular non-parametric tool for regression and classication. GPC appears to be an especially challenging problem for information-theoretic active learning because the parameter space is innite, however, by using (2) we are able to calculate fully the relevant information quantities without having to work out entropies of innite dimensional objects. The probabilistic model underlying GPC is as follows: f GP( ( ) ; k ( ; )) y j x ; f Bernoulli(( f ( x ))) The latent parameter, now called f is a function X ! R , and is assigned a Gaussian process prior with mean ( ) and covariance function or kernel k ( ; ). We consider the probit case where given the value of f , y takes a Bernoulli distribution with probability ( f ( x )), and is the Gaussian CDF. For further details on GPs see [Rasmussen and Williams, 2005]. Inference in the GPC model is intractable; given some observations D , the posterior over f becomes non-Gaussian and complicated. The most commonly used approximate inference methods { EP, Laplace approximation, Assumed Density Filtering and sparse methods { all approximate the posterior by a Gaussian [ Rasmussen and Williams, 2005 ]. Throughout this section we will assume that we are provided with such a Gaussian approximation from one of these methods, though the active learning algorithm does not care which one. In our derivation we will use 1 to indicate where such an approximation is exploited. The informativeness of a query x is computed using Eqn. (2) . The entropy of the binary output variable y given a xed f can be expressed in terms of the binary entropy function h: H[ y j x ; f ] = h (( f ( x )) h( p ) = p log p (1 p ) log(1 p ) Expectations over the posterior need to be computed. Using a Gaussian approxi- mation to the posterior, for each x , f x = f ( x ) will follow a Gaussian distribution with mean x ; D and variance 2 x ; D . To compute Eqn. (2) we have to compute 4",
      "compressed_prompt": "in [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ]) but are free choose from many available algorithms. Minimal additional approximations are introduced, so, our knowledge our algorithm represents most exact fastest way perform full information-theoretic active learning in non-parametric discriminative models. 3 Gaussian Processes Classication Pref- erence Learning In this section we derive BALD algorithm Gaussian Process classication (GPC). GPs powerful popular non-parametric tool regression classication. GPC appears be an especially challenging problem information-theoretic active learning because parameter space innite, however, by using (2) able calculate fully relevant information quantities without having work out entropies innite dimensional objects. probabilistic model underlying GPC as follows: GP( k )) y j Bernoulli(( ))) latent parameter, now called function X ! R assigned Gaussian process prior mean covariance function or kernel k ). We consider probit case where given value y takes Bernoulli distribution probability )), Gaussian CDF. For further details on GPs see [Rasmussen Williams, 2005]. Inference GPC model intractable; given some observations D posterior over becomes non-Gaussian complicated. most commonly used approximate inference methods { EP, Laplace approximation, Assumed Density Filtering sparse methods { all approximate posterior by [ Rasmussen Williams, 2005 ]. Throughout this section will assume that provided such approximation from one these methods, though active learning algorithm does not care which one. In our derivation will use 1 indicate where such an approximation exploited. informativeness query computed using Eqn. (2) . entropy binary output variable y given xed can be expressed terms binary entropy function h: H[ y j ] = h (( )) h( p = p log p (1 p log(1 p Expectations over posterior need be computed. Using Gaussian approxi- mation posterior, for each , = ) will follow Gaussian distribution with mean ; D variance 2 ; D . To compute Eqn. (2) we have compute 4",
      "original_tokens": 440,
      "compressed_tokens": 308,
      "compression_ratio": 0.7,
      "metadata": {
        "paper_id": "benchmark_100_paper_4",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1664
      }
    },
    {
      "test_id": "benchmark_100_paper_5_dictionary",
      "technique": "dictionary",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "[RULES]\n- Always expand ⟦n⟧ using DICT[n] before reasoning.\n- Do not print DICT in the result, only use it to understand context.\n\n[DICT]\n1: x ; D\n\n\n[BODY]\ntwo entropy quantities. The rst term in Eqn. (2) , H[ y j ⟦1⟧ ] can be handled analytically for the probit case: H[ y j ⟦1⟧ ] 1 h Z ( f x ) N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) df x = h 0 @ 0 @ ⟦1⟧ 2 ⟦1⟧ + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) df x = C 2 ⟦1⟧ + C 2 exp 0 @ 2 ⟦1⟧ 2 2 ⟦1⟧ + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) is centred at ⟦1⟧ = 2 : 05 with 2 ⟦1⟧ tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean ⟦1⟧ and ⟦1⟧ for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ ⟦1⟧ 2 ⟦1⟧ + 1 1 A 1 A C exp 2 ⟦1⟧ 2 ( 2 ⟦1⟧ + C 2 ) 2 ⟦1⟧ + C 2 (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 490,
      "compression_ratio": 0.9626718759536743,
      "metadata": {
        "paper_id": "benchmark_100_paper_5",
        "dictionary_entries": 1,
        "substitutions": 24,
        "processing_time_ms": 1.0406
      }
    },
    {
      "test_id": "benchmark_100_paper_5_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y ] can be handled analytically probit case: H[ y ] h Z N df = h @ @ (3) second term, E p jD [H[ y ]] can be computed approximately as follows: E p jD [H[ y ]] Z h(( )) N df (4) Z ln N df exp @ where q . rst approximation, , reects Gaussian ap- proximation posterior. integral left hand side Eqn. (4) is intractable. By performing Taylor expansion on ln h(( )) (see supplementary material) we see that it approximated up O 4 by squared exponential curve, exp ln 2). We will refer approximation . Now we apply standard convolution formula Gaussians nally get closed form expression both terms Eqn. (2). Fig. depicts striking accuracy simple approximation. max- imum possible error that will incurred when using approximation is if N centred at : 05 with tending zero (see Fig. 1, absolute error ), yielding only 0.27% error integral Eqn. (4) . authors are unaware previous use simple and useful approximation context. In Section 5 we investigate experimentally information lost from approximations and compared golden standard extensive Monte Carlo simulation. To summarise, BALD algorithm Gaussian process classication con- sists two steps. First it applies any standard approximate inference algorithm GPCs (such as EP) obtain posterior predictive mean and each point interest . Then, it selects query that maximises following objective function: h 0 @ 0 @ + A A C exp + C + C (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 254,
      "compression_ratio": 0.49901768172888017,
      "metadata": {
        "paper_id": "benchmark_100_paper_5",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.16369999999999998
      }
    },
    {
      "test_id": "benchmark_100_paper_5_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j D ] can be handled analytically for the probit case: H[ y j D ] 1 h Z ( ) N ( j D ) df = h 0 @ 0 @ + 1 1 A 1 A (3) The second term, E p ( jD ) [H[ y j ]] can be computed approximately as follows: E p ( jD ) [H[ y j ]] Z h(( )) N j ) df (4) Z exp ln N j ) df = C + C exp 0 @ + C A where C = q . The rst approximation, , reects Gaussian ap- proximation to posterior. The integral in left hand side Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( )) (see supplementary material) we can see that it can be approximated up to O ( 4 ) by a squared exponential curve, exp ( = ln 2). We will refer to this approximation as . Now we can apply standard convolution formula for Gaussians to nally get a closed form expression for both terms Eqn. (2). Fig. depicts striking accuracy this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( j ) is centred at = : 05 with tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in integral in Eqn. (4) . The authors are unaware previous use this simple and useful approximation in this context. In Section 5 we investigate experimentally information lost from approximations and as compared to golden standard extensive Monte Carlo simulation. To summarise, BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain posterior predictive mean and for each point of interest . Then, it selects a query that maximises the following objective function: h 0 @ 0 @ D D + 1 1 A 1 A C exp D ( D + C ) D + C (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 356,
      "compression_ratio": 0.6994106090373281,
      "metadata": {
        "paper_id": "benchmark_100_paper_5",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1572
      }
    },
    {
      "test_id": "benchmark_100_paper_5_hybrid",
      "technique": "hybrid",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "[RULES] - Always expand ⟦n⟧ using DICT[n] before reasoning. - Do not print DICT result, only use it understand context. [DICT] 1: D [BODY] two entropy quantities. rst term Eqn. (2) , H[ y ] handled analytically probit case: H[ y ] h Z N df h @ @ (3) second term, E p jD [H[ ]] computed approximately follows: E p jD [H[ ]] Z h(( )) N (4) Z N where q rst approximation, , reects Gaussian ap- proximation posterior. integral left hand side Eqn. (4) intractable. By performing Taylor expansion on ln h(( )) (see supplementary material) we see that approximated up O 4 by squared exponential curve, ln 2). We will refer approximation Now we apply standard convolution formula Gaussians nally get closed form expression both terms Eqn. (2). Fig. depicts striking accuracy simple approximation. max- imum possible error that will incurred when using approximation if N centred at : 05 with tending zero (see Fig. 1, absolute error ), yielding only 0.27% error integral Eqn. (4) authors are unaware previous use simple useful approximation context. In Section 5 we investigate experimentally information lost from approximations compared golden standard extensive Monte Carlo simulation. To summarise, BALD algorithm Gaussian process classication con- sists two steps. First it applies any standard approximate inference algorithm GPCs (such EP) obtain posterior predictive mean each point interest . Then, it selects query that maximises following objective function: h @ @ C exp C C (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 245,
      "compression_ratio": 0.481335952848723,
      "metadata": {
        "paper_id": "benchmark_100_paper_5",
        "dictionary_entries": 1,
        "substitutions": 24,
        "processing_time_ms": 1.2463000000000002
      }
    },
    {
      "test_id": "benchmark_100_paper_6_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "h (( )) exp( t 2 log(2) ) 5 10 3 dierence Figure 1: Analytic approximation ( 1 ) to the binary entropy of the error function ( ) by a squared exponential ( ). The absolute error ( ) remains under 3 10 3 . For most practically relevant kernels, the objective (5) is a smooth and dierentiable function of x , so gradient-based optimisation procedures can be used to nd the maximally informative query. 3.1 Extension: Learning Hyperparameters In many applications the parameter set naturally divides into parameters of interest, + , and nuisance parameters , i.e. = f + ; g . In such settings, the active learning may want to query points that are maximally informative about + , while not caring about . By integrating Eqn. (1) over the nuisance parameters, , BALD’s objective is re-derived as: H E p ( + ; jD ) y j x ; + ; E p ( + jD ) H E p ( j + ; D ) [ y j x ; + ; ] (6) In the context of GP models, hyperparameters typically control the smooth- ness or spatial length-scale of functions. If we maintain a posterior distribution over these hyperparameters, which we can do e. g. via Hamiltonian Monte Carlo, we can choose either to treat them as nuisance parameters and use Eq. 6, or to include them in + and perform active learning over them as well. In certain cases, such as automatic relevance determination [ Rasmussen and Williams, 2005 ], it may even make sense to treat hyperparameters as variables of primary interest, and the function f itself as nuisance parameter . 3.2 Preference Learning Our active learning framework for GPC can be extended to the important problem of preference learning [ Furnkranz and Hullermeier, 2003 , Chu and Ghahramani, 2005 ]. In preference learning the dataset consists for pairs of items ( u i ; v i ) 2 X 2 with binary labels, y i 2 f 0 ; 1 g . y i = 1 means instance u i is preferred to v i , denoted u i v i . The task is to predict the preference relation between any ( u ; v ). We can view this as a special case of building a classier on pairs of inputs 6",
      "compressed_prompt": "h (( )) exp( t log(2) 5 10 3 dierence Figure 1: Analytic approximation 1 binary entropy error function by squared exponential ). The absolute error remains under 10 For most practically relevant kernels, objective (5) smooth dierentiable so gradient-based optimisation procedures used nd maximally informative query. 3.1 Extension: Learning Hyperparameters many applications parameter set naturally divides into interest, i.e. = g such settings, may want query points that are maximally informative about while not caring about By integrating Eqn. (1) parameters, BALD’s objective re-derived as: H E jD E H E D ] (6) context GP models, hyperparameters typically control smooth- ness spatial length-scale functions. If maintain posterior distribution these hyperparameters, which do e. g. via Hamiltonian Monte Carlo, choose either treat use Eq. 6, include in perform well. certain cases, automatic relevance determination Rasmussen Williams, ], it even make sense hyperparameters variables primary interest, itself parameter 3.2 Preference Learning Our framework GPC extended important problem Furnkranz Hullermeier, 2003 Chu Ghahramani, ]. dataset consists pairs items X with binary labels, 0 g = means instance preferred denoted The task predict preference relation between any ). We view this special case building classier on pairs inputs 6",
      "original_tokens": 394,
      "compressed_tokens": 197,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_100_paper_6",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.14229999999999998
      }
    },
    {
      "test_id": "benchmark_100_paper_6_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "h (( )) exp( t 2 log(2) ) 5 10 3 dierence Figure 1: Analytic approximation ( 1 ) to the binary entropy of the error function ( ) by a squared exponential ( ). The absolute error ( ) remains under 3 10 3 . For most practically relevant kernels, the objective (5) is a smooth and dierentiable function of x , so gradient-based optimisation procedures can be used to nd the maximally informative query. 3.1 Extension: Learning Hyperparameters In many applications the parameter set naturally divides into parameters of interest, + , and nuisance parameters , i.e. = f + ; g . In such settings, the active learning may want to query points that are maximally informative about + , while not caring about . By integrating Eqn. (1) over the nuisance parameters, , BALD’s objective is re-derived as: H E p ( + ; jD ) y j x ; + ; E p ( + jD ) H E p ( j + ; D ) [ y j x ; + ; ] (6) In the context of GP models, hyperparameters typically control the smooth- ness or spatial length-scale of functions. If we maintain a posterior distribution over these hyperparameters, which we can do e. g. via Hamiltonian Monte Carlo, we can choose either to treat them as nuisance parameters and use Eq. 6, or to include them in + and perform active learning over them as well. In certain cases, such as automatic relevance determination [ Rasmussen and Williams, 2005 ], it may even make sense to treat hyperparameters as variables of primary interest, and the function f itself as nuisance parameter . 3.2 Preference Learning Our active learning framework for GPC can be extended to the important problem of preference learning [ Furnkranz and Hullermeier, 2003 , Chu and Ghahramani, 2005 ]. In preference learning the dataset consists for pairs of items ( u i ; v i ) 2 X 2 with binary labels, y i 2 f 0 ; 1 g . y i = 1 means instance u i is preferred to v i , denoted u i v i . The task is to predict the preference relation between any ( u ; v ). We can view this as a special case of building a classier on pairs of inputs 6",
      "compressed_prompt": "h (( )) exp( t 2 log(2) 5 10 3 dierence Figure 1: Analytic approximation 1 binary entropy error function by a squared exponential ). The absolute error remains under 3 10 3 For most practically relevant kernels, objective (5) is smooth dierentiable function x so gradient-based optimisation procedures can be used nd maximally informative query. 3.1 Extension: Learning Hyperparameters many applications parameter set naturally divides into parameters interest, nuisance parameters i.e. = f g such settings, active may want query points that are maximally informative about while not caring about By integrating Eqn. (1) over nuisance parameters, BALD’s objective re-derived as: H E p jD y j x E p jD H E p j D [ y j x ] (6) context GP models, hyperparameters typically control smooth- ness or spatial length-scale functions. If we maintain posterior distribution over these hyperparameters, which we do e. g. via Hamiltonian Monte Carlo, we choose either treat them nuisance parameters use Eq. 6, or include them in perform active over them well. certain cases, such automatic relevance determination [ Rasmussen Williams, 2005 ], it may even make sense treat hyperparameters variables primary interest, function f itself nuisance parameter 3.2 Preference Learning Our active framework for GPC be extended important problem preference [ Furnkranz Hullermeier, 2003 Chu Ghahramani, 2005 ]. preference dataset consists for pairs items u v 2 X 2 with binary labels, y 2 f 0 1 g y = 1 means instance u is preferred v denoted u v . The task is predict preference relation between any u v ). We can view this a special case building classier on pairs inputs 6",
      "original_tokens": 394,
      "compressed_tokens": 275,
      "compression_ratio": 0.6979695431472082,
      "metadata": {
        "paper_id": "benchmark_100_paper_6",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.13190000000000002
      }
    },
    {
      "test_id": "benchmark_100_paper_7_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "2 noise = 1. The likelihood only depends on the dierence between f ( u ) and f ( v ). We therefore dene g ( u ; v ) = f ( u ) f ( v ), and do inference entirely in terms of g , for which the likelihood becomes the same as for probit classication: y j u ; v ; f Bernoulli (( g ( u ; v ))). We observe that a GP prior is induced on g because it is formed by performing a linear operation on f , for which we have a GP prior already f GP (0 ; k ). We can derive the induced covariance function of g as (derivation in the Supplementary material) as: k pref (( u i ; v i ) ; ( u j ; v j )) = k ( u i ; u j ) + k ( v i ; v j ) k ( u i ; v j ) k ( v i ; u j ). Note that this kernel k pref respects the anti-symmetry properties desired for a preference learning scenario, i.e. the value g ( u; v ) is perfectly anti-correlated with g ( v; u ), ensuring P [ u v ] = 1 P [ v u ] holds. Thus, we can conclude that the GP preference learning framework of [ Chu and Ghahramani, 2005 ], is equivalent to GPC with a particular class of kernels, that we may call the preference judgement kernels . Therefore, our active learning algorithm presented in Section 3 for GPC can readily be applied to pairwise preference learning also. 4 Related Methodologies There are a number of closely related algorithms for active classication which we now review. The Informative Vector Machine (IVM): Perhaps the most closely re- lated approach is the IVM [ Lawrence et al., 2003 ]. This popular,and successful approach to active learning was designed specically for GPs; it uses an infor- mation theoretic approach and so appears very similar to BALD. The IVM algorithm was designed for subsampling a dataset for training a GP, so it is privy to the y values before including a measurement; it cannot therefore work explic- itly in output space i.e. with Eqn. (2) . The IVM uses Eqn. (1) , but parameter entropies are calculated approximately in the marginal subspace corresponding to the observed data points. The entropy decrease after inclusion of a new data point can then be calculated eciently using the GP covariance matrix. Although the IVM and BALD are motivated by the same objective, they work fundamentally dierently when approximate inference is carried out. At any time 7",
      "compressed_prompt": "2 noise 1. likelihood only depends dierence between ). We therefore dene ), do inference entirely terms , likelihood becomes same as probit classication: y Bernoulli (( ))). We observe GP prior induced because formed by performing linear operation have prior already (0 We derive induced covariance function (derivation Supplementary material) as: pref (( )) + Note this kernel pref respects anti-symmetry properties desired scenario, i.e. value u; perfectly anti-correlated v; ), ensuring P ] 1 P ] holds. Thus, conclude GP framework Chu Ghahramani, 2005 ], equivalent GPC particular class kernels, may call judgement kernels . Therefore, our algorithm presented Section 3 GPC readily applied pairwise also. 4 Related Methodologies There number closely related algorithms classication now review. Informative Vector Machine (IVM): Perhaps most closely re- lated IVM Lawrence et al., 2003 ]. This popular,and successful designed specically GPs; uses an infor- mation theoretic so appears very similar BALD. IVM algorithm designed subsampling dataset training GP, so privy y values before including measurement; cannot therefore work explic- itly output space i.e. Eqn. (2) . IVM uses Eqn. (1) but parameter entropies calculated approximately marginal subspace corresponding observed data points. entropy decrease after inclusion new data point then be calculated eciently using GP covariance matrix. Although IVM BALD motivated by same objective, they work fundamentally dierently when approximate inference carried out. At any time 7",
      "original_tokens": 451,
      "compressed_tokens": 225,
      "compression_ratio": 0.49889135254988914,
      "metadata": {
        "paper_id": "benchmark_100_paper_7",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1613
      }
    },
    {
      "test_id": "benchmark_100_paper_7_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "2 noise = 1. The likelihood only depends on the dierence between f ( u ) and f ( v ). We therefore dene g ( u ; v ) = f ( u ) f ( v ), and do inference entirely in terms of g , for which the likelihood becomes the same as for probit classication: y j u ; v ; f Bernoulli (( g ( u ; v ))). We observe that a GP prior is induced on g because it is formed by performing a linear operation on f , for which we have a GP prior already f GP (0 ; k ). We can derive the induced covariance function of g as (derivation in the Supplementary material) as: k pref (( u i ; v i ) ; ( u j ; v j )) = k ( u i ; u j ) + k ( v i ; v j ) k ( u i ; v j ) k ( v i ; u j ). Note that this kernel k pref respects the anti-symmetry properties desired for a preference learning scenario, i.e. the value g ( u; v ) is perfectly anti-correlated with g ( v; u ), ensuring P [ u v ] = 1 P [ v u ] holds. Thus, we can conclude that the GP preference learning framework of [ Chu and Ghahramani, 2005 ], is equivalent to GPC with a particular class of kernels, that we may call the preference judgement kernels . Therefore, our active learning algorithm presented in Section 3 for GPC can readily be applied to pairwise preference learning also. 4 Related Methodologies There are a number of closely related algorithms for active classication which we now review. The Informative Vector Machine (IVM): Perhaps the most closely re- lated approach is the IVM [ Lawrence et al., 2003 ]. This popular,and successful approach to active learning was designed specically for GPs; it uses an infor- mation theoretic approach and so appears very similar to BALD. The IVM algorithm was designed for subsampling a dataset for training a GP, so it is privy to the y values before including a measurement; it cannot therefore work explic- itly in output space i.e. with Eqn. (2) . The IVM uses Eqn. (1) , but parameter entropies are calculated approximately in the marginal subspace corresponding to the observed data points. The entropy decrease after inclusion of a new data point can then be calculated eciently using the GP covariance matrix. Although the IVM and BALD are motivated by the same objective, they work fundamentally dierently when approximate inference is carried out. At any time 7",
      "compressed_prompt": "2 noise = 1. The likelihood only depends on dierence between f ) and f ). We therefore dene g ) = f ) f ), and do inference entirely in terms of g , which likelihood becomes same as probit classication: y j f Bernoulli (( g ))). We observe that GP prior induced on g because it formed by performing linear operation on , which we have GP prior already GP (0 ). We can derive induced covariance function as (derivation Supplementary material) as: pref (( i )) = + ). Note that this kernel pref respects anti-symmetry properties desired preference learning scenario, i.e. value u; perfectly anti-correlated with v; ), ensuring P [ ] = 1 P [ ] holds. Thus, we can conclude that GP preference learning framework [ Chu Ghahramani, 2005 ], equivalent GPC with particular class kernels, that we may call preference judgement kernels . Therefore, our active learning algorithm presented Section 3 GPC can readily be applied pairwise preference learning also. 4 Related Methodologies There are number closely related algorithms active classication which we now review. The Informative Vector Machine (IVM): Perhaps most closely re- lated approach IVM [ Lawrence et al., 2003 ]. This popular,and successful approach active learning was designed specically GPs; it uses an infor- mation theoretic approach so appears very similar BALD. The IVM algorithm was designed subsampling dataset training GP, so it privy to y values before including measurement; it cannot therefore work explic- itly in output space i.e. with Eqn. (2) . The IVM uses Eqn. (1) , but parameter entropies are calculated approximately in marginal subspace corresponding observed data points. The entropy decrease after inclusion of new data point can then be calculated eciently using GP covariance matrix. Although IVM and BALD are motivated by same objective, they work fundamentally dierently when approximate inference is carried out. At any time 7",
      "original_tokens": 451,
      "compressed_tokens": 315,
      "compression_ratio": 0.6984478935698448,
      "metadata": {
        "paper_id": "benchmark_100_paper_7",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1548
      }
    },
    {
      "test_id": "benchmark_100_paper_8_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "Z q t ( jD ) p ( y t +1 j f; x t +1 ). If the posterior at t + 1 is approximated directly one gets q t +1 ( jD ; x t +1 ; y t +1 ). BALD calculates the entropy dierence between q t and ^ p t +1 , without having to compute q t +1 for each candidate x . In contrast, the IVM calculates the entropy change between q t and q t +1 . The IVM’s ap- proach cannot calculate the entropy of the full innite dimensional posterior, and requires O ( N x N y ) posterior updates. To do these updates eciently, ap- proximate inference is performed using Assumed Density Filtering (ADF). Using ADF means that q t +1 is a direct approximation to ^ p t +1 , indicating that the IVM makes a further approximation to BALD. Since BALD only requires O (1) posterior updates it can aord to use more accurate, iterative procedures, such as EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) [ Sebastiani and Wynn, 2000 ] explicitly works in dataspace (Eqn. (2) ). MES was proposed for regression models with input-independent observation noise. Al- though Eqn. (2) is used, the second term is constant because of input independent noise and is ignored. One cannot, however, use MES for heteroscedastic re- gression or classication; it fails to dierentiate between model uncertainty and observation uncertainty (about which our model may be condent). Some toy demonstrations show this ‘information based’ active learning criterion performing pathologically in classication by repeatedly querying points close the decision boundary or in regions of high observation uncertainty e.g. [ Huang et al., 2010 ]. This is because MES is inappropriate in this domain; BALD distinguishes be- tween observation and model uncertainty and eliminates these problems as we will show. Mutual-information based objective functions are presented in [ Ertin et al., , Fuhrmann, 2003 ]. They maximise the mutual information between the variable being measured and the variable of interest. Fuhrmann [ Fuhrmann, 2003 ] applies this to linear Gaussian models and acoustic arrays, Ertin et al. [ Ertin et al., ] to a communications channel. Although related, these objectives do not work with the model parameters and are not applied to classication. [ Guestrin et al., 2005 , Krause et al., 2006 ] also use mutual information. They specify interest points in advance and maximise the expected mutual information between the predictive distributions at these points and at the observed locations. Although this is a objective is promising for regression, it is not tractable for models with input-dependent observation noise, such as classication or preference learning. Decision theoretic: We briey mention decision theoretic approaches to ac- tive learning. Two closely related algorithms, [ Kapoor et al., 2007 , Zhu et al., 2003 ], seek to minimize the expected cost i.e. loss weighted misclassication probability on all seen and future data. These methods observe the locations of the test points and their objective functions become monotonic in the predictive entropies at the test points. [ Kapoor et al., 2007 ] also includes an empirical error term 8",
      "compressed_prompt": "Z jD ) j f; If posterior + 1 approximated directly one gets jD ; ; BALD calculates entropy dierence ^ without having compute each candidate . In contrast, IVM calculates change . The IVM’s ap- proach cannot calculate full innite dimensional posterior, requires O N N updates. To updates eciently, proximate inference performed using Assumed Density Filtering (ADF). Using ADF means direct indicating IVM makes further BALD. Since BALD only O (1) can aord more accurate, iterative procedures, EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) Sebastiani Wynn, 2000 explicitly works dataspace (Eqn. MES was proposed regression input-independent noise. Al- though Eqn. used, second constant input independent noise ignored. One cannot, however, MES heteroscedastic re- gression classication; fails dierentiate (about which our may be condent). Some toy demonstrations show ‘information based’ active learning criterion performing pathologically by repeatedly querying close boundary regions high e.g. Huang 2010 This MES inappropriate domain; BALD distinguishes be- tween eliminates problems we will show. Mutual-information based presented Fuhrmann, They being measured interest. Fuhrmann Fuhrmann, applies linear Gaussian acoustic arrays, al. communications channel. Although related, objectives work parameters applied classication. Guestrin 2005 Krause 2006 information. They specify interest advance distributions observed locations. Although promising regression, tractable input-dependent noise, such classication preference learning. Decision theoretic: We briey mention decision theoretic approaches ac- tive learning. Two closely related algorithms, Kapoor 2007 Zhu ], seek minimize expected cost i.e. loss weighted misclassication probability on all seen future data. These methods observe locations test their objective functions become monotonic predictive entropies test points. Kapoor 2007 also includes an empirical error term 8",
      "original_tokens": 527,
      "compressed_tokens": 263,
      "compression_ratio": 0.4990512333965844,
      "metadata": {
        "paper_id": "benchmark_100_paper_8",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.195
      }
    },
    {
      "test_id": "benchmark_100_paper_8_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "Z q t ( jD ) p ( y t +1 j f; x t +1 ). If the posterior at t + 1 is approximated directly one gets q t +1 ( jD ; x t +1 ; y t +1 ). BALD calculates the entropy dierence between q t and ^ p t +1 , without having to compute q t +1 for each candidate x . In contrast, the IVM calculates the entropy change between q t and q t +1 . The IVM’s ap- proach cannot calculate the entropy of the full innite dimensional posterior, and requires O ( N x N y ) posterior updates. To do these updates eciently, ap- proximate inference is performed using Assumed Density Filtering (ADF). Using ADF means that q t +1 is a direct approximation to ^ p t +1 , indicating that the IVM makes a further approximation to BALD. Since BALD only requires O (1) posterior updates it can aord to use more accurate, iterative procedures, such as EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) [ Sebastiani and Wynn, 2000 ] explicitly works in dataspace (Eqn. (2) ). MES was proposed for regression models with input-independent observation noise. Al- though Eqn. (2) is used, the second term is constant because of input independent noise and is ignored. One cannot, however, use MES for heteroscedastic re- gression or classication; it fails to dierentiate between model uncertainty and observation uncertainty (about which our model may be condent). Some toy demonstrations show this ‘information based’ active learning criterion performing pathologically in classication by repeatedly querying points close the decision boundary or in regions of high observation uncertainty e.g. [ Huang et al., 2010 ]. This is because MES is inappropriate in this domain; BALD distinguishes be- tween observation and model uncertainty and eliminates these problems as we will show. Mutual-information based objective functions are presented in [ Ertin et al., , Fuhrmann, 2003 ]. They maximise the mutual information between the variable being measured and the variable of interest. Fuhrmann [ Fuhrmann, 2003 ] applies this to linear Gaussian models and acoustic arrays, Ertin et al. [ Ertin et al., ] to a communications channel. Although related, these objectives do not work with the model parameters and are not applied to classication. [ Guestrin et al., 2005 , Krause et al., 2006 ] also use mutual information. They specify interest points in advance and maximise the expected mutual information between the predictive distributions at these points and at the observed locations. Although this is a objective is promising for regression, it is not tractable for models with input-dependent observation noise, such as classication or preference learning. Decision theoretic: We briey mention decision theoretic approaches to ac- tive learning. Two closely related algorithms, [ Kapoor et al., 2007 , Zhu et al., 2003 ], seek to minimize the expected cost i.e. loss weighted misclassication probability on all seen and future data. These methods observe the locations of the test points and their objective functions become monotonic in the predictive entropies at the test points. [ Kapoor et al., 2007 ] also includes an empirical error term 8",
      "compressed_prompt": "Z ( jD ) p ( y j f; x ). If posterior at + 1 approximated directly one gets ( jD ; x ; y ). BALD calculates entropy dierence between ^ p , without having compute each candidate x . In contrast, IVM calculates entropy change between . The IVM’s ap- proach cannot calculate entropy full innite dimensional posterior, requires O ( N x N y ) posterior updates. To do these updates eciently, ap- proximate inference performed using Assumed Density Filtering (ADF). Using ADF means that direct approximation ^ p indicating that IVM makes further approximation BALD. Since BALD only requires O (1) posterior updates it can aord use more accurate, iterative procedures, such as EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) Sebastiani Wynn, 2000 explicitly works dataspace (Eqn. (2) ). MES was proposed regression models with input-independent noise. Al- though Eqn. (2) used, second term constant because input independent noise ignored. One cannot, however, use MES heteroscedastic re- gression or classication; it fails dierentiate uncertainty uncertainty (about which our model may be condent). Some toy demonstrations show this ‘information based’ active learning criterion performing pathologically classication by repeatedly querying points close decision boundary or regions high uncertainty e.g. Huang 2010 ]. This because MES inappropriate this domain; BALD distinguishes be- tween uncertainty eliminates problems as we will show. Mutual-information based objective functions are presented Ertin Fuhrmann, 2003 ]. They maximise mutual information variable being measured variable interest. Fuhrmann Fuhrmann, 2003 applies this linear Gaussian models acoustic arrays, Ertin al. Ertin communications channel. Although related, objectives do not work with parameters are not applied classication. Guestrin 2005 Krause 2006 also use mutual information. They specify interest advance maximise expected mutual information predictive distributions observed locations. Although this objective promising regression, it not tractable models with input-dependent observation noise, such as classication or preference learning. Decision theoretic: We briey mention decision theoretic approaches ac- tive learning. Two closely related algorithms, Kapoor 2007 Zhu 2003 ], seek minimize expected cost i.e. loss weighted misclassication probability on all seen future data. These methods observe locations test points their objective functions become monotonic predictive entropies at test points. Kapoor 2007 ] also includes an empirical error term 8",
      "original_tokens": 527,
      "compressed_tokens": 368,
      "compression_ratio": 0.698292220113852,
      "metadata": {
        "paper_id": "benchmark_100_paper_8",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.2006
      }
    },
    {
      "test_id": "benchmark_100_paper_9_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "EP ( 1 ) Laplace ( 1 ) 7 : 51 2 : 51 41 : 57 4 : 02 0 : 16 0 : 05 7 : 43 2 : 40 40 : 45 3 : 67 Figure 2: Percentage approximation error ( 1 s.d.) for dierent methods of approximate inference ( columns ) and approximation methods for evaluating Eqn. (4) ( rows ). The results indicate that 2 is a very accurate approximation; EP causes some loss and Laplace signicantly more, which is in line with the comparison presented in [ Kuss and Rasmussen, 2005 ]. For our experiments we use EP. that can yield pathological behaviour (we investigate this experimentally). These approaches are computationally expensive, requiring O ( N x N y ) posterior updates. Also, they must know the locations of the test data (and thus are transductive approaches); designing an inductive, decision-theoretic algorithm is an open, hard problem as it would require expensive integration over possible test data distributions. Non-probabilistic Some non-probabilistic methods have close analogues to information theoretic active learning. Perhaps the most ubiquitous is active learning for SVMs [ Tong and Koller, 2001 , Seung et al., 1992 ], where the volume of Version Space (VS) is used as a proxy for the posterior entropy. If a uniform (improper) prior is used with a deterministic classication likelihood, the log volume of VS and Bayesian posterior entropy are in fact equivalent. Just as Bayesian posteriors become intractable after observing many data points, VS can become complicated. [ Tong and Koller, 2001 ] proposes methods for approximat- ing VS with a simple shapes, such as hyperspheres (their simplest approximation reduces to margin sampling). This closely resembles approximating a Bayesian posterior using a Gaussian distribution via the Laplace or EP approximations. [ Seung et al., 1992 ] sidesteps the problem by working with predictions. The al- gorithm, Query by Committee (QBC), samples parameters from VS (committee members), they vote on the outcome of each possible x . The x with the most balanced vote is selected; this is termed the ‘principle of maximal disagreement’. If BALD is used with a sampled posterior, query by committee is implemented but with a probabilistic measure of disagreement. QBC’s deterministic vote criterion discards condence in the predictions and so can exhibit the same pathologies as MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) we made two approx- imations: we perform approximate inference ( 1 ), and we approximated the binary entropy of the Gaussian CDF by a squared exponential ( 2 ). Both of these can be substituted with Monte Carlo sampling, enabling us to compute 9",
      "compressed_prompt": "EP 41 57 4 02 16 05 43 45 3 67 Figure 2: Percentage error s.d.) dierent columns evaluating Eqn. (4) rows results indicate very accurate approximation; EP causes some loss signicantly more, which line comparison presented Kuss Rasmussen, 2005 ]. For our experiments use EP. yield pathological behaviour (we investigate experimentally). These approaches computationally expensive, requiring O y updates. Also, must know locations (and thus transductive approaches); designing inductive, decision-theoretic algorithm open, hard it would require expensive integration over distributions. Non-probabilistic Some non-probabilistic have close analogues information theoretic learning. Perhaps ubiquitous learning SVMs Tong Koller, , Seung ], where Version Space (VS) proxy entropy. If uniform (improper) prior classication likelihood, log fact equivalent. Just posteriors intractable after observing many points, complicated. Tong Koller, proposes approximat- ing simple shapes, such hyperspheres (their simplest reduces margin sampling). This closely resembles approximating using distribution via approximations. sidesteps working predictions. al- gorithm, Query Committee (QBC), samples parameters (committee members), outcome each . balanced selected; termed ‘principle maximal disagreement’. BALD sampled posterior, query committee implemented but probabilistic measure disagreement. QBC’s criterion discards condence predictions so exhibit same pathologies MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) made two approx- imations: perform approximate inference ), approximated binary entropy Gaussian CDF squared exponential Both these be substituted Monte Carlo sampling, enabling us compute 9",
      "original_tokens": 438,
      "compressed_tokens": 219,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_100_paper_9",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1685
      }
    },
    {
      "test_id": "benchmark_100_paper_9_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "EP ( 1 ) Laplace ( 1 ) 7 : 51 2 : 51 41 : 57 4 : 02 0 : 16 0 : 05 7 : 43 2 : 40 40 : 45 3 : 67 Figure 2: Percentage approximation error ( 1 s.d.) for dierent methods of approximate inference ( columns ) and approximation methods for evaluating Eqn. (4) ( rows ). The results indicate that 2 is a very accurate approximation; EP causes some loss and Laplace signicantly more, which is in line with the comparison presented in [ Kuss and Rasmussen, 2005 ]. For our experiments we use EP. that can yield pathological behaviour (we investigate this experimentally). These approaches are computationally expensive, requiring O ( N x N y ) posterior updates. Also, they must know the locations of the test data (and thus are transductive approaches); designing an inductive, decision-theoretic algorithm is an open, hard problem as it would require expensive integration over possible test data distributions. Non-probabilistic Some non-probabilistic methods have close analogues to information theoretic active learning. Perhaps the most ubiquitous is active learning for SVMs [ Tong and Koller, 2001 , Seung et al., 1992 ], where the volume of Version Space (VS) is used as a proxy for the posterior entropy. If a uniform (improper) prior is used with a deterministic classication likelihood, the log volume of VS and Bayesian posterior entropy are in fact equivalent. Just as Bayesian posteriors become intractable after observing many data points, VS can become complicated. [ Tong and Koller, 2001 ] proposes methods for approximat- ing VS with a simple shapes, such as hyperspheres (their simplest approximation reduces to margin sampling). This closely resembles approximating a Bayesian posterior using a Gaussian distribution via the Laplace or EP approximations. [ Seung et al., 1992 ] sidesteps the problem by working with predictions. The al- gorithm, Query by Committee (QBC), samples parameters from VS (committee members), they vote on the outcome of each possible x . The x with the most balanced vote is selected; this is termed the ‘principle of maximal disagreement’. If BALD is used with a sampled posterior, query by committee is implemented but with a probabilistic measure of disagreement. QBC’s deterministic vote criterion discards condence in the predictions and so can exhibit the same pathologies as MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) we made two approx- imations: we perform approximate inference ( 1 ), and we approximated the binary entropy of the Gaussian CDF by a squared exponential ( 2 ). Both of these can be substituted with Monte Carlo sampling, enabling us to compute 9",
      "compressed_prompt": "EP 1 ) Laplace 1 ) 7 51 2 51 41 57 4 02 0 16 0 05 7 43 2 40 40 45 3 67 Figure 2: Percentage approximation error s.d.) dierent methods approximate inference columns approximation methods evaluating Eqn. (4) rows ). The results indicate that very accurate approximation; EP causes some loss Laplace signicantly more, which line comparison presented Kuss Rasmussen, 2005 ]. For our experiments use EP. that yield pathological behaviour (we investigate this experimentally). These approaches computationally expensive, requiring O N N y updates. Also, they must know locations test (and thus transductive approaches); designing an inductive, decision-theoretic algorithm an open, hard problem it would require expensive integration over possible test data distributions. Non-probabilistic Some non-probabilistic have close analogues information theoretic active learning. Perhaps most ubiquitous active learning SVMs Tong Koller, 2001 , Seung et al., 1992 ], where volume Version Space (VS) proxy entropy. If uniform (improper) prior deterministic classication likelihood, log volume VS Bayesian entropy fact equivalent. Just Bayesian posteriors become intractable after observing many points, VS become complicated. Tong Koller, 2001 ] proposes approximat- ing VS simple shapes, such hyperspheres (their simplest approximation reduces margin sampling). This closely resembles approximating Bayesian using Gaussian distribution via Laplace or EP approximations. Seung et al., 1992 ] sidesteps problem working predictions. al- gorithm, Query Committee (QBC), samples parameters from VS (committee members), they on outcome each possible . most balanced selected; this termed ‘principle maximal disagreement’. If BALD used sampled posterior, query committee implemented but probabilistic measure disagreement. QBC’s deterministic vote criterion discards condence predictions so exhibit same pathologies MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) made two approx- imations: we perform approximate inference 1 ), we approximated binary entropy Gaussian CDF squared exponential 2 ). Both these can be substituted Monte Carlo sampling, enabling us to compute 9",
      "original_tokens": 438,
      "compressed_tokens": 306,
      "compression_ratio": 0.6986301369863014,
      "metadata": {
        "paper_id": "benchmark_100_paper_9",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1598
      }
    },
    {
      "test_id": "benchmark_100_paper_10_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "Dim. 1 Dim. 2 (a) block in the middle Dim. 1 Dim. 2 (b) block in the corner Dim. 1 Dim. 2 (c) checkerboard 0 : 5 0 : 9 No. queried points Accuracy 0 : 5 No. queried points Accuracy 0 : 5 No. queried points Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars of the two classes are shown with black squares ( ) and red circles ( ). Bottom: Results of active learning with nine methods: random query ( ), BALD( ), MES ( ), QBC with the vote criterion with 2 ( ) and 100 ( ) committee members, active SVM ( ), IVM ( ), decision theoretic: [ Kapoor et al., 2007 ] ( ), [Zhu et al., 2003] ( ) and empirical error ( ). an asymptotically unbiased estimate of the expected information gain. Using extensive Monte Carlo as the ‘gold standard’, we can evaluate how much we loose by applying these approximations. We quantify approximation error as: max x 2P I ( x ) I (arg max x 2P ^ I ( x )) max x 2P I ( x ) 100% (8) where I is the objective computed using Monte Carlo, ^ I is the approximate objective. The cancer UCI dataset was used, results and discussion are in Fig. 2. Pool based active learning: We test BALDfor GPC and preference learning in the pool-based setting i.e. selecting x values from a xed set of data-points. Although BALD can generalise to selecting continuous x , this enables us to compare to algorithms that cannot. We compare to eight other algorithms: random sampling, MES, QBC (with 2 and 100 committee members), SVM with version space approximation [ Tong and Koller, 2001 ], decision theoretic approaches in [ Kapoor et al., 2007 , Zhu et al., 2003 ] and directly minimizing 10",
      "compressed_prompt": "(a) block middle (b) block corner (c) checkerboard 9 No. Accuracy No. Accuracy No. Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars two classes shown black squares red circles Bottom: Results nine methods: query BALD( MES QBC vote criterion members, SVM IVM theoretic: Kapoor [Zhu 2003] empirical an asymptotically unbiased estimate expected information gain. Using extensive Monte Carlo as ‘gold standard’, evaluate how much loose by applying these approximations. quantify as: (arg )) 100% (8) where objective computed using Monte Carlo, approximate objective. The cancer UCI dataset was used, results discussion Fig. 2. Pool based learning: test BALDfor GPC preference pool-based setting i.e. values from a xed set data-points. Although BALD generalise selecting continuous this enables us compare algorithms that cannot. We compare eight other algorithms: random sampling, MES, QBC (with committee members), SVM version space approximation Tong Koller, 2001 ], decision theoretic approaches Kapoor 2007 , Zhu 2003 ] directly minimizing 10",
      "original_tokens": 308,
      "compressed_tokens": 154,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_100_paper_10",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1139
      }
    },
    {
      "test_id": "benchmark_100_paper_10_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "Dim. 1 Dim. 2 (a) block in the middle Dim. 1 Dim. 2 (b) block in the corner Dim. 1 Dim. 2 (c) checkerboard 0 : 5 0 : 9 No. queried points Accuracy 0 : 5 No. queried points Accuracy 0 : 5 No. queried points Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars of the two classes are shown with black squares ( ) and red circles ( ). Bottom: Results of active learning with nine methods: random query ( ), BALD( ), MES ( ), QBC with the vote criterion with 2 ( ) and 100 ( ) committee members, active SVM ( ), IVM ( ), decision theoretic: [ Kapoor et al., 2007 ] ( ), [Zhu et al., 2003] ( ) and empirical error ( ). an asymptotically unbiased estimate of the expected information gain. Using extensive Monte Carlo as the ‘gold standard’, we can evaluate how much we loose by applying these approximations. We quantify approximation error as: max x 2P I ( x ) I (arg max x 2P ^ I ( x )) max x 2P I ( x ) 100% (8) where I is the objective computed using Monte Carlo, ^ I is the approximate objective. The cancer UCI dataset was used, results and discussion are in Fig. 2. Pool based active learning: We test BALDfor GPC and preference learning in the pool-based setting i.e. selecting x values from a xed set of data-points. Although BALD can generalise to selecting continuous x , this enables us to compare to algorithms that cannot. We compare to eight other algorithms: random sampling, MES, QBC (with 2 and 100 committee members), SVM with version space approximation [ Tong and Koller, 2001 ], decision theoretic approaches in [ Kapoor et al., 2007 , Zhu et al., 2003 ] and directly minimizing 10",
      "compressed_prompt": "Dim. 1 Dim. (a) block middle Dim. 1 Dim. (b) block corner Dim. 1 Dim. (c) checkerboard 0 : 5 0 : 9 No. queried points Accuracy 5 No. queried points Accuracy 5 No. queried points Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars two classes are shown black squares red circles ). Bottom: Results active learning nine methods: random query BALD( MES QBC vote criterion 100 committee members, active SVM IVM decision theoretic: [ Kapoor 2007 ] [Zhu 2003] empirical error ). an asymptotically unbiased estimate expected information gain. Using extensive Monte Carlo as ‘gold standard’, we can evaluate how much we loose by applying these approximations. We quantify approximation error as: max (arg ^ )) 100% (8) where is objective computed using Monte Carlo, ^ is approximate objective. The cancer UCI dataset was used, results discussion are Fig. 2. Pool based active learning: We test BALDfor GPC preference learning pool-based setting i.e. selecting values from a xed set data-points. Although BALD can generalise selecting continuous , this enables us compare algorithms that cannot. We compare eight other algorithms: random sampling, MES, QBC (with 100 committee members), SVM version space approximation [ Tong Koller, 2001 ], decision theoretic approaches [ Kapoor et al., 2007 , Zhu et al., 2003 ] directly minimizing 10",
      "original_tokens": 308,
      "compressed_tokens": 215,
      "compression_ratio": 0.698051948051948,
      "metadata": {
        "paper_id": "benchmark_100_paper_10",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1044
      }
    },
    {
      "test_id": "benchmark_200_paper_1_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "Bayesian Active Learning for Classication and Preference Learning Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational and Biological Learning Laboratory University of Cambridge November 27, 2024 Abstract Information theoretic active learning has been widely studied for prob- abilistic models. For simple regression an optimal myopic policy is easily tractable. However, for other tasks and with more complex models, such as classication with nonparametric models, the optimal solution is harder to compute. Current approaches make approximations to achieve tractabil- ity. We propose an approach that expresses information gain in terms of predictive entropies, and apply this method to the Gaussian Process Classier (GPC). Our approach makes minimal approximations to the full information theoretic objective. Our experimental performance compares favourably to many popular active learning algorithms, and has equal or lower computational complexity. We compare well to decision theoretic approaches also, which are privy to more information and require much more computational time. Secondly, by developing further a reformulation of binary preference learning to a classication problem, we extend our algorithm to Gaussian Process preference learning. 1 Introduction In most machine learning systems, the learner passively collects data with which it makes inferences about its environment. In active learning, however, the learner seeks the most useful measurements to be trained upon. The goal of active learning is to produce the best model with the least possible data; this is closely related to the statistical eld of optimal experimental design. With the advent of the internet and expansion of storage facilities, vast quantities of unlabelled data have become available, but it can be costly to obtain labels. Finding the most useful data in this vast space calls for ecient active learning algorithms. Two approaches to active learning are to use decision and information the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. The former minimizes the expected 1",
      "compressed_prompt": "Bayesian Active Classication Preference Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational Biological Laboratory University Cambridge November 27, 2024 Abstract Information been widely studied prob- abilistic models. For simple regression myopic policy easily tractable. However, other tasks complex such as nonparametric solution harder compute. Current make achieve tractabil- ity. propose that expresses gain terms predictive entropies, apply method Classier (GPC). minimal full objective. performance compares favourably many popular algorithms, equal lower complexity. compare well also, privy require much time. Secondly, developing further reformulation binary problem, we extend our algorithm learning. Introduction machine systems, passively collects inferences about its environment. learning, however, seeks measurements trained upon. goal produce best model least possible data; closely related statistical eld design. advent internet expansion storage facilities, quantities unlabelled have become available, but can costly obtain labels. Finding space calls ecient algorithms. Two use the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. former minimizes expected",
      "original_tokens": 308,
      "compressed_tokens": 154,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_200_paper_1",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1307
      }
    },
    {
      "test_id": "benchmark_200_paper_1_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "Bayesian Active Learning for Classication and Preference Learning Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational and Biological Learning Laboratory University of Cambridge November 27, 2024 Abstract Information theoretic active learning has been widely studied for prob- abilistic models. For simple regression an optimal myopic policy is easily tractable. However, for other tasks and with more complex models, such as classication with nonparametric models, the optimal solution is harder to compute. Current approaches make approximations to achieve tractabil- ity. We propose an approach that expresses information gain in terms of predictive entropies, and apply this method to the Gaussian Process Classier (GPC). Our approach makes minimal approximations to the full information theoretic objective. Our experimental performance compares favourably to many popular active learning algorithms, and has equal or lower computational complexity. We compare well to decision theoretic approaches also, which are privy to more information and require much more computational time. Secondly, by developing further a reformulation of binary preference learning to a classication problem, we extend our algorithm to Gaussian Process preference learning. 1 Introduction In most machine learning systems, the learner passively collects data with which it makes inferences about its environment. In active learning, however, the learner seeks the most useful measurements to be trained upon. The goal of active learning is to produce the best model with the least possible data; this is closely related to the statistical eld of optimal experimental design. With the advent of the internet and expansion of storage facilities, vast quantities of unlabelled data have become available, but it can be costly to obtain labels. Finding the most useful data in this vast space calls for ecient active learning algorithms. Two approaches to active learning are to use decision and information the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. The former minimizes the expected 1",
      "compressed_prompt": "Bayesian Active Learning Classication Preference Learning Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, Mate Lengyel Computational Biological Learning Laboratory University Cambridge November 27, 2024 Abstract Information theoretic has been widely studied prob- abilistic models. For simple regression an optimal myopic policy easily tractable. However, other tasks more complex models, such as classication nonparametric models, solution harder compute. Current make approximations achieve tractabil- ity. We propose approach that expresses gain terms predictive entropies, apply method Gaussian Process Classier (GPC). Our approach makes minimal approximations full objective. Our experimental performance compares favourably many popular algorithms, has equal or lower computational complexity. We compare well decision also, which privy require much computational time. Secondly, by developing further reformulation binary preference classication problem, we extend our algorithm Gaussian Process preference learning. 1 Introduction In machine systems, learner passively collects which it makes inferences about its environment. In learning, however, learner seeks useful measurements trained upon. The goal produce best model least possible data; closely related statistical eld experimental design. With advent internet expansion storage facilities, vast quantities unlabelled data have become available, but it can be costly obtain labels. Finding most useful in vast space calls ecient algorithms. Two approaches are use decision information the- ory [ Kapoor et al., 2007 , Lindley, 1956 ]. The former minimizes expected 1",
      "original_tokens": 308,
      "compressed_tokens": 215,
      "compression_ratio": 0.698051948051948,
      "metadata": {
        "paper_id": "benchmark_200_paper_1",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1125
      }
    },
    {
      "test_id": "benchmark_200_paper_2_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "losses encountered after making decisions based on the data collected i.e. min- imize the Bayes posterior risk [ Roy and McCallum, 2001 ]. Maximising perfor- mance under test is the ultimate objective of most learners, however, evaluat- ing this objective can be very hard. For example, the methods proposed in [ Kapoor et al., 2007 , Zhu et al., 2003 ] for classication are in general expensive to compute. Furthermore, one may not know the loss function or test distribution in advance, or may want the model to perform well on a variety of loss functions. In extreme scenarios, such as exploratory data analysis, or visualisation, losses may be very hard to quantify. This motivates information theoretic approaches to active learning, which are agnostic to the decision task at hand and particular test data, this is known an inductive approach. They seek to reduce the number of feasible models as quickly as possible, using either heuristics (e.g. margin sampling [ Tong and Koller, 2001 ]) or by formalising uncertainty using well studied quantities, such as Shannons entropy and the KL-divergence [ Cover et al., 1991 ]. Although the latter approach was proposed several decades ago [ Lindley, 1956 , Bernardo, 1979 ], it is not always straightforward to apply the criteria to complicated models such as nonparametric processes with innite parameter spaces. As a result many algorithms exist which compute approximate posterior entropies, perform sampling, or work with related quantities in non-probabilistic models. We return to this problem, presenting the full information criterion and demonstrate how to apply it to Gaussian Processes Classication (GPC), yielding a novel active learning algorithm that makes minimal approximations. GPC is a powerful, non-parametric kernel-based model, and poses an interesting problem for information-theoretic active learning because the parameter space is innite dimensional and the posterior distribution is analytically intractable. We present the information theoretic approach to active learning in Section 2. In Section 3 we apply it to GPC, and show how to extended our method to preference learning. In Section 4 we review other approaches and how they compare to our algorithm. We take particular care to contrast our approach to the Informative Vector Machine, that addresses data point selection for GPs directly. We present results on a wide variety of datasets in Section 5 and conclude in Section 6. 2 Bayesian Information Theoretic Active Learn- ing We consider a fully discriminative model where the goal of active learning is to discover the dependence of some variable y 2 Y on an input variable x 2 X . The key idea in active learning is that the learner chooses the input queries x i 2 X and observes the system’s response y i , rather than passively receiving ( x i y i ) pairs. Within a Bayesian framework we assume existence of some latent param- eters, , that control the dependence between inputs and outputs, p ( y j x ; ). Having observed data D = f ( x i ; y i ) g n i =1 , a posterior distribution over the pa- 2",
      "compressed_prompt": "losses encountered after making decisions based collected i.e. min- imize Bayes risk Roy McCallum, 2001 ]. Maximising perfor- mance under ultimate objective most learners, however, evaluat- ing objective can very hard. For example, methods proposed Kapoor 2007 Zhu 2003 ] classication general expensive compute. Furthermore, one not know loss function advance, want model perform well variety loss functions. extreme scenarios, exploratory analysis, visualisation, hard quantify. This motivates learning, agnostic decision task at hand data, known inductive approach. They seek reduce number feasible quickly possible, either heuristics (e.g. margin sampling Tong Koller, ]) by formalising uncertainty studied quantities, Shannons entropy KL-divergence Cover 1991 Although latter was several decades ago Lindley, 1956 Bernardo, 1979 ], always straightforward criteria complicated nonparametric processes spaces. As result many algorithms exist compute approximate entropies, sampling, work related quantities non-probabilistic models. return problem, presenting full criterion demonstrate Gaussian Processes Classication (GPC), yielding novel algorithm makes minimal approximations. GPC powerful, non-parametric kernel-based model, poses interesting problem information-theoretic because space dimensional analytically intractable. 2. 3 GPC, show extended method preference learning. 4 review other they compare algorithm. take care contrast Informative Vector Machine, addresses point selection GPs directly. results wide datasets 5 conclude 6. Bayesian Information Theoretic Active Learn- consider fully discriminative where goal discover variable Y input variable X . The key idea learner chooses queries X observes system’s response rather than passively receiving pairs. Within Bayesian framework assume existence some latent param- eters, control dependence between inputs outputs, p j ; ). Having observed D = f ; ) g n =1 over pa-",
      "original_tokens": 514,
      "compressed_tokens": 257,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_200_paper_2",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1914
      }
    },
    {
      "test_id": "benchmark_200_paper_2_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "losses encountered after making decisions based on the data collected i.e. min- imize the Bayes posterior risk [ Roy and McCallum, 2001 ]. Maximising perfor- mance under test is the ultimate objective of most learners, however, evaluat- ing this objective can be very hard. For example, the methods proposed in [ Kapoor et al., 2007 , Zhu et al., 2003 ] for classication are in general expensive to compute. Furthermore, one may not know the loss function or test distribution in advance, or may want the model to perform well on a variety of loss functions. In extreme scenarios, such as exploratory data analysis, or visualisation, losses may be very hard to quantify. This motivates information theoretic approaches to active learning, which are agnostic to the decision task at hand and particular test data, this is known an inductive approach. They seek to reduce the number of feasible models as quickly as possible, using either heuristics (e.g. margin sampling [ Tong and Koller, 2001 ]) or by formalising uncertainty using well studied quantities, such as Shannons entropy and the KL-divergence [ Cover et al., 1991 ]. Although the latter approach was proposed several decades ago [ Lindley, 1956 , Bernardo, 1979 ], it is not always straightforward to apply the criteria to complicated models such as nonparametric processes with innite parameter spaces. As a result many algorithms exist which compute approximate posterior entropies, perform sampling, or work with related quantities in non-probabilistic models. We return to this problem, presenting the full information criterion and demonstrate how to apply it to Gaussian Processes Classication (GPC), yielding a novel active learning algorithm that makes minimal approximations. GPC is a powerful, non-parametric kernel-based model, and poses an interesting problem for information-theoretic active learning because the parameter space is innite dimensional and the posterior distribution is analytically intractable. We present the information theoretic approach to active learning in Section 2. In Section 3 we apply it to GPC, and show how to extended our method to preference learning. In Section 4 we review other approaches and how they compare to our algorithm. We take particular care to contrast our approach to the Informative Vector Machine, that addresses data point selection for GPs directly. We present results on a wide variety of datasets in Section 5 and conclude in Section 6. 2 Bayesian Information Theoretic Active Learn- ing We consider a fully discriminative model where the goal of active learning is to discover the dependence of some variable y 2 Y on an input variable x 2 X . The key idea in active learning is that the learner chooses the input queries x i 2 X and observes the system’s response y i , rather than passively receiving ( x i y i ) pairs. Within a Bayesian framework we assume existence of some latent param- eters, , that control the dependence between inputs and outputs, p ( y j x ; ). Having observed data D = f ( x i ; y i ) g n i =1 , a posterior distribution over the pa- 2",
      "compressed_prompt": "losses encountered after making decisions based data collected i.e. min- imize Bayes posterior risk Roy McCallum, 2001 ]. Maximising perfor- mance under test ultimate objective most learners, however, evaluat- ing this objective can be very hard. For example, methods proposed Kapoor et al., 2007 Zhu et al., 2003 ] for classication are general expensive compute. Furthermore, one may not know loss function test distribution advance, may want model perform well variety loss functions. In extreme scenarios, such exploratory data analysis, visualisation, losses may be very hard quantify. This motivates information theoretic approaches learning, which are agnostic decision task at hand particular test data, this known inductive approach. They seek reduce number feasible models quickly possible, using either heuristics (e.g. margin sampling Tong Koller, 2001 ]) by formalising uncertainty using well studied quantities, such Shannons entropy KL-divergence Cover et al., 1991 ]. Although latter approach was proposed several decades ago Lindley, 1956 Bernardo, 1979 ], it not always straightforward apply criteria complicated models such nonparametric processes with innite parameter spaces. As result many algorithms exist which compute approximate entropies, perform sampling, work with related quantities non-probabilistic models. We return this problem, presenting full information criterion demonstrate how apply it Gaussian Processes Classication (GPC), yielding novel algorithm makes minimal approximations. GPC powerful, non-parametric kernel-based model, poses interesting problem information-theoretic because parameter space innite dimensional distribution analytically intractable. We present information theoretic approach Section 2. Section 3 we apply it GPC, show how extended our method preference learning. Section 4 we review other approaches how they compare our algorithm. We take particular care contrast our approach Informative Vector Machine, addresses point selection GPs directly. We present results wide variety datasets Section 5 conclude Section 6. Bayesian Information Theoretic Active Learn- ing We consider fully discriminative model where goal discover dependence some variable Y input variable X . The key idea learner chooses input queries X observes system’s response rather than passively receiving ( ) pairs. Within Bayesian framework we assume existence some latent param- eters, that control dependence between inputs outputs, p ( j ; ). Having observed data D = f ( ; ) g n =1 posterior distribution over pa-",
      "original_tokens": 514,
      "compressed_tokens": 359,
      "compression_ratio": 0.6984435797665369,
      "metadata": {
        "paper_id": "benchmark_200_paper_2",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1838
      }
    },
    {
      "test_id": "benchmark_200_paper_3_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "rameters is inferred, p ( jD ). The central goal of information theoretic ac- tive learning is to reduce the number possible hypotheses maximally fast, i.e. to minimize the uncertainty about the parameters using Shannon’s entropy [ Cover et al., 1991 ]. Data points D 0 are selected that satisfy arg min D 0 H[ jD 0 ] = R p ( jD 0 ) log p ( jD 0 )d . Solving this problem in general is NP-hard; however, as is common in sequential decision making tasks a myopic (greedy) approxi- mation is made [ Heckerman et al., 1995 ]. It has been shown that the myopic policy can perform near-optimally [ Golovin and Krause, 2010 , Dasgupta, 2005 ]. Therefore, the objective is to seek the data point x that maximises the decrease in expected posterior entropy: arg max x H[ jD ] E y p ( y j x D ) [H[ j y; x ; D ]] (1) Note that expectation over the unseen output y is required. Many works e.g. [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ] propose using this objective directly. However, parameter posteriors are often high dimen- sional and computing their entropies is usually intractable. Furthermore, for nonparametric processes the parameter space is innite dimensional so Eqn. (1) becomes poorly dened. To avoid gridding parameter space (exponentially hard with dimensionality), or sampling (from which it is notoriously hard to estimate entropies without introducing bias [ Panzeri and Petersen, 2007 ]), these papers make Gaussian or low dimensional approximations and calculate the entropy of the approximate posterior. A second computational diculty arises; if N x data points are under consideration, and N y responses may be seen, then O ( N x N y ), potentially expensive, posterior updates are required to calculate Eqn. (1). An important insight arises if we note that the objective in Eqn. (1) is equivalent to the conditional mutual information between the unknown output and the parameters, I[ ; y j x ; D ]. Using this insight it is simple to show that the objective can be rearranged to compute entropies in y space: arg max x H[ y j x ; D ] E p ( jD ) [H[ y j x ; ]] (2) Eqn. (2) overcomes the challenges we described for Eqn. (1) . Entropies are now calculated in, usually low dimensional, output space. For binary classication, these are just entropies of Bernoulli variables. Also is now conditioned only on D , so only O (1) posterior updates are required. Eqn. (2) also provides us with an interesting intuition about the objective; we seek the x for which the model is marginally most uncertain about y (high H[ y j x ; D ]), but for which individual settings of the parameters are condent (low E p ( jD ) [H[ y j x ; ]] ). This can be interpreted as seeking the x for which the parameters under the posterior disagree about the outcome the most, so we refer to this objective as Bayesian Active Learning by Disagreement (BALD). We present a method to apply Eqn. (2) directly to GPC and preference learning. We no longer need to build our entropy calculation around the type of posterior approximation (as 3",
      "compressed_prompt": "rameters inferred, ). The central goal information theoretic ac- tive learning reduce number possible hypotheses maximally fast, i.e. minimize uncertainty parameters using Shannon’s entropy Cover 1991 Data points selected satisfy arg min H[ = R log )d . Solving problem general NP-hard; however, common sequential decision making tasks a myopic (greedy) approxi- mation made Heckerman 1995 It has been shown myopic policy perform near-optimally Golovin Krause, 2010 Dasgupta, 2005 Therefore, data point maximises decrease expected entropy: max E y; Note expectation over unseen required. Many works e.g. MacKay, 1992 Krishnapuram Lawrence 2003 propose using directly. However, posteriors often high dimen- sional computing their usually intractable. Furthermore, nonparametric processes space innite dimensional becomes poorly dened. To avoid gridding space (exponentially hard dimensionality), sampling (from it notoriously hard estimate without introducing bias Panzeri Petersen, 2007 ]), these papers make Gaussian low dimensional approximations calculate approximate posterior. A second computational diculty arises; if data points consideration, responses may seen, then O ), potentially expensive, updates required calculate (1). An important insight arises if note equivalent conditional mutual information between unknown parameters, I[ Using insight it simple show rearranged compute space: E overcomes challenges described . Entropies now calculated in, usually low dimensional, space. For binary classication, these just Bernoulli variables. Also now conditioned only on O updates required. also provides us an interesting intuition objective; seek model marginally most uncertain (high H[ ]), but individual settings parameters condent (low E ). This interpreted seeking parameters under disagree outcome most, so refer Bayesian Active Learning by Disagreement (BALD). We present a method apply directly GPC preference learning. We no longer need build our entropy calculation around type approximation (as 3",
      "original_tokens": 553,
      "compressed_tokens": 276,
      "compression_ratio": 0.49909584086799275,
      "metadata": {
        "paper_id": "benchmark_200_paper_3",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.2046
      }
    },
    {
      "test_id": "benchmark_200_paper_3_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "rameters is inferred, p ( jD ). The central goal of information theoretic ac- tive learning is to reduce the number possible hypotheses maximally fast, i.e. to minimize the uncertainty about the parameters using Shannon’s entropy [ Cover et al., 1991 ]. Data points D 0 are selected that satisfy arg min D 0 H[ jD 0 ] = R p ( jD 0 ) log p ( jD 0 )d . Solving this problem in general is NP-hard; however, as is common in sequential decision making tasks a myopic (greedy) approxi- mation is made [ Heckerman et al., 1995 ]. It has been shown that the myopic policy can perform near-optimally [ Golovin and Krause, 2010 , Dasgupta, 2005 ]. Therefore, the objective is to seek the data point x that maximises the decrease in expected posterior entropy: arg max x H[ jD ] E y p ( y j x D ) [H[ j y; x ; D ]] (1) Note that expectation over the unseen output y is required. Many works e.g. [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ] propose using this objective directly. However, parameter posteriors are often high dimen- sional and computing their entropies is usually intractable. Furthermore, for nonparametric processes the parameter space is innite dimensional so Eqn. (1) becomes poorly dened. To avoid gridding parameter space (exponentially hard with dimensionality), or sampling (from which it is notoriously hard to estimate entropies without introducing bias [ Panzeri and Petersen, 2007 ]), these papers make Gaussian or low dimensional approximations and calculate the entropy of the approximate posterior. A second computational diculty arises; if N x data points are under consideration, and N y responses may be seen, then O ( N x N y ), potentially expensive, posterior updates are required to calculate Eqn. (1). An important insight arises if we note that the objective in Eqn. (1) is equivalent to the conditional mutual information between the unknown output and the parameters, I[ ; y j x ; D ]. Using this insight it is simple to show that the objective can be rearranged to compute entropies in y space: arg max x H[ y j x ; D ] E p ( jD ) [H[ y j x ; ]] (2) Eqn. (2) overcomes the challenges we described for Eqn. (1) . Entropies are now calculated in, usually low dimensional, output space. For binary classication, these are just entropies of Bernoulli variables. Also is now conditioned only on D , so only O (1) posterior updates are required. Eqn. (2) also provides us with an interesting intuition about the objective; we seek the x for which the model is marginally most uncertain about y (high H[ y j x ; D ]), but for which individual settings of the parameters are condent (low E p ( jD ) [H[ y j x ; ]] ). This can be interpreted as seeking the x for which the parameters under the posterior disagree about the outcome the most, so we refer to this objective as Bayesian Active Learning by Disagreement (BALD). We present a method to apply Eqn. (2) directly to GPC and preference learning. We no longer need to build our entropy calculation around the type of posterior approximation (as 3",
      "compressed_prompt": "rameters inferred, p ). The central goal of information theoretic ac- tive learning reduce number possible hypotheses maximally fast, i.e. minimize uncertainty about parameters using Shannon’s entropy [ Cover et al., 1991 ]. Data points D 0 selected that satisfy arg min D 0 H[ 0 ] = R 0 ) log 0 )d . Solving this problem general NP-hard; however, as common sequential decision making tasks a myopic (greedy) approxi- mation made [ Heckerman et al., 1995 ]. It has been shown myopic policy can perform near-optimally Golovin Krause, 2010 , Dasgupta, 2005 ]. Therefore, seek data point maximises decrease expected posterior entropy: arg max H[ ] E ) [H[ y; ]] Note expectation over unseen output required. Many works e.g. MacKay, 1992 , Krishnapuram et Lawrence et al., 2003 ] propose using this directly. However, parameter posteriors often high dimen- sional computing their entropies usually intractable. Furthermore, nonparametric processes parameter space innite dimensional so Eqn. becomes poorly dened. To avoid gridding parameter space (exponentially hard with dimensionality), or sampling (from which it notoriously hard estimate entropies without introducing bias Panzeri Petersen, 2007 ]), these papers make Gaussian or low dimensional approximations calculate entropy approximate posterior. A second computational diculty arises; if N data points under consideration, N responses may be seen, then O N N ), potentially expensive, updates required calculate Eqn. (1). An important insight arises if we note Eqn. equivalent conditional mutual information between unknown output parameters, I[ ]. Using this insight it simple show can be rearranged compute entropies space: arg max H[ ] E ) [H[ ]] (2) Eqn. (2) overcomes challenges we described Eqn. . Entropies now calculated in, usually low dimensional, output space. For binary classication, these just entropies Bernoulli variables. Also now conditioned only on , so only O updates required. Eqn. (2) also provides us with an interesting intuition about objective; we seek which model marginally most uncertain about (high H[ D ]), but which individual settings parameters condent (low E ) [H[ ]] ). This can be interpreted as seeking which parameters under posterior disagree about outcome most, so we refer this objective as Bayesian Active Learning by Disagreement (BALD). We present a method apply Eqn. (2) directly GPC preference learning. We no longer need build our entropy calculation around type of posterior approximation (as 3",
      "original_tokens": 553,
      "compressed_tokens": 387,
      "compression_ratio": 0.6998191681735986,
      "metadata": {
        "paper_id": "benchmark_200_paper_3",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1933
      }
    },
    {
      "test_id": "benchmark_200_paper_4_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "in [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ]) but are free to choose from many of the available algorithms. Minimal additional approximations are introduced, and so, to our knowledge our algorithm represents the most exact and fastest way to perform full information-theoretic active learning in non-parametric discriminative models. 3 Gaussian Processes for Classication and Pref- erence Learning In this section we derive the BALD algorithm for Gaussian Process classication (GPC). GPs are a powerful and popular non-parametric tool for regression and classication. GPC appears to be an especially challenging problem for information-theoretic active learning because the parameter space is innite, however, by using (2) we are able to calculate fully the relevant information quantities without having to work out entropies of innite dimensional objects. The probabilistic model underlying GPC is as follows: f GP( ( ) ; k ( ; )) y j x ; f Bernoulli(( f ( x ))) The latent parameter, now called f is a function X ! R , and is assigned a Gaussian process prior with mean ( ) and covariance function or kernel k ( ; ). We consider the probit case where given the value of f , y takes a Bernoulli distribution with probability ( f ( x )), and is the Gaussian CDF. For further details on GPs see [Rasmussen and Williams, 2005]. Inference in the GPC model is intractable; given some observations D , the posterior over f becomes non-Gaussian and complicated. The most commonly used approximate inference methods { EP, Laplace approximation, Assumed Density Filtering and sparse methods { all approximate the posterior by a Gaussian [ Rasmussen and Williams, 2005 ]. Throughout this section we will assume that we are provided with such a Gaussian approximation from one of these methods, though the active learning algorithm does not care which one. In our derivation we will use 1 to indicate where such an approximation is exploited. The informativeness of a query x is computed using Eqn. (2) . The entropy of the binary output variable y given a xed f can be expressed in terms of the binary entropy function h: H[ y j x ; f ] = h (( f ( x )) h( p ) = p log p (1 p ) log(1 p ) Expectations over the posterior need to be computed. Using a Gaussian approxi- mation to the posterior, for each x , f x = f ( x ) will follow a Gaussian distribution with mean x ; D and variance 2 x ; D . To compute Eqn. (2) we have to compute 4",
      "compressed_prompt": "[ MacKay, 1992 Krishnapuram et al., Lawrence et al., 2003 ]) but free choose from many available algorithms. Minimal additional approximations introduced, so, knowledge algorithm represents most exact fastest way perform full information-theoretic non-parametric discriminative models. 3 Processes Classication Pref- erence Learning In this section derive BALD Process classication (GPC). GPs powerful popular non-parametric tool regression classication. GPC appears especially challenging problem information-theoretic because parameter space innite, however, able calculate fully relevant information quantities without having work out entropies innite dimensional objects. probabilistic underlying GPC as follows: GP( Bernoulli(( ))) latent parameter, now called X ! R assigned process prior covariance or kernel ). We consider probit case value takes Bernoulli distribution probability )), CDF. For further details on GPs see [Rasmussen Williams, 2005]. Inference GPC intractable; some observations D becomes non-Gaussian complicated. commonly used approximate inference methods EP, Laplace approximation, Assumed Density Filtering sparse methods all approximate Rasmussen Williams, 2005 ]. Throughout section assume that provided approximation one these methods, though does not care which one. derivation use 1 indicate approximation exploited. informativeness query computed Eqn. entropy output variable xed can expressed terms binary entropy h: H[ j ] h (( )) h( log (1 log(1 Expectations over need computed. Using approxi- mation posterior, each follow distribution mean D variance 2 D . To compute Eqn. have compute 4",
      "original_tokens": 440,
      "compressed_tokens": 220,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_200_paper_4",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1676
      }
    },
    {
      "test_id": "benchmark_200_paper_4_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "in [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ]) but are free to choose from many of the available algorithms. Minimal additional approximations are introduced, and so, to our knowledge our algorithm represents the most exact and fastest way to perform full information-theoretic active learning in non-parametric discriminative models. 3 Gaussian Processes for Classication and Pref- erence Learning In this section we derive the BALD algorithm for Gaussian Process classication (GPC). GPs are a powerful and popular non-parametric tool for regression and classication. GPC appears to be an especially challenging problem for information-theoretic active learning because the parameter space is innite, however, by using (2) we are able to calculate fully the relevant information quantities without having to work out entropies of innite dimensional objects. The probabilistic model underlying GPC is as follows: f GP( ( ) ; k ( ; )) y j x ; f Bernoulli(( f ( x ))) The latent parameter, now called f is a function X ! R , and is assigned a Gaussian process prior with mean ( ) and covariance function or kernel k ( ; ). We consider the probit case where given the value of f , y takes a Bernoulli distribution with probability ( f ( x )), and is the Gaussian CDF. For further details on GPs see [Rasmussen and Williams, 2005]. Inference in the GPC model is intractable; given some observations D , the posterior over f becomes non-Gaussian and complicated. The most commonly used approximate inference methods { EP, Laplace approximation, Assumed Density Filtering and sparse methods { all approximate the posterior by a Gaussian [ Rasmussen and Williams, 2005 ]. Throughout this section we will assume that we are provided with such a Gaussian approximation from one of these methods, though the active learning algorithm does not care which one. In our derivation we will use 1 to indicate where such an approximation is exploited. The informativeness of a query x is computed using Eqn. (2) . The entropy of the binary output variable y given a xed f can be expressed in terms of the binary entropy function h: H[ y j x ; f ] = h (( f ( x )) h( p ) = p log p (1 p ) log(1 p ) Expectations over the posterior need to be computed. Using a Gaussian approxi- mation to the posterior, for each x , f x = f ( x ) will follow a Gaussian distribution with mean x ; D and variance 2 x ; D . To compute Eqn. (2) we have to compute 4",
      "compressed_prompt": "in [ MacKay, 1992 , Krishnapuram et al., , Lawrence et al., 2003 ]) but are free choose from many available algorithms. Minimal additional approximations are introduced, so, our knowledge our algorithm represents most exact fastest way perform full information-theoretic active learning in non-parametric discriminative models. 3 Gaussian Processes Classication Pref- erence Learning In this section we derive BALD algorithm Gaussian Process classication (GPC). GPs powerful popular non-parametric tool regression classication. GPC appears be an especially challenging problem information-theoretic active learning because parameter space innite, however, by using (2) able calculate fully relevant information quantities without having work out entropies innite dimensional objects. probabilistic model underlying GPC as follows: GP( k )) y j Bernoulli(( ))) latent parameter, now called function X ! R assigned Gaussian process prior mean covariance function or kernel k ). We consider probit case where given value y takes Bernoulli distribution probability )), Gaussian CDF. For further details on GPs see [Rasmussen Williams, 2005]. Inference GPC model intractable; given some observations D posterior over becomes non-Gaussian complicated. most commonly used approximate inference methods { EP, Laplace approximation, Assumed Density Filtering sparse methods { all approximate posterior by [ Rasmussen Williams, 2005 ]. Throughout this section will assume that provided such approximation from one these methods, though active learning algorithm does not care which one. In our derivation will use 1 indicate where such an approximation exploited. informativeness query computed using Eqn. (2) . entropy binary output variable y given xed can be expressed terms binary entropy function h: H[ y j ] = h (( )) h( p = p log p (1 p log(1 p Expectations over posterior need be computed. Using Gaussian approxi- mation posterior, for each , = ) will follow Gaussian distribution with mean ; D variance 2 ; D . To compute Eqn. (2) we have compute 4",
      "original_tokens": 440,
      "compressed_tokens": 308,
      "compression_ratio": 0.7,
      "metadata": {
        "paper_id": "benchmark_200_paper_4",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1555
      }
    },
    {
      "test_id": "benchmark_200_paper_5_dictionary",
      "technique": "dictionary",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "[RULES]\n- Always expand ⟦n⟧ using DICT[n] before reasoning.\n- Do not print DICT in the result, only use it to understand context.\n\n[DICT]\n1: x ; D\n\n\n[BODY]\ntwo entropy quantities. The rst term in Eqn. (2) , H[ y j ⟦1⟧ ] can be handled analytically for the probit case: H[ y j ⟦1⟧ ] 1 h Z ( f x ) N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) df x = h 0 @ 0 @ ⟦1⟧ 2 ⟦1⟧ + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) df x = C 2 ⟦1⟧ + C 2 exp 0 @ 2 ⟦1⟧ 2 2 ⟦1⟧ + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j ⟦1⟧ ; 2 ⟦1⟧ ) is centred at ⟦1⟧ = 2 : 05 with 2 ⟦1⟧ tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean ⟦1⟧ and ⟦1⟧ for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ ⟦1⟧ 2 ⟦1⟧ + 1 1 A 1 A C exp 2 ⟦1⟧ 2 ( 2 ⟦1⟧ + C 2 ) 2 ⟦1⟧ + C 2 (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 490,
      "compression_ratio": 0.9626718759536743,
      "metadata": {
        "paper_id": "benchmark_200_paper_5",
        "dictionary_entries": 1,
        "substitutions": 24,
        "processing_time_ms": 1.036
      }
    },
    {
      "test_id": "benchmark_200_paper_5_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y ] can be handled analytically probit case: H[ y ] h Z N df = h @ @ (3) second term, E p jD [H[ y ]] can be computed approximately as follows: E p jD [H[ y ]] Z h(( )) N df (4) Z ln N df exp @ where q . rst approximation, , reects Gaussian ap- proximation posterior. integral left hand side Eqn. (4) is intractable. By performing Taylor expansion on ln h(( )) (see supplementary material) we see that it approximated up O 4 by squared exponential curve, exp ln 2). We will refer approximation . Now we apply standard convolution formula Gaussians nally get closed form expression both terms Eqn. (2). Fig. depicts striking accuracy simple approximation. max- imum possible error that will incurred when using approximation is if N centred at : 05 with tending zero (see Fig. 1, absolute error ), yielding only 0.27% error integral Eqn. (4) . authors are unaware previous use simple and useful approximation context. In Section 5 we investigate experimentally information lost from approximations and compared golden standard extensive Monte Carlo simulation. To summarise, BALD algorithm Gaussian process classication con- sists two steps. First it applies any standard approximate inference algorithm GPCs (such as EP) obtain posterior predictive mean and each point interest . Then, it selects query that maximises following objective function: h 0 @ 0 @ + A A C exp + C + C (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 254,
      "compression_ratio": 0.49901768172888017,
      "metadata": {
        "paper_id": "benchmark_200_paper_5",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1622
      }
    },
    {
      "test_id": "benchmark_200_paper_5_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j D ] can be handled analytically for the probit case: H[ y j D ] 1 h Z ( ) N ( j D ) df = h 0 @ 0 @ + 1 1 A 1 A (3) The second term, E p ( jD ) [H[ y j ]] can be computed approximately as follows: E p ( jD ) [H[ y j ]] Z h(( )) N j ) df (4) Z exp ln N j ) df = C + C exp 0 @ + C A where C = q . The rst approximation, , reects Gaussian ap- proximation to posterior. The integral in left hand side Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( )) (see supplementary material) we can see that it can be approximated up to O ( 4 ) by a squared exponential curve, exp ( = ln 2). We will refer to this approximation as . Now we can apply standard convolution formula for Gaussians to nally get a closed form expression for both terms Eqn. (2). Fig. depicts striking accuracy this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( j ) is centred at = : 05 with tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in integral in Eqn. (4) . The authors are unaware previous use this simple and useful approximation in this context. In Section 5 we investigate experimentally information lost from approximations and as compared to golden standard extensive Monte Carlo simulation. To summarise, BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain posterior predictive mean and for each point of interest . Then, it selects a query that maximises the following objective function: h 0 @ 0 @ D D + 1 1 A 1 A C exp D ( D + C ) D + C (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 356,
      "compression_ratio": 0.6994106090373281,
      "metadata": {
        "paper_id": "benchmark_200_paper_5",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.159
      }
    },
    {
      "test_id": "benchmark_200_paper_5_hybrid",
      "technique": "hybrid",
      "original_prompt": "two entropy quantities. The rst term in Eqn. (2) , H[ y j x ; D ] can be handled analytically for the probit case: H[ y j x ; D ] 1 h Z ( f x ) N ( f x j x ; D ; 2 x ; D ) df x = h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A (3) The second term, E f p ( f jD ) [H[ y j x ; f ]] can be computed approximately as follows: E f p ( f jD ) [H[ y j x ; f ]] 1 Z h(( f x )) N ( f x j x ; D ; 2 x ; D ) df x (4) 2 Z exp f 2 x ln 2 N ( f x j x ; D ; 2 x ; D ) df x = C 2 x ; D + C 2 exp 0 @ 2 x ; D 2 2 x ; D + C 2 1 A where C = q\n2 . The rst approximation, 1 , reects the Gaussian ap- proximation to the posterior. The integral in the left hand side of Eqn. (4) is intractable. By performing a Taylor expansion on ln h(( f x )) (see supplementary material) we can see that it can be approximated up to O ( f 4 x ) by a squared exponential curve, exp ( f 2 x = ln 2). We will refer to this approximation as 2 . Now we can apply the standard convolution formula for Gaussians to nally get a closed form expression for both terms of Eqn. (2). Fig. 1 depicts the striking accuracy of this simple approximation. The max- imum possible error that will be incurred when using this approximation is if N ( f x j x ; D ; 2 x ; D ) is centred at x ; D = 2 : 05 with 2 x ; D tending to zero (see Fig. 1, absolute error ), yielding only a 0.27% error in the integral in Eqn. (4) . The authors are unaware of previous use of this simple and useful approximation in this context. In Section 5 we investigate experimentally the information lost from approximations 1 and 2 as compared to the golden standard of extensive Monte Carlo simulation. To summarise, the BALD algorithm for Gaussian process classication con- sists of two steps. First it applies any standard approximate inference algorithm for GPCs (such as EP) to obtain the posterior predictive mean x ; D and x ; D for each point of interest x . Then, it selects a query x that maximises the following objective function: h 0 @ 0 @ x ; D 2 x ; D + 1 1 A 1 A C exp 2 x ; D 2 ( 2 x ; D + C 2 ) 2 x ; D + C 2 (5) 5",
      "compressed_prompt": "[RULES] - Always expand ⟦n⟧ using DICT[n] before reasoning. - Do not print DICT result, only use it understand context. [DICT] 1: D [BODY] two entropy quantities. rst term Eqn. (2) , H[ y ] handled analytically probit case: H[ y ] h Z N df h @ @ (3) second term, E p jD [H[ ]] computed approximately follows: E p jD [H[ ]] Z h(( )) N (4) Z N where q rst approximation, , reects Gaussian ap- proximation posterior. integral left hand side Eqn. (4) intractable. By performing Taylor expansion on ln h(( )) (see supplementary material) we see that approximated up O 4 by squared exponential curve, ln 2). We will refer approximation Now we apply standard convolution formula Gaussians nally get closed form expression both terms Eqn. (2). Fig. depicts striking accuracy simple approximation. max- imum possible error that will incurred when using approximation if N centred at : 05 with tending zero (see Fig. 1, absolute error ), yielding only 0.27% error integral Eqn. (4) authors are unaware previous use simple useful approximation context. In Section 5 we investigate experimentally information lost from approximations compared golden standard extensive Monte Carlo simulation. To summarise, BALD algorithm Gaussian process classication con- sists two steps. First it applies any standard approximate inference algorithm GPCs (such EP) obtain posterior predictive mean each point interest . Then, it selects query that maximises following objective function: h @ @ C exp C C (5) 5",
      "original_tokens": 509,
      "compressed_tokens": 245,
      "compression_ratio": 0.481335952848723,
      "metadata": {
        "paper_id": "benchmark_200_paper_5",
        "dictionary_entries": 1,
        "substitutions": 24,
        "processing_time_ms": 1.1965999999999999
      }
    },
    {
      "test_id": "benchmark_200_paper_6_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "h (( )) exp( t 2 log(2) ) 5 10 3 dierence Figure 1: Analytic approximation ( 1 ) to the binary entropy of the error function ( ) by a squared exponential ( ). The absolute error ( ) remains under 3 10 3 . For most practically relevant kernels, the objective (5) is a smooth and dierentiable function of x , so gradient-based optimisation procedures can be used to nd the maximally informative query. 3.1 Extension: Learning Hyperparameters In many applications the parameter set naturally divides into parameters of interest, + , and nuisance parameters , i.e. = f + ; g . In such settings, the active learning may want to query points that are maximally informative about + , while not caring about . By integrating Eqn. (1) over the nuisance parameters, , BALD’s objective is re-derived as: H E p ( + ; jD ) y j x ; + ; E p ( + jD ) H E p ( j + ; D ) [ y j x ; + ; ] (6) In the context of GP models, hyperparameters typically control the smooth- ness or spatial length-scale of functions. If we maintain a posterior distribution over these hyperparameters, which we can do e. g. via Hamiltonian Monte Carlo, we can choose either to treat them as nuisance parameters and use Eq. 6, or to include them in + and perform active learning over them as well. In certain cases, such as automatic relevance determination [ Rasmussen and Williams, 2005 ], it may even make sense to treat hyperparameters as variables of primary interest, and the function f itself as nuisance parameter . 3.2 Preference Learning Our active learning framework for GPC can be extended to the important problem of preference learning [ Furnkranz and Hullermeier, 2003 , Chu and Ghahramani, 2005 ]. In preference learning the dataset consists for pairs of items ( u i ; v i ) 2 X 2 with binary labels, y i 2 f 0 ; 1 g . y i = 1 means instance u i is preferred to v i , denoted u i v i . The task is to predict the preference relation between any ( u ; v ). We can view this as a special case of building a classier on pairs of inputs 6",
      "compressed_prompt": "h (( )) exp( t log(2) 5 10 3 dierence Figure 1: Analytic approximation 1 binary entropy error function by squared exponential ). The absolute error remains under 10 For most practically relevant kernels, objective (5) smooth dierentiable so gradient-based optimisation procedures used nd maximally informative query. 3.1 Extension: Learning Hyperparameters many applications parameter set naturally divides into interest, i.e. = g such settings, may want query points that are maximally informative about while not caring about By integrating Eqn. (1) parameters, BALD’s objective re-derived as: H E jD E H E D ] (6) context GP models, hyperparameters typically control smooth- ness spatial length-scale functions. If maintain posterior distribution these hyperparameters, which do e. g. via Hamiltonian Monte Carlo, choose either treat use Eq. 6, include in perform well. certain cases, automatic relevance determination Rasmussen Williams, ], it even make sense hyperparameters variables primary interest, itself parameter 3.2 Preference Learning Our framework GPC extended important problem Furnkranz Hullermeier, 2003 Chu Ghahramani, ]. dataset consists pairs items X with binary labels, 0 g = means instance preferred denoted The task predict preference relation between any ). We view this special case building classier on pairs inputs 6",
      "original_tokens": 394,
      "compressed_tokens": 197,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_200_paper_6",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.13990000000000002
      }
    },
    {
      "test_id": "benchmark_200_paper_6_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "h (( )) exp( t 2 log(2) ) 5 10 3 dierence Figure 1: Analytic approximation ( 1 ) to the binary entropy of the error function ( ) by a squared exponential ( ). The absolute error ( ) remains under 3 10 3 . For most practically relevant kernels, the objective (5) is a smooth and dierentiable function of x , so gradient-based optimisation procedures can be used to nd the maximally informative query. 3.1 Extension: Learning Hyperparameters In many applications the parameter set naturally divides into parameters of interest, + , and nuisance parameters , i.e. = f + ; g . In such settings, the active learning may want to query points that are maximally informative about + , while not caring about . By integrating Eqn. (1) over the nuisance parameters, , BALD’s objective is re-derived as: H E p ( + ; jD ) y j x ; + ; E p ( + jD ) H E p ( j + ; D ) [ y j x ; + ; ] (6) In the context of GP models, hyperparameters typically control the smooth- ness or spatial length-scale of functions. If we maintain a posterior distribution over these hyperparameters, which we can do e. g. via Hamiltonian Monte Carlo, we can choose either to treat them as nuisance parameters and use Eq. 6, or to include them in + and perform active learning over them as well. In certain cases, such as automatic relevance determination [ Rasmussen and Williams, 2005 ], it may even make sense to treat hyperparameters as variables of primary interest, and the function f itself as nuisance parameter . 3.2 Preference Learning Our active learning framework for GPC can be extended to the important problem of preference learning [ Furnkranz and Hullermeier, 2003 , Chu and Ghahramani, 2005 ]. In preference learning the dataset consists for pairs of items ( u i ; v i ) 2 X 2 with binary labels, y i 2 f 0 ; 1 g . y i = 1 means instance u i is preferred to v i , denoted u i v i . The task is to predict the preference relation between any ( u ; v ). We can view this as a special case of building a classier on pairs of inputs 6",
      "compressed_prompt": "h (( )) exp( t 2 log(2) 5 10 3 dierence Figure 1: Analytic approximation 1 binary entropy error function by a squared exponential ). The absolute error remains under 3 10 3 For most practically relevant kernels, objective (5) is smooth dierentiable function x so gradient-based optimisation procedures can be used nd maximally informative query. 3.1 Extension: Learning Hyperparameters many applications parameter set naturally divides into parameters interest, nuisance parameters i.e. = f g such settings, active may want query points that are maximally informative about while not caring about By integrating Eqn. (1) over nuisance parameters, BALD’s objective re-derived as: H E p jD y j x E p jD H E p j D [ y j x ] (6) context GP models, hyperparameters typically control smooth- ness or spatial length-scale functions. If we maintain posterior distribution over these hyperparameters, which we do e. g. via Hamiltonian Monte Carlo, we choose either treat them nuisance parameters use Eq. 6, or include them in perform active over them well. certain cases, such automatic relevance determination [ Rasmussen Williams, 2005 ], it may even make sense treat hyperparameters variables primary interest, function f itself nuisance parameter 3.2 Preference Learning Our active framework for GPC be extended important problem preference [ Furnkranz Hullermeier, 2003 Chu Ghahramani, 2005 ]. preference dataset consists for pairs items u v 2 X 2 with binary labels, y 2 f 0 1 g y = 1 means instance u is preferred v denoted u v . The task is predict preference relation between any u v ). We can view this a special case building classier on pairs inputs 6",
      "original_tokens": 394,
      "compressed_tokens": 275,
      "compression_ratio": 0.6979695431472082,
      "metadata": {
        "paper_id": "benchmark_200_paper_6",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1304
      }
    },
    {
      "test_id": "benchmark_200_paper_7_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "2 noise = 1. The likelihood only depends on the dierence between f ( u ) and f ( v ). We therefore dene g ( u ; v ) = f ( u ) f ( v ), and do inference entirely in terms of g , for which the likelihood becomes the same as for probit classication: y j u ; v ; f Bernoulli (( g ( u ; v ))). We observe that a GP prior is induced on g because it is formed by performing a linear operation on f , for which we have a GP prior already f GP (0 ; k ). We can derive the induced covariance function of g as (derivation in the Supplementary material) as: k pref (( u i ; v i ) ; ( u j ; v j )) = k ( u i ; u j ) + k ( v i ; v j ) k ( u i ; v j ) k ( v i ; u j ). Note that this kernel k pref respects the anti-symmetry properties desired for a preference learning scenario, i.e. the value g ( u; v ) is perfectly anti-correlated with g ( v; u ), ensuring P [ u v ] = 1 P [ v u ] holds. Thus, we can conclude that the GP preference learning framework of [ Chu and Ghahramani, 2005 ], is equivalent to GPC with a particular class of kernels, that we may call the preference judgement kernels . Therefore, our active learning algorithm presented in Section 3 for GPC can readily be applied to pairwise preference learning also. 4 Related Methodologies There are a number of closely related algorithms for active classication which we now review. The Informative Vector Machine (IVM): Perhaps the most closely re- lated approach is the IVM [ Lawrence et al., 2003 ]. This popular,and successful approach to active learning was designed specically for GPs; it uses an infor- mation theoretic approach and so appears very similar to BALD. The IVM algorithm was designed for subsampling a dataset for training a GP, so it is privy to the y values before including a measurement; it cannot therefore work explic- itly in output space i.e. with Eqn. (2) . The IVM uses Eqn. (1) , but parameter entropies are calculated approximately in the marginal subspace corresponding to the observed data points. The entropy decrease after inclusion of a new data point can then be calculated eciently using the GP covariance matrix. Although the IVM and BALD are motivated by the same objective, they work fundamentally dierently when approximate inference is carried out. At any time 7",
      "compressed_prompt": "2 noise 1. likelihood only depends dierence between ). We therefore dene ), do inference entirely terms , likelihood becomes same as probit classication: y Bernoulli (( ))). We observe GP prior induced because formed by performing linear operation have prior already (0 We derive induced covariance function (derivation Supplementary material) as: pref (( )) + Note this kernel pref respects anti-symmetry properties desired scenario, i.e. value u; perfectly anti-correlated v; ), ensuring P ] 1 P ] holds. Thus, conclude GP framework Chu Ghahramani, 2005 ], equivalent GPC particular class kernels, may call judgement kernels . Therefore, our algorithm presented Section 3 GPC readily applied pairwise also. 4 Related Methodologies There number closely related algorithms classication now review. Informative Vector Machine (IVM): Perhaps most closely re- lated IVM Lawrence et al., 2003 ]. This popular,and successful designed specically GPs; uses an infor- mation theoretic so appears very similar BALD. IVM algorithm designed subsampling dataset training GP, so privy y values before including measurement; cannot therefore work explic- itly output space i.e. Eqn. (2) . IVM uses Eqn. (1) but parameter entropies calculated approximately marginal subspace corresponding observed data points. entropy decrease after inclusion new data point then be calculated eciently using GP covariance matrix. Although IVM BALD motivated by same objective, they work fundamentally dierently when approximate inference carried out. At any time 7",
      "original_tokens": 451,
      "compressed_tokens": 225,
      "compression_ratio": 0.49889135254988914,
      "metadata": {
        "paper_id": "benchmark_200_paper_7",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.16349999999999998
      }
    },
    {
      "test_id": "benchmark_200_paper_7_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "2 noise = 1. The likelihood only depends on the dierence between f ( u ) and f ( v ). We therefore dene g ( u ; v ) = f ( u ) f ( v ), and do inference entirely in terms of g , for which the likelihood becomes the same as for probit classication: y j u ; v ; f Bernoulli (( g ( u ; v ))). We observe that a GP prior is induced on g because it is formed by performing a linear operation on f , for which we have a GP prior already f GP (0 ; k ). We can derive the induced covariance function of g as (derivation in the Supplementary material) as: k pref (( u i ; v i ) ; ( u j ; v j )) = k ( u i ; u j ) + k ( v i ; v j ) k ( u i ; v j ) k ( v i ; u j ). Note that this kernel k pref respects the anti-symmetry properties desired for a preference learning scenario, i.e. the value g ( u; v ) is perfectly anti-correlated with g ( v; u ), ensuring P [ u v ] = 1 P [ v u ] holds. Thus, we can conclude that the GP preference learning framework of [ Chu and Ghahramani, 2005 ], is equivalent to GPC with a particular class of kernels, that we may call the preference judgement kernels . Therefore, our active learning algorithm presented in Section 3 for GPC can readily be applied to pairwise preference learning also. 4 Related Methodologies There are a number of closely related algorithms for active classication which we now review. The Informative Vector Machine (IVM): Perhaps the most closely re- lated approach is the IVM [ Lawrence et al., 2003 ]. This popular,and successful approach to active learning was designed specically for GPs; it uses an infor- mation theoretic approach and so appears very similar to BALD. The IVM algorithm was designed for subsampling a dataset for training a GP, so it is privy to the y values before including a measurement; it cannot therefore work explic- itly in output space i.e. with Eqn. (2) . The IVM uses Eqn. (1) , but parameter entropies are calculated approximately in the marginal subspace corresponding to the observed data points. The entropy decrease after inclusion of a new data point can then be calculated eciently using the GP covariance matrix. Although the IVM and BALD are motivated by the same objective, they work fundamentally dierently when approximate inference is carried out. At any time 7",
      "compressed_prompt": "2 noise = 1. The likelihood only depends on dierence between f ) and f ). We therefore dene g ) = f ) f ), and do inference entirely in terms of g , which likelihood becomes same as probit classication: y j f Bernoulli (( g ))). We observe that GP prior induced on g because it formed by performing linear operation on , which we have GP prior already GP (0 ). We can derive induced covariance function as (derivation Supplementary material) as: pref (( i )) = + ). Note that this kernel pref respects anti-symmetry properties desired preference learning scenario, i.e. value u; perfectly anti-correlated with v; ), ensuring P [ ] = 1 P [ ] holds. Thus, we can conclude that GP preference learning framework [ Chu Ghahramani, 2005 ], equivalent GPC with particular class kernels, that we may call preference judgement kernels . Therefore, our active learning algorithm presented Section 3 GPC can readily be applied pairwise preference learning also. 4 Related Methodologies There are number closely related algorithms active classication which we now review. The Informative Vector Machine (IVM): Perhaps most closely re- lated approach IVM [ Lawrence et al., 2003 ]. This popular,and successful approach active learning was designed specically GPs; it uses an infor- mation theoretic approach so appears very similar BALD. The IVM algorithm was designed subsampling dataset training GP, so it privy to y values before including measurement; it cannot therefore work explic- itly in output space i.e. with Eqn. (2) . The IVM uses Eqn. (1) , but parameter entropies are calculated approximately in marginal subspace corresponding observed data points. The entropy decrease after inclusion of new data point can then be calculated eciently using GP covariance matrix. Although IVM and BALD are motivated by same objective, they work fundamentally dierently when approximate inference is carried out. At any time 7",
      "original_tokens": 451,
      "compressed_tokens": 315,
      "compression_ratio": 0.6984478935698448,
      "metadata": {
        "paper_id": "benchmark_200_paper_7",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.15669999999999998
      }
    },
    {
      "test_id": "benchmark_200_paper_8_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "Z q t ( jD ) p ( y t +1 j f; x t +1 ). If the posterior at t + 1 is approximated directly one gets q t +1 ( jD ; x t +1 ; y t +1 ). BALD calculates the entropy dierence between q t and ^ p t +1 , without having to compute q t +1 for each candidate x . In contrast, the IVM calculates the entropy change between q t and q t +1 . The IVM’s ap- proach cannot calculate the entropy of the full innite dimensional posterior, and requires O ( N x N y ) posterior updates. To do these updates eciently, ap- proximate inference is performed using Assumed Density Filtering (ADF). Using ADF means that q t +1 is a direct approximation to ^ p t +1 , indicating that the IVM makes a further approximation to BALD. Since BALD only requires O (1) posterior updates it can aord to use more accurate, iterative procedures, such as EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) [ Sebastiani and Wynn, 2000 ] explicitly works in dataspace (Eqn. (2) ). MES was proposed for regression models with input-independent observation noise. Al- though Eqn. (2) is used, the second term is constant because of input independent noise and is ignored. One cannot, however, use MES for heteroscedastic re- gression or classication; it fails to dierentiate between model uncertainty and observation uncertainty (about which our model may be condent). Some toy demonstrations show this ‘information based’ active learning criterion performing pathologically in classication by repeatedly querying points close the decision boundary or in regions of high observation uncertainty e.g. [ Huang et al., 2010 ]. This is because MES is inappropriate in this domain; BALD distinguishes be- tween observation and model uncertainty and eliminates these problems as we will show. Mutual-information based objective functions are presented in [ Ertin et al., , Fuhrmann, 2003 ]. They maximise the mutual information between the variable being measured and the variable of interest. Fuhrmann [ Fuhrmann, 2003 ] applies this to linear Gaussian models and acoustic arrays, Ertin et al. [ Ertin et al., ] to a communications channel. Although related, these objectives do not work with the model parameters and are not applied to classication. [ Guestrin et al., 2005 , Krause et al., 2006 ] also use mutual information. They specify interest points in advance and maximise the expected mutual information between the predictive distributions at these points and at the observed locations. Although this is a objective is promising for regression, it is not tractable for models with input-dependent observation noise, such as classication or preference learning. Decision theoretic: We briey mention decision theoretic approaches to ac- tive learning. Two closely related algorithms, [ Kapoor et al., 2007 , Zhu et al., 2003 ], seek to minimize the expected cost i.e. loss weighted misclassication probability on all seen and future data. These methods observe the locations of the test points and their objective functions become monotonic in the predictive entropies at the test points. [ Kapoor et al., 2007 ] also includes an empirical error term 8",
      "compressed_prompt": "Z jD ) j f; If posterior + 1 approximated directly one gets jD ; ; BALD calculates entropy dierence ^ without having compute each candidate . In contrast, IVM calculates change . The IVM’s ap- proach cannot calculate full innite dimensional posterior, requires O N N updates. To updates eciently, proximate inference performed using Assumed Density Filtering (ADF). Using ADF means direct indicating IVM makes further BALD. Since BALD only O (1) can aord more accurate, iterative procedures, EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) Sebastiani Wynn, 2000 explicitly works dataspace (Eqn. MES was proposed regression input-independent noise. Al- though Eqn. used, second constant input independent noise ignored. One cannot, however, MES heteroscedastic re- gression classication; fails dierentiate (about which our may be condent). Some toy demonstrations show ‘information based’ active learning criterion performing pathologically by repeatedly querying close boundary regions high e.g. Huang 2010 This MES inappropriate domain; BALD distinguishes be- tween eliminates problems we will show. Mutual-information based presented Fuhrmann, They being measured interest. Fuhrmann Fuhrmann, applies linear Gaussian acoustic arrays, al. communications channel. Although related, objectives work parameters applied classication. Guestrin 2005 Krause 2006 information. They specify interest advance distributions observed locations. Although promising regression, tractable input-dependent noise, such classication preference learning. Decision theoretic: We briey mention decision theoretic approaches ac- tive learning. Two closely related algorithms, Kapoor 2007 Zhu ], seek minimize expected cost i.e. loss weighted misclassication probability on all seen future data. These methods observe locations test their objective functions become monotonic predictive entropies test points. Kapoor 2007 also includes an empirical error term 8",
      "original_tokens": 527,
      "compressed_tokens": 263,
      "compression_ratio": 0.4990512333965844,
      "metadata": {
        "paper_id": "benchmark_200_paper_8",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.2008
      }
    },
    {
      "test_id": "benchmark_200_paper_8_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "Z q t ( jD ) p ( y t +1 j f; x t +1 ). If the posterior at t + 1 is approximated directly one gets q t +1 ( jD ; x t +1 ; y t +1 ). BALD calculates the entropy dierence between q t and ^ p t +1 , without having to compute q t +1 for each candidate x . In contrast, the IVM calculates the entropy change between q t and q t +1 . The IVM’s ap- proach cannot calculate the entropy of the full innite dimensional posterior, and requires O ( N x N y ) posterior updates. To do these updates eciently, ap- proximate inference is performed using Assumed Density Filtering (ADF). Using ADF means that q t +1 is a direct approximation to ^ p t +1 , indicating that the IVM makes a further approximation to BALD. Since BALD only requires O (1) posterior updates it can aord to use more accurate, iterative procedures, such as EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) [ Sebastiani and Wynn, 2000 ] explicitly works in dataspace (Eqn. (2) ). MES was proposed for regression models with input-independent observation noise. Al- though Eqn. (2) is used, the second term is constant because of input independent noise and is ignored. One cannot, however, use MES for heteroscedastic re- gression or classication; it fails to dierentiate between model uncertainty and observation uncertainty (about which our model may be condent). Some toy demonstrations show this ‘information based’ active learning criterion performing pathologically in classication by repeatedly querying points close the decision boundary or in regions of high observation uncertainty e.g. [ Huang et al., 2010 ]. This is because MES is inappropriate in this domain; BALD distinguishes be- tween observation and model uncertainty and eliminates these problems as we will show. Mutual-information based objective functions are presented in [ Ertin et al., , Fuhrmann, 2003 ]. They maximise the mutual information between the variable being measured and the variable of interest. Fuhrmann [ Fuhrmann, 2003 ] applies this to linear Gaussian models and acoustic arrays, Ertin et al. [ Ertin et al., ] to a communications channel. Although related, these objectives do not work with the model parameters and are not applied to classication. [ Guestrin et al., 2005 , Krause et al., 2006 ] also use mutual information. They specify interest points in advance and maximise the expected mutual information between the predictive distributions at these points and at the observed locations. Although this is a objective is promising for regression, it is not tractable for models with input-dependent observation noise, such as classication or preference learning. Decision theoretic: We briey mention decision theoretic approaches to ac- tive learning. Two closely related algorithms, [ Kapoor et al., 2007 , Zhu et al., 2003 ], seek to minimize the expected cost i.e. loss weighted misclassication probability on all seen and future data. These methods observe the locations of the test points and their objective functions become monotonic in the predictive entropies at the test points. [ Kapoor et al., 2007 ] also includes an empirical error term 8",
      "compressed_prompt": "Z ( jD ) p ( y j f; x ). If posterior at + 1 approximated directly one gets ( jD ; x ; y ). BALD calculates entropy dierence between ^ p , without having compute each candidate x . In contrast, IVM calculates entropy change between . The IVM’s ap- proach cannot calculate entropy full innite dimensional posterior, requires O ( N x N y ) posterior updates. To do these updates eciently, ap- proximate inference performed using Assumed Density Filtering (ADF). Using ADF means that direct approximation ^ p indicating that IVM makes further approximation BALD. Since BALD only requires O (1) posterior updates it can aord use more accurate, iterative procedures, such as EP. Information Theoretic approaches: Maximum Entropy Sampling (MES) Sebastiani Wynn, 2000 explicitly works dataspace (Eqn. (2) ). MES was proposed regression models with input-independent noise. Al- though Eqn. (2) used, second term constant because input independent noise ignored. One cannot, however, use MES heteroscedastic re- gression or classication; it fails dierentiate uncertainty uncertainty (about which our model may be condent). Some toy demonstrations show this ‘information based’ active learning criterion performing pathologically classication by repeatedly querying points close decision boundary or regions high uncertainty e.g. Huang 2010 ]. This because MES inappropriate this domain; BALD distinguishes be- tween uncertainty eliminates problems as we will show. Mutual-information based objective functions are presented Ertin Fuhrmann, 2003 ]. They maximise mutual information variable being measured variable interest. Fuhrmann Fuhrmann, 2003 applies this linear Gaussian models acoustic arrays, Ertin al. Ertin communications channel. Although related, objectives do not work with parameters are not applied classication. Guestrin 2005 Krause 2006 also use mutual information. They specify interest advance maximise expected mutual information predictive distributions observed locations. Although this objective promising regression, it not tractable models with input-dependent observation noise, such as classication or preference learning. Decision theoretic: We briey mention decision theoretic approaches ac- tive learning. Two closely related algorithms, Kapoor 2007 Zhu 2003 ], seek minimize expected cost i.e. loss weighted misclassication probability on all seen future data. These methods observe locations test points their objective functions become monotonic predictive entropies at test points. Kapoor 2007 ] also includes an empirical error term 8",
      "original_tokens": 527,
      "compressed_tokens": 368,
      "compression_ratio": 0.698292220113852,
      "metadata": {
        "paper_id": "benchmark_200_paper_8",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1847
      }
    },
    {
      "test_id": "benchmark_200_paper_9_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "EP ( 1 ) Laplace ( 1 ) 7 : 51 2 : 51 41 : 57 4 : 02 0 : 16 0 : 05 7 : 43 2 : 40 40 : 45 3 : 67 Figure 2: Percentage approximation error ( 1 s.d.) for dierent methods of approximate inference ( columns ) and approximation methods for evaluating Eqn. (4) ( rows ). The results indicate that 2 is a very accurate approximation; EP causes some loss and Laplace signicantly more, which is in line with the comparison presented in [ Kuss and Rasmussen, 2005 ]. For our experiments we use EP. that can yield pathological behaviour (we investigate this experimentally). These approaches are computationally expensive, requiring O ( N x N y ) posterior updates. Also, they must know the locations of the test data (and thus are transductive approaches); designing an inductive, decision-theoretic algorithm is an open, hard problem as it would require expensive integration over possible test data distributions. Non-probabilistic Some non-probabilistic methods have close analogues to information theoretic active learning. Perhaps the most ubiquitous is active learning for SVMs [ Tong and Koller, 2001 , Seung et al., 1992 ], where the volume of Version Space (VS) is used as a proxy for the posterior entropy. If a uniform (improper) prior is used with a deterministic classication likelihood, the log volume of VS and Bayesian posterior entropy are in fact equivalent. Just as Bayesian posteriors become intractable after observing many data points, VS can become complicated. [ Tong and Koller, 2001 ] proposes methods for approximat- ing VS with a simple shapes, such as hyperspheres (their simplest approximation reduces to margin sampling). This closely resembles approximating a Bayesian posterior using a Gaussian distribution via the Laplace or EP approximations. [ Seung et al., 1992 ] sidesteps the problem by working with predictions. The al- gorithm, Query by Committee (QBC), samples parameters from VS (committee members), they vote on the outcome of each possible x . The x with the most balanced vote is selected; this is termed the ‘principle of maximal disagreement’. If BALD is used with a sampled posterior, query by committee is implemented but with a probabilistic measure of disagreement. QBC’s deterministic vote criterion discards condence in the predictions and so can exhibit the same pathologies as MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) we made two approx- imations: we perform approximate inference ( 1 ), and we approximated the binary entropy of the Gaussian CDF by a squared exponential ( 2 ). Both of these can be substituted with Monte Carlo sampling, enabling us to compute 9",
      "compressed_prompt": "EP 41 57 4 02 16 05 43 45 3 67 Figure 2: Percentage error s.d.) dierent columns evaluating Eqn. (4) rows results indicate very accurate approximation; EP causes some loss signicantly more, which line comparison presented Kuss Rasmussen, 2005 ]. For our experiments use EP. yield pathological behaviour (we investigate experimentally). These approaches computationally expensive, requiring O y updates. Also, must know locations (and thus transductive approaches); designing inductive, decision-theoretic algorithm open, hard it would require expensive integration over distributions. Non-probabilistic Some non-probabilistic have close analogues information theoretic learning. Perhaps ubiquitous learning SVMs Tong Koller, , Seung ], where Version Space (VS) proxy entropy. If uniform (improper) prior classication likelihood, log fact equivalent. Just posteriors intractable after observing many points, complicated. Tong Koller, proposes approximat- ing simple shapes, such hyperspheres (their simplest reduces margin sampling). This closely resembles approximating using distribution via approximations. sidesteps working predictions. al- gorithm, Query Committee (QBC), samples parameters (committee members), outcome each . balanced selected; termed ‘principle maximal disagreement’. BALD sampled posterior, query committee implemented but probabilistic measure disagreement. QBC’s criterion discards condence predictions so exhibit same pathologies MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) made two approx- imations: perform approximate inference ), approximated binary entropy Gaussian CDF squared exponential Both these be substituted Monte Carlo sampling, enabling us compute 9",
      "original_tokens": 438,
      "compressed_tokens": 219,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_200_paper_9",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.16540000000000002
      }
    },
    {
      "test_id": "benchmark_200_paper_9_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "EP ( 1 ) Laplace ( 1 ) 7 : 51 2 : 51 41 : 57 4 : 02 0 : 16 0 : 05 7 : 43 2 : 40 40 : 45 3 : 67 Figure 2: Percentage approximation error ( 1 s.d.) for dierent methods of approximate inference ( columns ) and approximation methods for evaluating Eqn. (4) ( rows ). The results indicate that 2 is a very accurate approximation; EP causes some loss and Laplace signicantly more, which is in line with the comparison presented in [ Kuss and Rasmussen, 2005 ]. For our experiments we use EP. that can yield pathological behaviour (we investigate this experimentally). These approaches are computationally expensive, requiring O ( N x N y ) posterior updates. Also, they must know the locations of the test data (and thus are transductive approaches); designing an inductive, decision-theoretic algorithm is an open, hard problem as it would require expensive integration over possible test data distributions. Non-probabilistic Some non-probabilistic methods have close analogues to information theoretic active learning. Perhaps the most ubiquitous is active learning for SVMs [ Tong and Koller, 2001 , Seung et al., 1992 ], where the volume of Version Space (VS) is used as a proxy for the posterior entropy. If a uniform (improper) prior is used with a deterministic classication likelihood, the log volume of VS and Bayesian posterior entropy are in fact equivalent. Just as Bayesian posteriors become intractable after observing many data points, VS can become complicated. [ Tong and Koller, 2001 ] proposes methods for approximat- ing VS with a simple shapes, such as hyperspheres (their simplest approximation reduces to margin sampling). This closely resembles approximating a Bayesian posterior using a Gaussian distribution via the Laplace or EP approximations. [ Seung et al., 1992 ] sidesteps the problem by working with predictions. The al- gorithm, Query by Committee (QBC), samples parameters from VS (committee members), they vote on the outcome of each possible x . The x with the most balanced vote is selected; this is termed the ‘principle of maximal disagreement’. If BALD is used with a sampled posterior, query by committee is implemented but with a probabilistic measure of disagreement. QBC’s deterministic vote criterion discards condence in the predictions and so can exhibit the same pathologies as MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) we made two approx- imations: we perform approximate inference ( 1 ), and we approximated the binary entropy of the Gaussian CDF by a squared exponential ( 2 ). Both of these can be substituted with Monte Carlo sampling, enabling us to compute 9",
      "compressed_prompt": "EP 1 ) Laplace 1 ) 7 51 2 51 41 57 4 02 0 16 0 05 7 43 2 40 40 45 3 67 Figure 2: Percentage approximation error s.d.) dierent methods approximate inference columns approximation methods evaluating Eqn. (4) rows ). The results indicate that very accurate approximation; EP causes some loss Laplace signicantly more, which line comparison presented Kuss Rasmussen, 2005 ]. For our experiments use EP. that yield pathological behaviour (we investigate this experimentally). These approaches computationally expensive, requiring O N N y updates. Also, they must know locations test (and thus transductive approaches); designing an inductive, decision-theoretic algorithm an open, hard problem it would require expensive integration over possible test data distributions. Non-probabilistic Some non-probabilistic have close analogues information theoretic active learning. Perhaps most ubiquitous active learning SVMs Tong Koller, 2001 , Seung et al., 1992 ], where volume Version Space (VS) proxy entropy. If uniform (improper) prior deterministic classication likelihood, log volume VS Bayesian entropy fact equivalent. Just Bayesian posteriors become intractable after observing many points, VS become complicated. Tong Koller, 2001 ] proposes approximat- ing VS simple shapes, such hyperspheres (their simplest approximation reduces margin sampling). This closely resembles approximating Bayesian using Gaussian distribution via Laplace or EP approximations. Seung et al., 1992 ] sidesteps problem working predictions. al- gorithm, Query Committee (QBC), samples parameters from VS (committee members), they on outcome each possible . most balanced selected; this termed ‘principle maximal disagreement’. If BALD used sampled posterior, query committee implemented but probabilistic measure disagreement. QBC’s deterministic vote criterion discards condence predictions so exhibit same pathologies MES. 5 Experiments Quantifying Approximation Losses: To obtain (5) made two approx- imations: we perform approximate inference 1 ), we approximated binary entropy Gaussian CDF squared exponential 2 ). Both these can be substituted Monte Carlo sampling, enabling us to compute 9",
      "original_tokens": 438,
      "compressed_tokens": 306,
      "compression_ratio": 0.6986301369863014,
      "metadata": {
        "paper_id": "benchmark_200_paper_9",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.15669999999999998
      }
    },
    {
      "test_id": "benchmark_200_paper_10_statistical_50",
      "technique": "statistical_50%",
      "original_prompt": "Dim. 1 Dim. 2 (a) block in the middle Dim. 1 Dim. 2 (b) block in the corner Dim. 1 Dim. 2 (c) checkerboard 0 : 5 0 : 9 No. queried points Accuracy 0 : 5 No. queried points Accuracy 0 : 5 No. queried points Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars of the two classes are shown with black squares ( ) and red circles ( ). Bottom: Results of active learning with nine methods: random query ( ), BALD( ), MES ( ), QBC with the vote criterion with 2 ( ) and 100 ( ) committee members, active SVM ( ), IVM ( ), decision theoretic: [ Kapoor et al., 2007 ] ( ), [Zhu et al., 2003] ( ) and empirical error ( ). an asymptotically unbiased estimate of the expected information gain. Using extensive Monte Carlo as the ‘gold standard’, we can evaluate how much we loose by applying these approximations. We quantify approximation error as: max x 2P I ( x ) I (arg max x 2P ^ I ( x )) max x 2P I ( x ) 100% (8) where I is the objective computed using Monte Carlo, ^ I is the approximate objective. The cancer UCI dataset was used, results and discussion are in Fig. 2. Pool based active learning: We test BALDfor GPC and preference learning in the pool-based setting i.e. selecting x values from a xed set of data-points. Although BALD can generalise to selecting continuous x , this enables us to compare to algorithms that cannot. We compare to eight other algorithms: random sampling, MES, QBC (with 2 and 100 committee members), SVM with version space approximation [ Tong and Koller, 2001 ], decision theoretic approaches in [ Kapoor et al., 2007 , Zhu et al., 2003 ] and directly minimizing 10",
      "compressed_prompt": "(a) block middle (b) block corner (c) checkerboard 9 No. Accuracy No. Accuracy No. Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars two classes shown black squares red circles Bottom: Results nine methods: query BALD( MES QBC vote criterion members, SVM IVM theoretic: Kapoor [Zhu 2003] empirical an asymptotically unbiased estimate expected information gain. Using extensive Monte Carlo as ‘gold standard’, evaluate how much loose by applying these approximations. quantify as: (arg )) 100% (8) where objective computed using Monte Carlo, approximate objective. The cancer UCI dataset was used, results discussion Fig. 2. Pool based learning: test BALDfor GPC preference pool-based setting i.e. values from a xed set data-points. Although BALD generalise selecting continuous this enables us compare algorithms that cannot. We compare eight other algorithms: random sampling, MES, QBC (with committee members), SVM version space approximation Tong Koller, 2001 ], decision theoretic approaches Kapoor 2007 , Zhu 2003 ] directly minimizing 10",
      "original_tokens": 308,
      "compressed_tokens": 154,
      "compression_ratio": 0.5,
      "metadata": {
        "paper_id": "benchmark_200_paper_10",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.11309999999999999
      }
    },
    {
      "test_id": "benchmark_200_paper_10_statistical_70",
      "technique": "statistical_70%",
      "original_prompt": "Dim. 1 Dim. 2 (a) block in the middle Dim. 1 Dim. 2 (b) block in the corner Dim. 1 Dim. 2 (c) checkerboard 0 : 5 0 : 9 No. queried points Accuracy 0 : 5 No. queried points Accuracy 0 : 5 No. queried points Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars of the two classes are shown with black squares ( ) and red circles ( ). Bottom: Results of active learning with nine methods: random query ( ), BALD( ), MES ( ), QBC with the vote criterion with 2 ( ) and 100 ( ) committee members, active SVM ( ), IVM ( ), decision theoretic: [ Kapoor et al., 2007 ] ( ), [Zhu et al., 2003] ( ) and empirical error ( ). an asymptotically unbiased estimate of the expected information gain. Using extensive Monte Carlo as the ‘gold standard’, we can evaluate how much we loose by applying these approximations. We quantify approximation error as: max x 2P I ( x ) I (arg max x 2P ^ I ( x )) max x 2P I ( x ) 100% (8) where I is the objective computed using Monte Carlo, ^ I is the approximate objective. The cancer UCI dataset was used, results and discussion are in Fig. 2. Pool based active learning: We test BALDfor GPC and preference learning in the pool-based setting i.e. selecting x values from a xed set of data-points. Although BALD can generalise to selecting continuous x , this enables us to compare to algorithms that cannot. We compare to eight other algorithms: random sampling, MES, QBC (with 2 and 100 committee members), SVM with version space approximation [ Tong and Koller, 2001 ], decision theoretic approaches in [ Kapoor et al., 2007 , Zhu et al., 2003 ] and directly minimizing 10",
      "compressed_prompt": "Dim. 1 Dim. (a) block middle Dim. 1 Dim. (b) block corner Dim. 1 Dim. (c) checkerboard 0 : 5 0 : 9 No. queried points Accuracy 5 No. queried points Accuracy 5 No. queried points Accuracy Figure 3: Top: Evaluation on articial datasets. Exemplars two classes are shown black squares red circles ). Bottom: Results active learning nine methods: random query BALD( MES QBC vote criterion 100 committee members, active SVM IVM decision theoretic: [ Kapoor 2007 ] [Zhu 2003] empirical error ). an asymptotically unbiased estimate expected information gain. Using extensive Monte Carlo as ‘gold standard’, we can evaluate how much we loose by applying these approximations. We quantify approximation error as: max (arg ^ )) 100% (8) where is objective computed using Monte Carlo, ^ is approximate objective. The cancer UCI dataset was used, results discussion are Fig. 2. Pool based active learning: We test BALDfor GPC preference learning pool-based setting i.e. selecting values from a xed set data-points. Although BALD can generalise selecting continuous , this enables us compare algorithms that cannot. We compare eight other algorithms: random sampling, MES, QBC (with 100 committee members), SVM version space approximation [ Tong Koller, 2001 ], decision theoretic approaches [ Kapoor et al., 2007 , Zhu et al., 2003 ] directly minimizing 10",
      "original_tokens": 308,
      "compressed_tokens": 215,
      "compression_ratio": 0.698051948051948,
      "metadata": {
        "paper_id": "benchmark_200_paper_10",
        "dictionary_entries": null,
        "substitutions": null,
        "processing_time_ms": 0.1032
      }
    }
  ]
}